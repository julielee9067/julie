2:"$Sreact.suspense"
3:I[1523,["851","static/chunks/851-4b7230f426f3d0c3.js","636","static/chunks/636-65bb31d056e95ffd.js","614","static/chunks/614-de6ae75424f2579f.js","797","static/chunks/app/blog/%5B...slug%5D/page-57cc52b850e230d1.js"],"BailoutToCSR"]
5:I[4707,[],""]
7:I[6423,[],""]
8:I[3483,["648","static/chunks/648-f6f3afee71b2d583.js","768","static/chunks/app/blog/layout-3825e9c62cfb97f3.js"],"default",1]
9:I[5495,["851","static/chunks/851-4b7230f426f3d0c3.js","648","static/chunks/648-f6f3afee71b2d583.js","185","static/chunks/app/layout-396cfab0aaba2929.js"],"ThemeProvider"]
a:I[4491,["851","static/chunks/851-4b7230f426f3d0c3.js","648","static/chunks/648-f6f3afee71b2d583.js","185","static/chunks/app/layout-396cfab0aaba2929.js"],"LanguageProvider"]
b:I[1890,["851","static/chunks/851-4b7230f426f3d0c3.js","648","static/chunks/648-f6f3afee71b2d583.js","185","static/chunks/app/layout-396cfab0aaba2929.js"],"Header"]
6:["slug","cs/multiprocessing-and-multithreading-in-python","c"]
0:["d7PBk91r6083YdzRyAzeq",[[["",{"children":["blog",{"children":[["slug","cs/multiprocessing-and-multithreading-in-python","c"],{"children":["__PAGE__?{\"slug\":[\"cs\",\"multiprocessing-and-multithreading-in-python\"]}",{}]}]}]},"$undefined","$undefined",true],["",{"children":["blog",{"children":[["slug","cs/multiprocessing-and-multithreading-in-python","c"],{"children":["__PAGE__",{},[["$L1",["$","$2",null,{"fallback":null,"children":["$","$L3",null,{"reason":"next/dynamic","children":"$L4"}]}],null],null],null]},[null,["$","$L5",null,{"parallelRouterKey":"children","segmentPath":["children","blog","children","$6","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L7",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined"}]],null]},[[null,["$","$L8",null,{"children":["$","$L5",null,{"parallelRouterKey":"children","segmentPath":["children","blog","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L7",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined"}],"params":{}}]],null],null]},[[[["$","link","0",{"rel":"stylesheet","href":"/julie/_next/static/css/2688adaac3b51e6f.css","precedence":"next","crossOrigin":"$undefined"}],["$","link","1",{"rel":"stylesheet","href":"/julie/_next/static/css/e680cef9016abb97.css","precedence":"next","crossOrigin":"$undefined"}]],["$","html",null,{"lang":"ko","suppressHydrationWarning":true,"children":["$","body",null,{"className":"__className_29e2ff","children":["$","$L9",null,{"attribute":"class","defaultTheme":"system","enableSystem":true,"disableTransitionOnChange":true,"children":["$","$La",null,{"children":[["$","$Lb",null,{}],["$","$L5",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L7",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":"404"}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],"notFoundStyles":[]}]]}]}]}]}]],null],null],["$Lc",null]]]]
d:I[3124,["851","static/chunks/851-4b7230f426f3d0c3.js","636","static/chunks/636-65bb31d056e95ffd.js","614","static/chunks/614-de6ae75424f2579f.js","797","static/chunks/app/blog/%5B...slug%5D/page-57cc52b850e230d1.js"],"default"]
e:T2792,
## 개요
대규모 데이터 파이프라인을 운영하다보면 **병목 현상**을 자주 목격하게 됩니다. 이 때, 마이크로서비스가 실행 중인 컨테이너들을 수평적으로 확장하는 것도 중요하지만, 때로는 컨테이너 확장만으로는 해결되지 않는 문제들도 있습니다.

예를 들어, 특정 서비스에서 복잡한 연산 때문에 한 개의 메시지를 처리하는 데 시간이 너무 오래 걸린다면, 멀티 프로세싱 기법을 도입하여 문제를 해결할 수 있습니다. 또한, 한 서비스가 다른 서비스의 네트워크 응답을 기다려야 하는 상황에서는, 멀티 스레딩을 활용하여 대기 시간 동안 다른 작업을 병행할 수 있습니다.

이 글에서는 멀티 프로세싱과 멀티 스레딩의 차이가 무엇인지, 그리고 이 방법들을 파이썬에서 어떻게 사용할 수 있을지 알아보도록 하겠습니다.

## 멀티 프로세싱
먼저, 프로세스의 개념에 대해서 알아보겠습니다.

**프로세스**: **컴퓨터에서 실행 중인 하나의 프로그램**이라고 생각하면 됩니다. 예를 들어, 웹 브라우저, 미디어 플레이어 등이 각각 하나의 프로세스입니다.

각 프로세스는 운영체제로부터 독립된 메모리 공간(힙, 스택 등)과 자원을 할당 받고, 한 프로세스에 문제가 발생해도 다른 프로세스에는 영향을 주지 않습니다.

CPU 코어를 활용해 위와 같은 여러 개의 프로세스들을 병렬로 실행할 수 있으며, 프로세스 간 통신은 **IPC**(Inter-Process Communication)을 사용합니다.
예를 들어, 한 컴퓨터에서 웹 브라우저와 미디어 플레이어를 동시에 실행하는 경우, 두 개의 독립된 프로세스가 작동합니다.  

아래는 Python에서 multiprocessing을 구현할 수 있는 간단한 예제입니다.
```python
from multiprocessing import Process
import time

def process_file(file_name):
    print(f"[프로세스] {file_name} 처리 시작")
    # 실제 파일 처리는 생략하고, 2초간 대기합니다.
    time.sleep(2)
    print(f"[프로세스] {file_name} 처리 완료")

def main():
    files = ['file1.csv', 'file2.csv']
    processes = []

    # 각 파일에 대해 별도의 프로세스를 생성합니다.
    for file in files:
        p = Process(target=process_file, args=(file,))
        processes.append(p)
        p.start()  # 각 프로세스 시작

    # 모든 프로세스가 끝날 때까지 대기합니다.
    for p in processes:
        p.join()

    print("모든 프로세스 작업 완료")

if __name__ == "__main__":
    main()
```
#### 동시에 실행할 수 있는 프로세스의 수
그럼, **동시에 실행되는 프로세스의 수**는 어떻게 결정하는 것이 좋을까요?


보통 **CPU bound** 작업일 경우, 일반적으로 **실행할 프로세스의 수를 CPU 코어 수와 동일**하게 맞추는 것이 좋습니다. 예를 들어, 8코어 시스템에서는 8개의 프로세스를 동시에 실행하면 각 프로세스가 별도의 코어에서 동작하며 최적의 성능을 낼 수 있습니다.

만약 작업이 **I/O bound**일 경우, CPU 사용률이 낮으므로 **CPU 코어 수보다 더 많은 프로세스**를 실행해도 문제가 없을 수 있습니다. 하지만 동시에 실행되는 프로세스가 많아지면, 각 프로세스가 사용하는 메모리와 자원에 대한 부담이 커지기 때문에 시스템의 **메모리 용량**과 **자원 사용량**을 고려하여 정해야 합니다.

#### IPC (Inter-Process Communication)
IPC, 프로세스 간 통신은 서로 독립적으로 실행되는 여러 프로세스들이 데이터를 주고받을 수 있도록 해주는 메커니즘입니다.

**IPC 방법들**
1. **Pipe와 FIFO (Named Pipe)**  
    **파이프**: 두 프로세스 간에 데이터를 일방향으로 전달하는 통신 채널입니다. 보통 부모/자식 프로세스 사이에서 사용됩니다.  
    **FIFO (Named Pipe)**: 이름이 있는 파이프로, 관련 없는 독립적인 프로세스들 간에도 통신할 수 있습니다.
2. **메시지 큐**  
  여러 프로세스가 데이터를 메시지 단위로 보내고 받을 수 있는 큐입니다.
  메시지는 순서대로 저장되고, 한 프로세스가 메시지를 보내면 다른 프로세스가 이를 꺼내어 처리합니다.
3. **공유 메모리**  
  여러 프로세스가 같은 메모리 영역에 접근할 수 있게 하는 방법입니다.
  접근 속도가 매우 빠르지만, race condition(동기화 문제)를 해결하기 위한 추가 메커니즘이 필요합니다.
4. **소켓**  
  네트워크를 통해 프로세스 간 통신을 할 수 있고, 동일 컴퓨터 내의 프로세스 뿐만 아니라 다른 컴퓨터의 프로세스와도 통신할 수 있습니다.

파이썬에서는 사용의 편의성과 안정성 면에서 메시지 큐(`multiprocessing.Queue`)가 가장 널리 사용됩니다. 

#### 멀티 프로세싱 풀 (Pool)
멀티 프로세싱 풀은 미리 정해진 수의 프로세스(작업자)를 생성해두고, 이를 통해 작업을 분산하여 실행하는 방식입니다. 이렇게 하면 매번 새로운 프로세스를 생성하는 오버헤드를 줄일 수 있어, 다수의 작업을 효율적으로 처리할 수 있습니다.

**작동 원리**
1. 풀은 시작할 때 **지정한 수의 프로세스를 미리 생성**합니다. 예를 들어, **CPU 코어 수나 작업량**에 맞게 4개, 8개 등의 프로세스를 만들어 둡니다.
2. 여러 작업을 풀에 제출하면, 풀에 있는 프로세스들이 작업을 나눠서 실행합니다. **작업이 끝난 프로세스는 다시 대기** 상태로 돌아가 다음 작업을 처리할 준비를 합니다.
3. 한 번 생성된 프로세스는 여러 작업에 대해 **재사용**됩니다.

## 멀티 스레딩
**스레드**: 스레드는 하나의 프로세스 내에서 **실제로 작업을 수행하는 작은 실행 단위**입니다. 즉, 하나의 프로세스 안에서 여러 가지 일을 동시에 진행할 수 있도록 도와주는 역할을 합니다. 예를 들면, 크롬(프로세스)에서 여러 개의 탭마다 웹사이트를 불러오는 작업은 멀티 스레딩으로 이루어집니다.

같은 프로세스 내의 스레드들은 **모두 동일한 메모리(데이터, 변수 등)를 공유**하며, 스레드들끼리 데이터를 쉽게 주고받을 수 있습니다. 하지만, 동시에 **같은 데이터에 접근하다 보면 서로 충돌**할 수도 있어 주의해야 합니다.

#### Python에서 멀티 스레딩과 GIL (Global Interpreter Lock)
Python의 가장 널리 쓰이는 interpreter인 CPython에는 **GIL**이라는 메커니즘이 있습니다. GIL은 한 번에 **오직 하나의 스레드**만 Python 코드를 실행하도록 하는 잠금장치입니다.


Python은 **Garbage collection**을 사용해 메모리를 자동으로 관리합니다. GIL은 **여러 스레드가 동시에 메모리를 변경하는 일을 방지**하고, 프로그램이 복잡해져도 메모리 관리가 안전하게 이루어지도록 도와줍니다.

하지만, GIL으로 인해 여러 스레드를 사용해도 한 시점에 오직 하나의 스레드만이 실제로 코드를 실행합니다. 따라서, 복잡한 계산이나 **CPU를 많이 사용하는 작업(CPU bound)은 여러 스레드로 병렬 처리했을 때 기대만큼의 성능 향상을 얻기 어렵습니다**.

반면에, 파일 입출력, 네트워크 통신 등과 같이 **기다리는 시간이 상대적으로 많은 작업**(I/O bound)들에서는 **스레드가 대기 상태로 있을 때 다른 스레드가 실행**될 수 있으므로 GIL의 영향이 덜합니다. 이 경우, CPU는 한 스레드에만 국한되지 않고 다른 스레드로 전환되어 작업을 진행합니다.

예를 들면, 파일을 읽거나 쓸 때, CPU는 집중적으로 계산하는 것이 아니라, 외부 장치(디스크 등)와 데이터를 주고받느라 기다리는 시간이 발생합니다. 이 때 스레드가 **대기 상태**로 들어가면서 GIL을 해제하게 됩니다. 이로 인해 다른 스레드들이 CPU를 사용할 수 있게 되어, 여러 파일을 동시에 읽거나 쓸 수 있습니다.
  
엄밀히 말하면 CPU가 여러 작업을 번갈아 실행하기 때문에, 동시에 실행되는 것처럼 보이지만 실제로는 **컨텍스트 스위칭**이 계속 발생하며 작업을 처리합니다.

CPython에서는 GIL이 interpreter의 핵심 설계 요소이기 때문에 Python 자체에서 **GIL을 완전히 해제하거나 제거하는 것은 불가능**합니다.

#### 동시에 실행할 수 있는 스레드의 수
멀티 스레딩에서 **동시에 실행할 수 있는 스레드의 수**는 작업의 종류에 따라 달라집니다.

**CPU 집약적인 작업**의 경우, CPython의 GIL 때문에 한 번에 한 스레드만 Python 바이트코드를 실행합니다. 따라서, CPU 코어 수에 맞춰 스레드를 구성하는 것이 좋습니다. 이렇게 하면 불필요한 스레드 전환(컨텍스트 스위칭) 오버헤드를 줄일 수 있습니다.

반면, **I/O 바운드 작업**처럼 파일 입출력이나 네트워크 요청과 같이 대기 시간이 긴 작업에서는, CPU 사용이 크게 발생하지 않으므로 CPU 코어 수보다 훨씬 많은 스레드를 사용할 수 있습니다. 예를 들어, 네트워크 요청이 많은 애플리케이션에서는 수십 개 이상의 스레드를 사용해도 오히려 성능 향상을 기대할 수 있습니다.

#### 멀티 스레딩에서의 풀
멀티 프로세싱에서 풀을 사용하는 것과 같이, 스레딩에서도 풀 개념을 적용할 수 있습니다. Python에서는 주로 `cuncurrent.futures.ThreadPoolExecutor`를 사용하여 풀을 구성합니다. 이를 통해 **미리 정해진 수의 스레드를 생성하고, 작업을 해당 스레드들에 분산**시켜 실행할 수 있습니다.
4:["$","$Ld",null,{"post":{"slug":"cs/multiprocessing-and-multithreading-in-python","categorySlug":"cs","title":{"ko":"파이썬에서의 멀티 프로세싱과 멀티 스레딩","en":"Multiprocessing and Multithreading in Python"},"date":"2025-02-21","category":{"ko":"컴퓨터 공학","en":"Computer Science"},"description":{"ko":"멀티 프로세싱과 멀티 스레딩의 파이썬에서의 동작 원리","en":"How Multiprocessing and Multithreading Work in Python"},"content":"$e"}}]
c:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"Julie Lee's Portfolio"}],["$","meta","3",{"name":"description","content":"Welcome to Julie's portfolio page."}],["$","meta","4",{"name":"next-size-adjust"}]]
1:null
