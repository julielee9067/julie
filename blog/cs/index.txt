2:I[3422,["851","static/chunks/851-4b7230f426f3d0c3.js","648","static/chunks/648-f6f3afee71b2d583.js","636","static/chunks/636-65bb31d056e95ffd.js","254","static/chunks/app/blog/%5Bcategory%5D/page-8ececd3cb7d12067.js"],"default"]
6:I[4707,[],""]
8:I[6423,[],""]
9:I[3483,["648","static/chunks/648-f6f3afee71b2d583.js","768","static/chunks/app/blog/layout-3825e9c62cfb97f3.js"],"default",1]
a:I[5495,["851","static/chunks/851-4b7230f426f3d0c3.js","648","static/chunks/648-f6f3afee71b2d583.js","185","static/chunks/app/layout-396cfab0aaba2929.js"],"ThemeProvider"]
b:I[4491,["851","static/chunks/851-4b7230f426f3d0c3.js","648","static/chunks/648-f6f3afee71b2d583.js","185","static/chunks/app/layout-396cfab0aaba2929.js"],"LanguageProvider"]
c:I[1890,["851","static/chunks/851-4b7230f426f3d0c3.js","648","static/chunks/648-f6f3afee71b2d583.js","185","static/chunks/app/layout-396cfab0aaba2929.js"],"Header"]
3:T6154,
오늘은 이벤트 브로커와 메시지 브로커, 그리고 각각의 대표적인 예시인 Apache Kafka와 RabbitMQ에 대해 알아보겠습니다.

## 이벤트 브로커 (Event Broker)
이벤트 브로커는 **시스템 내에서 일어나는 다양한 사건이나 상태 변화를 다른 컴포넌트에 전달**하는 중개자 역할을 합니다.

예를 들어, 온라인 쇼핑몰에서는 사용자가 상품을 장바구니에 담거나 결제하는 등의 행동이 이벤트로 발생할 수 있습니다.
이러한 이벤트들은 직접적으로 다른 컴포넌트에 전달되는 것이 아니라 이벤트 브로커를 통해 전달되어 **여러 시스템이나 서비스가 동시에 반응**할 수 있도록 할 수 있습니다.

시스템의 각 부분은 이벤트 브로커를 통해 **서로 분리되어 동작**하게 되는데, 이를 통해 한 부분에서 발생한 변화가 다른 부분에 영향을 주더라도 서로 강하게 의존하지 않게 됩니다.

만일 결제 시스템에 문제가 생겨도 주문 처리나 재고 관리 시스템은 이미 발생한 이벤트를 기반으로 자신의 업무를 계속 진행할 수 있습니다.

이런 구조 덕분에 장애가 발생했을 때 **문제를 국소적으로 격리**할 수 있고 **시스템 전체의 안정성을 높일 수 있는 효과**가 있습니다. (Loose coupling)

또한, 이벤트 브로커는 발생한 이벤트 데이터를 기록하고 저장하는 기능도 제공합니다. 
예를 들어 사용자가 웹사이트에서 발생시킨 모든 행동 기록을 이벤트 브로커가 수집해 저장해 놓으면 나중에 이 데이터를 분석해 **사용자 행동 패턴을 파악**하거나 **문제 발생 시 재처리할 수 있는 기반**을 마련할 수 있습니다.

이러한 기능은 **실시간 모니터링**이나 **로그 수집**, **감사**와 같은 다양한 활용 사례에 유용하게 쓰입니다.

### Pub/Sub 모델
이벤트 브로커는 pub/sub 모델을 채택하고 있는데, 이 모델에서 이벤트를 생성하는 쪽은 **publisher**, 이벤트를 받아 처리하는 쪽은 **consumer**라고 부릅니다.

Publisher는 자신이 **생성한 이벤트를 이벤트 브로커에 전달**하고, 이벤트 브로커는 이 **이벤트를 구독하고 있는 여러 consumer들에게 동시에 전달**합니다.

예를 들어, 온라인 쇼핑몰에서 상품이 구매되면 결제 시스템, 주문 관리 시스템, 재고 관리 시스템, 심지어는 고객에게 알림을 보내는 시스템 등이 모두 이 이벤트를 받아 각각의 역할을 수행할 수 있습니다.

다른 예시를 생각해보면 이벤트 브로커는 마치 **도서관의 사서**와 같다고 볼 수 있습니다.

도서관에서 책을 요청하면 사서가 책을 찾아 여러 독자에게 전달해 주는 것처럼, 이벤트 브로커도 각 시스템의 요청이나 상태 변화를 받아 필요한 모든 곳에 전달합니다.
이 과정에서 각 시스템은 직접 서로를 호출할 필요 없이 **간접적으로 소통**할 수 있게 됩니다.

### Apache Kafka
Kafka는 이벤트 브로커의 대표적인 예시로 주로 **대용량의 실시간 데이터 스트림**을 처리하는 데 최적화되어 있습니다.

Kafka에서는 **모든 이벤트가 로그 형태로 기록**되며, 이 로그는 분산 시스템 내 여러 노드에 걸쳐 저장됩니다.

예를 들어 대규모 웹 애플리케이션에서 사용자 행동 데이터나 서버 로그 같은 이벤트가 발생하면
이 데이터를 Kafka에 기록해 여러 consumer가 동시에 실시간 분석, 모니터링, 경고 등의 작업을 수행할 수 있습니다.

Event broker의 특성처럼 Kafka의 pub/sub 모델은 publisher가 데이터를 보내면 여러 소비자가 그 로그를 구독하여 각자의 필요에 따라 데이터를 처리할 수 있습니다.
이 과정에서 이벤트가 지속적으로 기록되기 때문에 **나중에 필요할 때 과거의 데이터를 재분석하거나 시스템 에러 발생 시 재처리**를 쉽게 할 수 있습니다.

#### 예제
월드컵처럼 실시간 이벤트가 많은 대회를 다루는 웹사이트를 운영한다고 가정해봅시다.

경기가 진행되는 동안 골이 들어가거나 선수 교체가 이루어질 때마다 해당 정보를 빠르게 업데이트해야 합니다.

이를 위해 이벤트가 발생할 때마다 **큐(queue)** 에 저장하며, 이벤트를 큐에 삽입하는 서버나 프로세스를 **producer**라고 부릅니다.

반대로, 큐에서 이벤트를 읽고 웹사이트를 업데이트하는 서버를 **consumer**라고 합니다.

현재 월드컵은 48개 팀이 참가하지만, 만약 1000개 팀이 동시에 경기를 진행하는 대회로 확장된다면 발생하는 이벤트 수가 급증할 것입니다.

이 경우, 하나의 서버가 큐를 관리하는 방식으로는 부담을 감당하기 어렵고, consumer 또한 넘쳐나는 데이터를 처리하지 못할 것입니다.
이 때는 **시스템을 확장하여 여러 대의 서버를 활용**해야 하는 상황이 발생합니다.

그러나 단순히 여러 서버에 이벤트를 무작위로 분배하면 문제가 생길 수 있습니다.
예를 들어, 어떤 서버에서는 경기가 시작되기 전에 골이 들어가는 것으로 표기될 수도 있고, 선수가 경고를 받기 전에 이미 퇴장당한 것으로 기록될 수도 있습니다.

따라서 **이벤트 순서를 유지**하면서도 여러 서버에서 부하를 나누어 처리하는 방법이 필요합니다.

Kafka의 핵심 개념 중 하나는 **사용자가 직접 메시지의 분배 전략을 정의할 수 있다**는 것입니다.

위 예제에서 가장 적절한 방법은 **경기단위로 이벤트를 분배하는 것**입니다. 즉, **같은 경기에 대한 이벤트는 동일한 큐(Partition)에 저장되도록 구성**하면 한 경기 내에서는 모든 이벤트가 순서대로 처리될 수 있습니다.

하지만 consumer가 **처리해야 할 데이터가 너무 많다**면 어떻게 해결할 수 있을까요?

Kafka에서는 **consumer group**을 활용해 이 문제를 해결할 수 있습니다. 여러 consumer가 같은 consumer group에 속하면 Kafka는 **각 이벤트가 오직 하나의 consumer에게만 할당되도록 보장**합니다.
그럼 부하를 여러 consumer가 나누어 처리하면서도 중복 처리를 방지할 수 있습니다.

만약 웹사이트가 축구뿐만 아니라 농구 같은 다른 스포츠 이벤트도 다루기로 결정했다면 Kafka의 **topic** 개념을 활용할 수 있습니다.

**각 이벤트는 특정한 topic에 속하며, consumer는 특정한 토픽만 구독**하면 됩니다. 예를 들어 축구 웹사이트 전용 consumer는 축구 토픽만 구독하고, 농구 웹사이트 전용 consumer는 농구 토픽만 구독하면 됩니다.

#### 기본 개념
앞서 설명한 예제를 기반으로 Kafka의 핵심 개념에 대해 좀 더 알아보겠습니다.

1. **Kafka 클러스터와 브로커**
    
    Kafka 클러스터는 여러 개의 **브로커**로 구성 됩니다.
    브로커는 각각 독립적인 서버로, 데이터를 저장하고 클라이언트 요청을 처리하는 역할을 합니다.
    브로커가 많을수록 더 많은 데이터를 저장할 수 있고, 더 많은 클라이언트를 처리할 수 있습니다.

2. **파티션과 로그 구조**

    각 브로커는 여러 개의 **파티션**을 가집니다.
    파티션은 **불변(immutable)한 메시지의 순차적인 저장 공간**으로, 새로운 메시지가 계속 추가되는 구조입니다.
    이 구조는 **로그(log) 파일**과 유사하게 생각하면 됩니다.
    Kafka는 파티션 단위로 데이터를 분산 저장하고 병렬로 처리하기 때문에 파티션을 통해 시스템을 확장할 수 있습니다.

3. **토픽과 파티션의 차이**
    
    **토픽은 파티션을 논리적으로 그룹화하는 개념**입니다.
    Kafka에서 데이터를 주고받을 때는 항상 특정 토픽을 통해 이루어집니다.
    토픽은 항상 **다중 producer를 허용**하며, 하나의 토픽에는 0개, 1개, 또는 여러 개의 producer가 데이터를 쓸 수 있습니다.

4. **Kafka의 메시지 큐 vs. 스트림 처리 방식**
    
    Kafka는 **메시지 큐(Message Queue)** 로 사용할 수도 있고, **스트림(Stream)** 으로 사용할 수도 있습니다.
    
    메시지 큐 방식은 consumer가 메시지를 읽은 후 **처리가 완료되었음을 명시적으로 확인**합니다.
    스트림 방식은 consumer가 메시지를 읽고 처리는 하지만 **Kafka에 처리 완료를 하지는 않습니다**.

#### 동작 원리
Kafka에서 이벤트가 발생하면 producer는 메시지를 포맷팅한 후 토픽으로 전송합니다.
Kafka의 메시지는 필수 필드인 **value**와 선택 필드인 **key, timestamp, headers**로 구성됩니다. 

    Key: 메시지가 어느 파티션에 저장될지를 결정하는데 사용됩니다. key가 없으면 Kafka는 메시지를 무작위로 파티션에 배치합니다.
    Timestamp: 메시지의 순서를 결정하는데 사용됩니다.
    headers: HTTP header처럼 키-값 쌍으로 메타데이터를 저장할 수 있습니다. 

1. **파티션 할당 및 브로커 처리**
    
    Kafka는 메시지의 키를 해싱하여 특정 파티션에 할당합니다.
    키가 없는 경우 **라운드 로빈**이나 설정된 다른 로직을 이용해 파티션을 배정합니다.
    여기서 **같은 키를 가진 메시지는 항상 같은 파티션에 저장되어 순서가 유지**됩니다.
    
    Kafka는 메시지가 할당된 **파티션을 어느 브로커가 관리하는지 확인**하기도 합니다.
    **Kafka 컨트롤러**가 이 메타데이터를 유지하고 Producer는 해당 브로커로 메시지를 전송하게 됩니다.

2. **Kafka의 로그 구조 및 메시지 처리 방식**

    **파티션**은 **append-only log** 형태로 동작하는데, 메시지는 끝에 추가되며 수정이나 삭제되지 않습니다.
    
    이 방식이 가지는 장점은 다음과 같습니다.
        
        불변성 (Immutability): 메시지가 한 번 저장되면 변경되지 않아 일관성이 유지됩니다.
        고성능 (Efficiency): 디스크의 순차 쓰기(sequential write)를 활용하여 높은 처리량을 제공합니다.
        확장성 (Scalability): 파티션을 여러 브로커에 분산시켜 시스템 부하를 효율적으로 분배할 수 있습니다.

    Kafka의 메시지는 **각 파티션 내에서만 순서가 보장**되며, 각 메시지는 **offset**을 부여받습니다.
    여기서 offset은 **특정 파티션에서의 메시지 위치**를 나타내고, consumer가 메시지를 읽을 때 이걸 기준으로 진행 상태를 관리합니다.
    
3. **복제 및 내구성**

    Kafka는 **leader-follower** 모델을 이용해 데이터 복제를 수행합니다.
        
        리더 복제본 (Leader replica): 각 파티션의 리더는 메시지의 읽기 및 쓰기를 담당합니다.
        팔로워 복제본 (Follower replica): 다른 브로커에 분산 저장되어 리더 복제본을 백업하는 역할을 합니다.
        동기화 및 장애 복구 (sync and failover): 팔로워들은 리더의 메시지를 동기화하며 최신 데이터를 유지합니다.
            만약 리더에 장애(failure)가 발생하면 최신 데이터를 가진 팔로워가 새로운 리더로 승격(promote)됩니다.
            Kafka의 컨트롤러가 전체 복제 및 장애 조치를 관리합니다.
    
4. **Consumer의 동작 방식**
    
    consumer는 토픽에서 메시지를 읽어오는 역할을 하는데 두 가지 방식으로 동작할 수 있습니다.
    
    1. **Push model**: 메시지가 도착하면 즉시 consumer에게 전달
    2. **Pull model**: consumer가 일정 주기로 Kafka에서 메시지를 조회    

#### Kafka는 언제 사용해야 할까?
위에서 정리했다시피 Kafka는 **메시지 큐** 또는 **스트림**으로 활용될 수 있으며 두 방식의 가장 큰 차이는 **consumer가 데이터를 처리하는 방식**에 있습니다.

1. **메시지 큐로 사용하는 것이 적절한 경우**
    
    1. **비동기 처리가 필요한 경우**:
    Youtube와 같은 비디오 플랫폼을 예로 들어봅시다. 사용자가 동영상을 업로드하면 저화질 버전은 즉시 제공하고 고화질 인코딩은 Kafka 토픽에 메시지를 추가하여 여유가 생길 때 처리할 수 있습니다.
    
    2. **메시지의 순서를 보장해야 하는 경우**:
    온라인 티켓 예매 시스템 같은 경우 사용자가 도착한 순서대로 티켓 구매 페이지에 접근해야 합니다.
    Kafka를 **가상 대기열로 활용**하면서 사용자가 접근한 **순서를 유지하며 메시지를 소비하도록 보장**할 수 있습니다.
    
    3. **Producer와 consumer를 분리하여 독립적으로 확장해야 하는 경우**:
    일반적으로 **producer가 메시지를 생성하는 속도가 consumer가 처리하는 속도보다 빠를 때** 발생합니다. 
    MSA (Microservice Architecture) 에서는 서비스 간 결합도를 낮추고, 특정 서비스가 다운되더라도 다른 서비스에 영향을 주지 않도록 비동기 메시지 큐를 활용합니다.
    
2. **스트림으로 사용하는 것이 적절한 경우**
    
    1. **실시간으로 데이터를 지속적으로 처리해야 하는 경우**:
    광고 클릭 데이터를 실시간으로 수집/집계하는 Ad Click Aggregator 시스템을 예로 들 수 있습니다.
    Kafka를 활용하면 **실시간으로 수집된 클릭 데이터를 빠르게 분석하고 광고주에게 즉시 피드백을 제공**할 수 있습니다.
    
    2. **여러 consumer가 동시에 메시지를 처리해야 하는 경우**:
    Youtube live 댓글 시스템 같은 실시간 방송 플랫폼에서는 댓글을 여러 consumer에게 동시에 전달해야 합니다.
    Kafka를 pub/sub system으로 활용하면 **여러 consumer가 동일한 메시지를 소비할 수 있도록 보장**할 수 있습니다.

#### 단일 브로커의 성능 한계
Kafka를 이용한 설계를 할 때는 먼저 단일 Kafka 브로커의 한계를 이해하는 것이 중요합니다.
**예상되는 메시지 처리량(throughput)** 과 **메시지 크기**를 잘 고려하여 확장이 필요한지에 대한 여부를 판단해야 합니다.

Kafka 메시지 크기에는 **hard limit이 없지만** 설정 파일에서 `message.max.bytes`를 통해 조정할 수 있습니다.
그러나 최적의 성능을 위해선 **메시지 크기를 1MB 이하로 유지**하는 것이 권장됩니다.
메시지가 작을수록 메모리 부담이 줄어들고 네트워크 활용이 최적화되기 때문입니다.

또한, Kafka는 데이터베이스가 아니며 대형 파일 저장용 시스템도 아니라는 점을 명심해야 합니다.
**메시지는 빠르게 처리될 수 있어야 하고 큰 데이터를 직접 저장하는 것은 비효율적**입니다.

예를 들어 Youtube같은 동영상 플랫폼을 설계할 때 업로드된 동영상을 Kafka에 저장하는 것이 아니라 S3 같은 분산 파일 시스템에 저장하고, Kafka 메시지에는 **해당 파일의 위치만 저장**하는 것이 올바른 접근법입니다.

좋은 하드웨어 환경에서는 단일 브로커가 약 **1TB의 데이터를 저장**하고 **최대 100만개의 메시지를 초당 처리**할 수 있습니다.
다만, 이는 메시지 크기와 하드웨어 사양에 따라 다를 수 있고 일반적인 개략적 추정치입니다.
만약 Kafka의 처리량이 이 범위를 넘지 않는다면 확장을 고려할 필요가 없을 수도 있습니다.
    
#### 확장 전략
1. **수평 확장 (Horizontal scaling)**
    
    가장 단순한 방법은 **Kafka 클러스터에 더 많은 브로커를 추가**하는 것입니다.
    브로커를 추가하면 로드가 분산되며 장애 내성이 향상됩니다.
    
    그러나 브로커를 추가하는 것만으로는 확장이 되지 않는데, **토픽의 파티션 개수를 충분히 설정**해야 브로커 추가의 효과를 볼 수 있습니다.
    파티션이 충분하지 않으면 새로 추가된 브로커가 활용되지 않으므로 파티션 개수 증가가 필수입니다.
    
2. **파티셔닝 전략 (Partitioning strategy)**
    
    가장 중요한 확장 전략은 **어떻게 데이터를 파티션할 것인지 결정하는 것**입니다.
    
    Kafka는 메시지 키의 해시값을 기반으로 파티션을 결정하는데 잘못된 키 선택은 특정 파티션에 과부하(**Hot partition**)를 발생시킬 수 있습니다. 
    좋은 키를 선택하려면 트래픽이 고르게 분산될 수 있도록 설계해야 합니다.

#### Hot Partition 문제 해결 전략
1. **무작위 파티셔닝 (Random Partitioning)**
    
    키를 제공하지 않으면 Kafka는 메시지를 랜덤한 파티션으로 분배합니다.
    이 방법은 트래픽이 균등하게 분산된다는 장점이 있지만 **메시지 순서 보장이 어렵습니다.**
    메시지 순서가 중요하지 않은 경우에 사용 가능합니다.
    
2. **랜덤 솔팅 (Random Salting)**
    
    **키 값에 랜덤 값(숫자, Timestamp 등)을 추가**하여 분산을 유도하는 기법입니다.
    예를 들어, 광고 클릭 로그를 `ad_id` 기반으로 파티셔닝하면 특정 인기 광고에 트래픽이 집중될 가능성이 있습니다.
    
    여기서 `ad_id + random_salt`를 사용해서 여러 파티션에 트래픽을 분산할 수 있습니다.
    단, **consumer에서 데이터를 집계하는 로직이 복잡**해질 수 있습니다.
    
3. **복합 키 (Compound Key) 사용**
  
    단일 `ad_id` 대신 `ad_id + geolocation`, `ad_id + user_id` 등 복합 키를 사용하여 트래픽을 분산할 수 있습니다.
   
4. **백 프레셔 (Back Pressure) 적용**
    
    과부하가 발생하면 **producer가 메시지를 생성하는 속도를 늦추도록** 조정할 수도 있습니다.
    
#### 성능 최적화

Kafka를 이벤트 스트림으로 사용할 경우 성능 최적화가 중요해집니다.

이 때, **배치 전송**과 **메시지 압축** 등과 같은 기법을 사용할 수 있습니다.

배치 전송은 producer가 메시지를 개별적으로 전송하는 대신 일정량을 모아서 한 번에 전송하는 방법입니다.

또한, KafKa는 GZIP, Snappy, LZ4 등의 압축 알고리즘을 지원하며 압축을 활성화하면 네트워크 전송 속도를 높이고 저장 공간을 절약할 수 있습니다.

## 메시지 브로커 (Message Broker)
메시지 브로커의 주요 목적은 **메시지를 안정적으로 전송하고 각 시스템이 독립적으로 작동**할 수 있도록 하는 것입니다.

메시지 브로커는 메시지를 **Queue나 Topic과 같은 구조에 저장**하고, consumer가 준비되면 해당 메시지를 전달하여 순차적 또는 병렬적으로 처리할 수 있게 합니다.

예를 들어, 사용자가 주문을 완료하면 메시지 브로커는 이 주문 데이터를 결제 처리 시스템에 전달하고, 결제가 완료된 후 다시 주문 처리 시스템에 결과를 전달하는 과정을 중개합니다.

이벤트 브로커가 도서관의 사서와 같았다면 메시지 브로커는 **우편 배달 시스템**과 비슷하다고 볼 수 있습니다.

편지를 보내는 사람이 직접 수취인에게 전달하는 대신 우체국에 맡기는 것처럼 메시지 브로커는 발신자로부터 메시지를 받아 중간에서 필요한 곳으로 전달합니다.

### RabbitMQ
RabbitMQ는 전통적인 메시지 브로커의 대표적인 예입니다.

RabbitMQ에서는 **메시지가 큐에 저장되고, consumer가 해당 큐에서 하나씩 메시지를 가져와 처리하는 방식**으로 동작합니다.

예를 들어 전자상거래 시스템에서 주문이 들어오면 주문 처리 요청 메시지가 RabbitMQ 큐에 저장되고, 주문 처리 서비스가 이 큐에서 메시지를 하나씩 꺼내 처리합니다.

RabbitMQ의 **라우팅 기능**을 이용하면 특정 조건이나 주제에 따라 메시지를 다양한 큐로 분배할 수 있어 시스템 간의 통신을 보다 세밀하게 조절할 수 있습니다.

#### 동작 원리
RabbitMQ의 기본 구성 요소는 크게 **producer, consumer, exchange, queue, binding**으로 구분할 수 있습니다.

**Producer**는 애플리케이션에서 **메시지를 생성하고 RabbitMQ에 전달**하는 역할을 합니다.
이때 메시지를 직접 queue에 넣는 것이 아니라, 먼저 **exchange로 메시지를 전송**합니다.

**Exchang**e는 들어오는 **메시지를 어떻게 queue로 라우팅할 것인지 결정**하는 중추적인 역할을 합니다.
Exchange엔 여러 종류가 있는데, 대표적으로 **direct, topic, fanout, headers** exchange가 있습니다.
각 exchange는 routing key나 바인딩 조건에 따라 메시지를 적절한 queue로 분배합니다.

**Queue**는 **실제로 메시지가 저장되는 공간**입니다.
메시지는 저장된 후, 준비된 consumer에게 전달되어 처리됩니다.

RabbitMQ는 메세지의 신뢰성과 안정성 보장을 위해 큐에 저장된 메시지에 대해 **persistence 옵션을 제공**하며, 
consumer가 메시지를 받아 처리한 후에는 메시지에 대한 **ACK을 받아야 메시지를 삭제**합니다.
이 과정은 메시지 유실이나 중복 처리 방지에 중요한 역할을 합니다.

**Binding**은 exchange와 queue 사이의 **연결 규칙을 정의**합니다.
Binding을 통해 특정 routing key나 패턴에 맞는 메시지가 어떤 queue로 전달될지 결정되므로, 메시지 흐름을 세밀하게 정의할 수 있습니다.

**Consumer**는 큐에 저장된 **메시지를 받아 처리**하는 역할을 합니다.
여러 consumer가 하나의 큐를 구독할 경우, RabbitMQ는 메시지를 **라운드 로빈 방식** 등으로 분배하여 각 consumer가 메시지를 균등하게 처리할 수 있도록 지원합니다.

Consumer가 메시지를 처리하고 난 후 ACK을 보내야하는데, 만약 메시지 처리에 실패하면 RabbitMQ는 해당 메시지를 **재전달하거나 DLX 또는 다른 큐로 라우팅** 할 수 있습니다.


## 차이점
이벤트 브로커는 **"어떤 일이 발생했다"는 사실 자체를 전파**하는 데 중점을 둡니다. 예를 들어 온라인 쇼핑몰에서 사용자가 결제를 완료했을 때 그 사건을 기록하고 여러 시스템에 동시에 알리는 역할을 할 수 있습니다.

반면, 메시지 브로커는 **특정 작업이나 요청을 안전하게 전달**하는 데 집중합니다.
예를 들어, 주문 처리를 위해 결제 요청을 보내거나 작업 큐에 저장된 작업을 하나씩 처리하는 시스템에서 메시지 브로커는 메시지를 큐잉하여 전달하고, 재시도나 배달 보증 등의 기능을 통해 데이터의 신뢰성을 보장합니다.

또한 이벤트 브로커는 이벤트 자체를 **지속적으로 기록하고 저장**하여 나중에 재처리나 분석에 활용할 수 있는 반면, 메시지 브로커는 일반적으로 메시지를 즉시 처리하는 **단기적인 데이터 전달**에 집중합니다.

이처럼 이벤트 브로커는 주로 **시스템의 상태 변화나 사건 발생의 "기록"** 을 다루고, 메시지 브로커는 **특정 작업의 "수행"** 과 관련된 데이터를 다루는 데 초점을 맞춥니다.

Kafka와 RabbitMQ 사용 사례를 비교하자면 Kafka는 **높은 처리량, 내구성, 재처리 기능** 등이 중요한 이벤트 스트리밍 환경에, RabbitMQ는 **복잡한 라우팅, 메세지 우선 순위, 큐 기반의 작업 분산 처리**와 같은 요구 사항이 있을 때 효과적인 선택이 됩니다.

## References
https://medium.com/riskified-technology/message-broker-vs-event-broker-when-to-use-each-one-of-them-15597320a8ba#:~:text=I%20would%20like%20to%20discuss,have%20a%20working%20experience%20with.
https://kafka.apache.org/uses
https://www.cloudamqp.com/blog/rabbitmq-use-cases-explaining-message-queues-and-when-to-use-them.html
https://www.youtube.com/watch?v=DU8o-OTeoCc&ab_channel=HelloInterview-SWEInterviewPreparation
https://medium.com/riskified-technology/message-broker-vs-event-broker-when-to-use-each-one-of-them-15597320a8ba
4:T2792,
## 개요
대규모 데이터 파이프라인을 운영하다보면 **병목 현상**을 자주 목격하게 됩니다. 이 때, 마이크로서비스가 실행 중인 컨테이너들을 수평적으로 확장하는 것도 중요하지만, 때로는 컨테이너 확장만으로는 해결되지 않는 문제들도 있습니다.

예를 들어, 특정 서비스에서 복잡한 연산 때문에 한 개의 메시지를 처리하는 데 시간이 너무 오래 걸린다면, 멀티 프로세싱 기법을 도입하여 문제를 해결할 수 있습니다. 또한, 한 서비스가 다른 서비스의 네트워크 응답을 기다려야 하는 상황에서는, 멀티 스레딩을 활용하여 대기 시간 동안 다른 작업을 병행할 수 있습니다.

이 글에서는 멀티 프로세싱과 멀티 스레딩의 차이가 무엇인지, 그리고 이 방법들을 파이썬에서 어떻게 사용할 수 있을지 알아보도록 하겠습니다.

## 멀티 프로세싱
먼저, 프로세스의 개념에 대해서 알아보겠습니다.

**프로세스**: **컴퓨터에서 실행 중인 하나의 프로그램**이라고 생각하면 됩니다. 예를 들어, 웹 브라우저, 미디어 플레이어 등이 각각 하나의 프로세스입니다.

각 프로세스는 운영체제로부터 독립된 메모리 공간(힙, 스택 등)과 자원을 할당 받고, 한 프로세스에 문제가 발생해도 다른 프로세스에는 영향을 주지 않습니다.

CPU 코어를 활용해 위와 같은 여러 개의 프로세스들을 병렬로 실행할 수 있으며, 프로세스 간 통신은 **IPC**(Inter-Process Communication)을 사용합니다.
예를 들어, 한 컴퓨터에서 웹 브라우저와 미디어 플레이어를 동시에 실행하는 경우, 두 개의 독립된 프로세스가 작동합니다.  

아래는 Python에서 multiprocessing을 구현할 수 있는 간단한 예제입니다.
```python
from multiprocessing import Process
import time

def process_file(file_name):
    print(f"[프로세스] {file_name} 처리 시작")
    # 실제 파일 처리는 생략하고, 2초간 대기합니다.
    time.sleep(2)
    print(f"[프로세스] {file_name} 처리 완료")

def main():
    files = ['file1.csv', 'file2.csv']
    processes = []

    # 각 파일에 대해 별도의 프로세스를 생성합니다.
    for file in files:
        p = Process(target=process_file, args=(file,))
        processes.append(p)
        p.start()  # 각 프로세스 시작

    # 모든 프로세스가 끝날 때까지 대기합니다.
    for p in processes:
        p.join()

    print("모든 프로세스 작업 완료")

if __name__ == "__main__":
    main()
```
#### 동시에 실행할 수 있는 프로세스의 수
그럼, **동시에 실행되는 프로세스의 수**는 어떻게 결정하는 것이 좋을까요?


보통 **CPU bound** 작업일 경우, 일반적으로 **실행할 프로세스의 수를 CPU 코어 수와 동일**하게 맞추는 것이 좋습니다. 예를 들어, 8코어 시스템에서는 8개의 프로세스를 동시에 실행하면 각 프로세스가 별도의 코어에서 동작하며 최적의 성능을 낼 수 있습니다.

만약 작업이 **I/O bound**일 경우, CPU 사용률이 낮으므로 **CPU 코어 수보다 더 많은 프로세스**를 실행해도 문제가 없을 수 있습니다. 하지만 동시에 실행되는 프로세스가 많아지면, 각 프로세스가 사용하는 메모리와 자원에 대한 부담이 커지기 때문에 시스템의 **메모리 용량**과 **자원 사용량**을 고려하여 정해야 합니다.

#### IPC (Inter-Process Communication)
IPC, 프로세스 간 통신은 서로 독립적으로 실행되는 여러 프로세스들이 데이터를 주고받을 수 있도록 해주는 메커니즘입니다.

**IPC 방법들**
1. **Pipe와 FIFO (Named Pipe)**  
    **파이프**: 두 프로세스 간에 데이터를 일방향으로 전달하는 통신 채널입니다. 보통 부모/자식 프로세스 사이에서 사용됩니다.  
    **FIFO (Named Pipe)**: 이름이 있는 파이프로, 관련 없는 독립적인 프로세스들 간에도 통신할 수 있습니다.
2. **메시지 큐**  
  여러 프로세스가 데이터를 메시지 단위로 보내고 받을 수 있는 큐입니다.
  메시지는 순서대로 저장되고, 한 프로세스가 메시지를 보내면 다른 프로세스가 이를 꺼내어 처리합니다.
3. **공유 메모리**  
  여러 프로세스가 같은 메모리 영역에 접근할 수 있게 하는 방법입니다.
  접근 속도가 매우 빠르지만, race condition(동기화 문제)를 해결하기 위한 추가 메커니즘이 필요합니다.
4. **소켓**  
  네트워크를 통해 프로세스 간 통신을 할 수 있고, 동일 컴퓨터 내의 프로세스 뿐만 아니라 다른 컴퓨터의 프로세스와도 통신할 수 있습니다.

파이썬에서는 사용의 편의성과 안정성 면에서 메시지 큐(`multiprocessing.Queue`)가 가장 널리 사용됩니다. 

#### 멀티 프로세싱 풀 (Pool)
멀티 프로세싱 풀은 미리 정해진 수의 프로세스(작업자)를 생성해두고, 이를 통해 작업을 분산하여 실행하는 방식입니다. 이렇게 하면 매번 새로운 프로세스를 생성하는 오버헤드를 줄일 수 있어, 다수의 작업을 효율적으로 처리할 수 있습니다.

**작동 원리**
1. 풀은 시작할 때 **지정한 수의 프로세스를 미리 생성**합니다. 예를 들어, **CPU 코어 수나 작업량**에 맞게 4개, 8개 등의 프로세스를 만들어 둡니다.
2. 여러 작업을 풀에 제출하면, 풀에 있는 프로세스들이 작업을 나눠서 실행합니다. **작업이 끝난 프로세스는 다시 대기** 상태로 돌아가 다음 작업을 처리할 준비를 합니다.
3. 한 번 생성된 프로세스는 여러 작업에 대해 **재사용**됩니다.

## 멀티 스레딩
**스레드**: 스레드는 하나의 프로세스 내에서 **실제로 작업을 수행하는 작은 실행 단위**입니다. 즉, 하나의 프로세스 안에서 여러 가지 일을 동시에 진행할 수 있도록 도와주는 역할을 합니다. 예를 들면, 크롬(프로세스)에서 여러 개의 탭마다 웹사이트를 불러오는 작업은 멀티 스레딩으로 이루어집니다.

같은 프로세스 내의 스레드들은 **모두 동일한 메모리(데이터, 변수 등)를 공유**하며, 스레드들끼리 데이터를 쉽게 주고받을 수 있습니다. 하지만, 동시에 **같은 데이터에 접근하다 보면 서로 충돌**할 수도 있어 주의해야 합니다.

#### Python에서 멀티 스레딩과 GIL (Global Interpreter Lock)
Python의 가장 널리 쓰이는 interpreter인 CPython에는 **GIL**이라는 메커니즘이 있습니다. GIL은 한 번에 **오직 하나의 스레드**만 Python 코드를 실행하도록 하는 잠금장치입니다.


Python은 **Garbage collection**을 사용해 메모리를 자동으로 관리합니다. GIL은 **여러 스레드가 동시에 메모리를 변경하는 일을 방지**하고, 프로그램이 복잡해져도 메모리 관리가 안전하게 이루어지도록 도와줍니다.

하지만, GIL으로 인해 여러 스레드를 사용해도 한 시점에 오직 하나의 스레드만이 실제로 코드를 실행합니다. 따라서, 복잡한 계산이나 **CPU를 많이 사용하는 작업(CPU bound)은 여러 스레드로 병렬 처리했을 때 기대만큼의 성능 향상을 얻기 어렵습니다**.

반면에, 파일 입출력, 네트워크 통신 등과 같이 **기다리는 시간이 상대적으로 많은 작업**(I/O bound)들에서는 **스레드가 대기 상태로 있을 때 다른 스레드가 실행**될 수 있으므로 GIL의 영향이 덜합니다. 이 경우, CPU는 한 스레드에만 국한되지 않고 다른 스레드로 전환되어 작업을 진행합니다.

예를 들면, 파일을 읽거나 쓸 때, CPU는 집중적으로 계산하는 것이 아니라, 외부 장치(디스크 등)와 데이터를 주고받느라 기다리는 시간이 발생합니다. 이 때 스레드가 **대기 상태**로 들어가면서 GIL을 해제하게 됩니다. 이로 인해 다른 스레드들이 CPU를 사용할 수 있게 되어, 여러 파일을 동시에 읽거나 쓸 수 있습니다.
  
엄밀히 말하면 CPU가 여러 작업을 번갈아 실행하기 때문에, 동시에 실행되는 것처럼 보이지만 실제로는 **컨텍스트 스위칭**이 계속 발생하며 작업을 처리합니다.

CPython에서는 GIL이 interpreter의 핵심 설계 요소이기 때문에 Python 자체에서 **GIL을 완전히 해제하거나 제거하는 것은 불가능**합니다.

#### 동시에 실행할 수 있는 스레드의 수
멀티 스레딩에서 **동시에 실행할 수 있는 스레드의 수**는 작업의 종류에 따라 달라집니다.

**CPU 집약적인 작업**의 경우, CPython의 GIL 때문에 한 번에 한 스레드만 Python 바이트코드를 실행합니다. 따라서, CPU 코어 수에 맞춰 스레드를 구성하는 것이 좋습니다. 이렇게 하면 불필요한 스레드 전환(컨텍스트 스위칭) 오버헤드를 줄일 수 있습니다.

반면, **I/O 바운드 작업**처럼 파일 입출력이나 네트워크 요청과 같이 대기 시간이 긴 작업에서는, CPU 사용이 크게 발생하지 않으므로 CPU 코어 수보다 훨씬 많은 스레드를 사용할 수 있습니다. 예를 들어, 네트워크 요청이 많은 애플리케이션에서는 수십 개 이상의 스레드를 사용해도 오히려 성능 향상을 기대할 수 있습니다.

#### 멀티 스레딩에서의 풀
멀티 프로세싱에서 풀을 사용하는 것과 같이, 스레딩에서도 풀 개념을 적용할 수 있습니다. Python에서는 주로 `cuncurrent.futures.ThreadPoolExecutor`를 사용하여 풀을 구성합니다. 이를 통해 **미리 정해진 수의 스레드를 생성하고, 작업을 해당 스레드들에 분산**시켜 실행할 수 있습니다.
5:T16f3,
## 가비지 컬렉션 (Garbage Collection)
Python의 가비지 컬렉션은 메모리 관리를 자동으로 수행하는 메커니즘입니다. 이 메커니즘은 크게 두 가지 방법을 사용합니다.
### 1. 참조 카운팅 (Reference Counting)
어떤 물건을 여러 사람이 공유하고 있을 때 몇 명이 그 물건을 사용 중인지 숫자로 세어보는 것과 비슷합니다.

**작동 원리**
1. Python에서 어떤 데이터를 저장하는 객체(list, dictionary, etc)가 만들어지면 이 객체를 사용하고 있는 변수가 몇 개인지 기록합니다.
2. 만약 변수가 그 객체를 사용하면 숫자가 1 증가하고, 더 이상 사용하지 않게 되면 숫자가 1 감소합니다.
3. 이 **참조 카운트가 0**이 되면 그 객체는 아무도 사용하지 않는 것으로 판단되어 청소부가 그 객체를 메모리에서 제거합니다.
```python
a = [1, 2, 3]    # 리스트 객체 생성 (참조 카운트 증가)

b = a            # b가 a를 참조 (참조 카운트 증가)

del b            # b 삭제 (참조 카운트 감소)
```
### 2. 순환 가비지 컬렉터 (Cyclic Garbage Collector)
때로는 두 개 이상의 객체가 서로를 참조하면서 **서로를 잡아먹는** 상황이 생깁니다. 예를 들어, A가 B를, B가 A를 참조하고 있으면 외부에서는 둘 다 사용하지 않더라도 참조 카운트가 0이 되지 않습니다.

```python
class A:
    def __init__(self):
        self.other = None

# 두 객체 생성 후 서로를 참조하게 만듭니다.
a = A()
b = A()
a.other = b  # a는 b를 참조
b.other = a  # b는 a를 참조

# 외부 참조 제거
a = None
b = None

# 이제 두 객체는 외부에서 접근할 수 없지만 서로를 참조하므로 참조 카운트는 0이 되지 않습니다.
```
Python은 이러한 순환 참조 문제를 해결하기 위해 정기적으로 청소를 하는 **순환 가비지 컬렉터** 시스템을 사용합니다. 이 시스템은 주기적으로 객체 그래프를 탐색하여, **외부에서는 접근할 수 없지만 내부적으로 서로 참조하는 객체들**을 찾아냅니다.
#### 세대 개념
객체는 **얼마나 오래 살아남았느냐**에 따라 몇 개의 세대로 분류됩니다. 최근에 생성된 객체는 0세대, 조금 오래된 객체는 1세대, 가장 오래된 객체는 2세대로 분류됩니다.

이렇게 세대를 구분하는 이유는 대부분의 객체가 짧은 수명을 가지고 있고, 오래 살아남은 객체는 변경 가능성이 낮다고 판단하여 더 자주 검사하지 않음으로써 가비지 컬렉션 오버헤드를 줄이기 위함입니다.

### 고려 사항
한 객체를 참조하는 수가 많을 경우 **참조 카운트를 업데이트하는 오버헤드**가 발생할 수 있습니다. 객체에 대한 참조를 추가하거나 제거할 때마다 메모리 내에서 해당 값을 읽고, 수정하고, 다시 저장하는 작업이 필요합니다. 
이런 연산이 반복되면 단순히 그 객체를 사용하거나 해제하는 비용 외에도 참조 카운트 업데이트에 따른 부가적인 CPU 연산 비용이 누적될 수 있습니다.

예를 들어, 수천 개의 복잡한 데이터 구조에서 한 객체가 여러 부분에서 참조될 경우, 참조 카운트 관리에 드는 시간이 전체 성능에 영향을 줄 수 있습니다.

OS는 새로운 메모리 블록을 할당하거나, 사용이 끝난 메모리 블록을 해제할 때 **시스템 호출**을 사용합니다. 이러한 호출은 사용자 코드에서 직접 호출하는 연산보다 훨씬 느리고 오버헤드가 큽니다.


또한, 메모리 할당/해제를 반복하면 메모리 내부에 작고 산발적인 빈 공간들이 생기는데, 이를 **메모리 단편화**(Fragmentation)라고 합니다. 단편화가 심해지면 **메모리 사용 효율이 떨어지고 큰 연속된 메모리 공간을 할당받기 어려워집니다**.


이와 같이 메모리 할당 및 해제는 비용이 크므로 Python은 **메모리 풀**과 같은 기법을 통해 메모리를 재활용합니다. 메모리 풀은 **미리 일정 크기의 메모리 블록들을 할당해 놓고 필요할 때마다 이 블록들을 재활용**하는 방식입니다.

예를 들어, CPython은 짧은 문자열이나 작은 리스트와 같은 소형 객체를 위한 전용 메모리 할당기를 사용합니다. 이 풀은 **한 번에 시스템으로부터 큰 메모리 블록**을 받아 내부에서 작고 고정된 크기의 블록들로 나눈 후, 객체 생성 시 이 블록들을 할당합니다.

이 방식을 사용하면 새로운 객체를 만들 때마다 OS에 매번 메모리 할당 요청을 보내지 않아도 되므로 **매우 빠르게 메모리를 할당**할 수 있습니다. 객체가 해제되면 해당 메모리 블록은 즉시 운영체제에 반환되지 않고 **메모리 풀에 다시 저장**되어 다음에 **재사용**됩니다.


만약 현재 **할당된 메모리 풀이 모두 사용중**이라면:
1. Python의 메모리 할당기는 OS에 추가 메모리를 요청합니다.
2. 운영체제에서 추가 메모리를 제공하면 메모리 풀은 확장되어 이후에 새로운 객체 할당에 사용됩니다.
3. 만약 운영체제에서 더 이상 메모리를 제공할 수 없다면 Python은 더 이상 객체를 위한 메모리를 할당할 수 없게 됩니다. (`MemoryError` Exception 발생)

메모리 풀 확장 시 여러 프로세스가 동시에 메모리를 요구할 수 있고 이런 상황에서는 경쟁이 발생할 수도 있습니다.

## 마무리
오늘은 파이썬에서 가비지 컬렉션이 어떻게 동작하는지 알아보았습니다. 다음엔 네트워크 관련 게시글을 올려보도록 하겠습니다. 감사합니다 :)
7:["category","cs","d"]
0:["3oLDgray45f79msMW0SnU",[[["",{"children":["blog",{"children":[["category","cs","d"],{"children":["__PAGE__?{\"category\":\"cs\"}",{}]}]}]},"$undefined","$undefined",true],["",{"children":["blog",{"children":[["category","cs","d"],{"children":["__PAGE__",{},[["$L1",["$","$L2",null,{"category":"cs","filteredPosts":[{"slug":"cs/event-broker-vs-message-broker","categorySlug":"cs","title":{"ko":"이벤트 브로커와 메시지 브로커","en":"Event Broker and Message Broker"},"date":"2025-02-23 18:11","category":{"ko":"컴퓨터 공학","en":"Computer Science"},"description":{"ko":"이벤트 브로커와 메시지 브로커의 차이, RabbitMQ와 Kafka의 동작 원리","en":"Difference between event broker and message broker, how RabbitMQ and Kafka work"},"content":"$3"},{"slug":"cs/multiprocessing-and-multithreading-in-python","categorySlug":"cs","title":{"ko":"파이썬에서의 멀티 프로세싱과 멀티 스레딩","en":"Multiprocessing and Multithreading in Python"},"date":"2025-02-21 00:00","category":{"ko":"컴퓨터 공학","en":"Computer Science"},"description":{"ko":"멀티 프로세싱과 멀티 스레딩의 파이썬에서의 동작 원리","en":"How Multiprocessing and Multithreading Work in Python"},"content":"$4"},{"slug":"cs/garbage-collection-in-python","categorySlug":"cs","title":{"ko":"파이썬에서의 가비지 컬렉션","en":"Garbage Collection in Python"},"date":"2025-02-21 00:00","category":{"ko":"컴퓨터 공학","en":"Computer Science"},"description":{"ko":"가비지 컬렉션의 파이썬에서의 동작 원리","en":"How Garbage Collection Works in Python"},"content":"$5"}]}],null],null],null]},[null,["$","$L6",null,{"parallelRouterKey":"children","segmentPath":["children","blog","children","$7","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined"}]],null]},[[null,["$","$L9",null,{"children":["$","$L6",null,{"parallelRouterKey":"children","segmentPath":["children","blog","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined"}],"params":{}}]],null],null]},[[[["$","link","0",{"rel":"stylesheet","href":"/julie/_next/static/css/2688adaac3b51e6f.css","precedence":"next","crossOrigin":"$undefined"}],["$","link","1",{"rel":"stylesheet","href":"/julie/_next/static/css/e680cef9016abb97.css","precedence":"next","crossOrigin":"$undefined"}]],["$","html",null,{"lang":"ko","suppressHydrationWarning":true,"children":["$","body",null,{"className":"__className_29e2ff","children":["$","$La",null,{"attribute":"class","defaultTheme":"system","enableSystem":true,"disableTransitionOnChange":true,"children":["$","$Lb",null,{"children":[["$","$Lc",null,{}],["$","$L6",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":"404"}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],"notFoundStyles":[]}]]}]}]}]}]],null],null],["$Ld",null]]]]
d:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"Julie Lee's Portfolio"}],["$","meta","3",{"name":"description","content":"Welcome to Julie's portfolio page."}],["$","meta","4",{"name":"next-size-adjust"}]]
1:null
