2:I[3422,["851","static/chunks/851-4b7230f426f3d0c3.js","648","static/chunks/648-f6f3afee71b2d583.js","636","static/chunks/636-65bb31d056e95ffd.js","254","static/chunks/app/blog/%5Bcategory%5D/page-8636faf3adaa3fd9.js"],"default"]
6:I[4707,[],""]
8:I[6423,[],""]
9:I[3483,["648","static/chunks/648-f6f3afee71b2d583.js","768","static/chunks/app/blog/layout-3825e9c62cfb97f3.js"],"default",1]
a:I[5495,["851","static/chunks/851-4b7230f426f3d0c3.js","648","static/chunks/648-f6f3afee71b2d583.js","185","static/chunks/app/layout-396cfab0aaba2929.js"],"ThemeProvider"]
b:I[4491,["851","static/chunks/851-4b7230f426f3d0c3.js","648","static/chunks/648-f6f3afee71b2d583.js","185","static/chunks/app/layout-396cfab0aaba2929.js"],"LanguageProvider"]
c:I[1890,["851","static/chunks/851-4b7230f426f3d0c3.js","648","static/chunks/648-f6f3afee71b2d583.js","185","static/chunks/app/layout-396cfab0aaba2929.js"],"Header"]
3:T2792,
## 개요
대규모 데이터 파이프라인을 운영하다보면 **병목 현상**을 자주 목격하게 됩니다. 이 때, 마이크로서비스가 실행 중인 컨테이너들을 수평적으로 확장하는 것도 중요하지만, 때로는 컨테이너 확장만으로는 해결되지 않는 문제들도 있습니다.

예를 들어, 특정 서비스에서 복잡한 연산 때문에 한 개의 메시지를 처리하는 데 시간이 너무 오래 걸린다면, 멀티 프로세싱 기법을 도입하여 문제를 해결할 수 있습니다. 또한, 한 서비스가 다른 서비스의 네트워크 응답을 기다려야 하는 상황에서는, 멀티 스레딩을 활용하여 대기 시간 동안 다른 작업을 병행할 수 있습니다.

이 글에서는 멀티 프로세싱과 멀티 스레딩의 차이가 무엇인지, 그리고 이 방법들을 파이썬에서 어떻게 사용할 수 있을지 알아보도록 하겠습니다.

## 멀티 프로세싱
먼저, 프로세스의 개념에 대해서 알아보겠습니다.

**프로세스**: **컴퓨터에서 실행 중인 하나의 프로그램**이라고 생각하면 됩니다. 예를 들어, 웹 브라우저, 미디어 플레이어 등이 각각 하나의 프로세스입니다.

각 프로세스는 운영체제로부터 독립된 메모리 공간(힙, 스택 등)과 자원을 할당 받고, 한 프로세스에 문제가 발생해도 다른 프로세스에는 영향을 주지 않습니다.

CPU 코어를 활용해 위와 같은 여러 개의 프로세스들을 병렬로 실행할 수 있으며, 프로세스 간 통신은 **IPC**(Inter-Process Communication)을 사용합니다.
예를 들어, 한 컴퓨터에서 웹 브라우저와 미디어 플레이어를 동시에 실행하는 경우, 두 개의 독립된 프로세스가 작동합니다.  

아래는 Python에서 multiprocessing을 구현할 수 있는 간단한 예제입니다.
```python
from multiprocessing import Process
import time

def process_file(file_name):
    print(f"[프로세스] {file_name} 처리 시작")
    # 실제 파일 처리는 생략하고, 2초간 대기합니다.
    time.sleep(2)
    print(f"[프로세스] {file_name} 처리 완료")

def main():
    files = ['file1.csv', 'file2.csv']
    processes = []

    # 각 파일에 대해 별도의 프로세스를 생성합니다.
    for file in files:
        p = Process(target=process_file, args=(file,))
        processes.append(p)
        p.start()  # 각 프로세스 시작

    # 모든 프로세스가 끝날 때까지 대기합니다.
    for p in processes:
        p.join()

    print("모든 프로세스 작업 완료")

if __name__ == "__main__":
    main()
```
#### 동시에 실행할 수 있는 프로세스의 수
그럼, **동시에 실행되는 프로세스의 수**는 어떻게 결정하는 것이 좋을까요?


보통 **CPU bound** 작업일 경우, 일반적으로 **실행할 프로세스의 수를 CPU 코어 수와 동일**하게 맞추는 것이 좋습니다. 예를 들어, 8코어 시스템에서는 8개의 프로세스를 동시에 실행하면 각 프로세스가 별도의 코어에서 동작하며 최적의 성능을 낼 수 있습니다.

만약 작업이 **I/O bound**일 경우, CPU 사용률이 낮으므로 **CPU 코어 수보다 더 많은 프로세스**를 실행해도 문제가 없을 수 있습니다. 하지만 동시에 실행되는 프로세스가 많아지면, 각 프로세스가 사용하는 메모리와 자원에 대한 부담이 커지기 때문에 시스템의 **메모리 용량**과 **자원 사용량**을 고려하여 정해야 합니다.

#### IPC (Inter-Process Communication)
IPC, 프로세스 간 통신은 서로 독립적으로 실행되는 여러 프로세스들이 데이터를 주고받을 수 있도록 해주는 메커니즘입니다.

**IPC 방법들**
1. **Pipe와 FIFO (Named Pipe)**  
    **파이프**: 두 프로세스 간에 데이터를 일방향으로 전달하는 통신 채널입니다. 보통 부모/자식 프로세스 사이에서 사용됩니다.  
    **FIFO (Named Pipe)**: 이름이 있는 파이프로, 관련 없는 독립적인 프로세스들 간에도 통신할 수 있습니다.
2. **메시지 큐**  
  여러 프로세스가 데이터를 메시지 단위로 보내고 받을 수 있는 큐입니다.
  메시지는 순서대로 저장되고, 한 프로세스가 메시지를 보내면 다른 프로세스가 이를 꺼내어 처리합니다.
3. **공유 메모리**  
  여러 프로세스가 같은 메모리 영역에 접근할 수 있게 하는 방법입니다.
  접근 속도가 매우 빠르지만, race condition(동기화 문제)를 해결하기 위한 추가 메커니즘이 필요합니다.
4. **소켓**  
  네트워크를 통해 프로세스 간 통신을 할 수 있고, 동일 컴퓨터 내의 프로세스 뿐만 아니라 다른 컴퓨터의 프로세스와도 통신할 수 있습니다.

파이썬에서는 사용의 편의성과 안정성 면에서 메시지 큐(`multiprocessing.Queue`)가 가장 널리 사용됩니다. 

#### 멀티 프로세싱 풀 (Pool)
멀티 프로세싱 풀은 미리 정해진 수의 프로세스(작업자)를 생성해두고, 이를 통해 작업을 분산하여 실행하는 방식입니다. 이렇게 하면 매번 새로운 프로세스를 생성하는 오버헤드를 줄일 수 있어, 다수의 작업을 효율적으로 처리할 수 있습니다.

**작동 원리**
1. 풀은 시작할 때 **지정한 수의 프로세스를 미리 생성**합니다. 예를 들어, **CPU 코어 수나 작업량**에 맞게 4개, 8개 등의 프로세스를 만들어 둡니다.
2. 여러 작업을 풀에 제출하면, 풀에 있는 프로세스들이 작업을 나눠서 실행합니다. **작업이 끝난 프로세스는 다시 대기** 상태로 돌아가 다음 작업을 처리할 준비를 합니다.
3. 한 번 생성된 프로세스는 여러 작업에 대해 **재사용**됩니다.

## 멀티 스레딩
**스레드**: 스레드는 하나의 프로세스 내에서 **실제로 작업을 수행하는 작은 실행 단위**입니다. 즉, 하나의 프로세스 안에서 여러 가지 일을 동시에 진행할 수 있도록 도와주는 역할을 합니다. 예를 들면, 크롬(프로세스)에서 여러 개의 탭마다 웹사이트를 불러오는 작업은 멀티 스레딩으로 이루어집니다.

같은 프로세스 내의 스레드들은 **모두 동일한 메모리(데이터, 변수 등)를 공유**하며, 스레드들끼리 데이터를 쉽게 주고받을 수 있습니다. 하지만, 동시에 **같은 데이터에 접근하다 보면 서로 충돌**할 수도 있어 주의해야 합니다.

#### Python에서 멀티 스레딩과 GIL (Global Interpreter Lock)
Python의 가장 널리 쓰이는 interpreter인 CPython에는 **GIL**이라는 메커니즘이 있습니다. GIL은 한 번에 **오직 하나의 스레드**만 Python 코드를 실행하도록 하는 잠금장치입니다.


Python은 **Garbage collection**을 사용해 메모리를 자동으로 관리합니다. GIL은 **여러 스레드가 동시에 메모리를 변경하는 일을 방지**하고, 프로그램이 복잡해져도 메모리 관리가 안전하게 이루어지도록 도와줍니다.

하지만, GIL으로 인해 여러 스레드를 사용해도 한 시점에 오직 하나의 스레드만이 실제로 코드를 실행합니다. 따라서, 복잡한 계산이나 **CPU를 많이 사용하는 작업(CPU bound)은 여러 스레드로 병렬 처리했을 때 기대만큼의 성능 향상을 얻기 어렵습니다**.

반면에, 파일 입출력, 네트워크 통신 등과 같이 **기다리는 시간이 상대적으로 많은 작업**(I/O bound)들에서는 **스레드가 대기 상태로 있을 때 다른 스레드가 실행**될 수 있으므로 GIL의 영향이 덜합니다. 이 경우, CPU는 한 스레드에만 국한되지 않고 다른 스레드로 전환되어 작업을 진행합니다.

예를 들면, 파일을 읽거나 쓸 때, CPU는 집중적으로 계산하는 것이 아니라, 외부 장치(디스크 등)와 데이터를 주고받느라 기다리는 시간이 발생합니다. 이 때 스레드가 **대기 상태**로 들어가면서 GIL을 해제하게 됩니다. 이로 인해 다른 스레드들이 CPU를 사용할 수 있게 되어, 여러 파일을 동시에 읽거나 쓸 수 있습니다.
  
엄밀히 말하면 CPU가 여러 작업을 번갈아 실행하기 때문에, 동시에 실행되는 것처럼 보이지만 실제로는 **컨텍스트 스위칭**이 계속 발생하며 작업을 처리합니다.

CPython에서는 GIL이 interpreter의 핵심 설계 요소이기 때문에 Python 자체에서 **GIL을 완전히 해제하거나 제거하는 것은 불가능**합니다.

#### 동시에 실행할 수 있는 스레드의 수
멀티 스레딩에서 **동시에 실행할 수 있는 스레드의 수**는 작업의 종류에 따라 달라집니다.

**CPU 집약적인 작업**의 경우, CPython의 GIL 때문에 한 번에 한 스레드만 Python 바이트코드를 실행합니다. 따라서, CPU 코어 수에 맞춰 스레드를 구성하는 것이 좋습니다. 이렇게 하면 불필요한 스레드 전환(컨텍스트 스위칭) 오버헤드를 줄일 수 있습니다.

반면, **I/O 바운드 작업**처럼 파일 입출력이나 네트워크 요청과 같이 대기 시간이 긴 작업에서는, CPU 사용이 크게 발생하지 않으므로 CPU 코어 수보다 훨씬 많은 스레드를 사용할 수 있습니다. 예를 들어, 네트워크 요청이 많은 애플리케이션에서는 수십 개 이상의 스레드를 사용해도 오히려 성능 향상을 기대할 수 있습니다.

#### 멀티 스레딩에서의 풀
멀티 프로세싱에서 풀을 사용하는 것과 같이, 스레딩에서도 풀 개념을 적용할 수 있습니다. Python에서는 주로 `cuncurrent.futures.ThreadPoolExecutor`를 사용하여 풀을 구성합니다. 이를 통해 **미리 정해진 수의 스레드를 생성하고, 작업을 해당 스레드들에 분산**시켜 실행할 수 있습니다.
4:T16f3,
## 가비지 컬렉션 (Garbage Collection)
Python의 가비지 컬렉션은 메모리 관리를 자동으로 수행하는 메커니즘입니다. 이 메커니즘은 크게 두 가지 방법을 사용합니다.
### 1. 참조 카운팅 (Reference Counting)
어떤 물건을 여러 사람이 공유하고 있을 때 몇 명이 그 물건을 사용 중인지 숫자로 세어보는 것과 비슷합니다.

**작동 원리**
1. Python에서 어떤 데이터를 저장하는 객체(list, dictionary, etc)가 만들어지면 이 객체를 사용하고 있는 변수가 몇 개인지 기록합니다.
2. 만약 변수가 그 객체를 사용하면 숫자가 1 증가하고, 더 이상 사용하지 않게 되면 숫자가 1 감소합니다.
3. 이 **참조 카운트가 0**이 되면 그 객체는 아무도 사용하지 않는 것으로 판단되어 청소부가 그 객체를 메모리에서 제거합니다.
```python
a = [1, 2, 3]    # 리스트 객체 생성 (참조 카운트 증가)

b = a            # b가 a를 참조 (참조 카운트 증가)

del b            # b 삭제 (참조 카운트 감소)
```
### 2. 순환 가비지 컬렉터 (Cyclic Garbage Collector)
때로는 두 개 이상의 객체가 서로를 참조하면서 **서로를 잡아먹는** 상황이 생깁니다. 예를 들어, A가 B를, B가 A를 참조하고 있으면 외부에서는 둘 다 사용하지 않더라도 참조 카운트가 0이 되지 않습니다.

```python
class A:
    def __init__(self):
        self.other = None

# 두 객체 생성 후 서로를 참조하게 만듭니다.
a = A()
b = A()
a.other = b  # a는 b를 참조
b.other = a  # b는 a를 참조

# 외부 참조 제거
a = None
b = None

# 이제 두 객체는 외부에서 접근할 수 없지만 서로를 참조하므로 참조 카운트는 0이 되지 않습니다.
```
Python은 이러한 순환 참조 문제를 해결하기 위해 정기적으로 청소를 하는 **순환 가비지 컬렉터** 시스템을 사용합니다. 이 시스템은 주기적으로 객체 그래프를 탐색하여, **외부에서는 접근할 수 없지만 내부적으로 서로 참조하는 객체들**을 찾아냅니다.
#### 세대 개념
객체는 **얼마나 오래 살아남았느냐**에 따라 몇 개의 세대로 분류됩니다. 최근에 생성된 객체는 0세대, 조금 오래된 객체는 1세대, 가장 오래된 객체는 2세대로 분류됩니다.

이렇게 세대를 구분하는 이유는 대부분의 객체가 짧은 수명을 가지고 있고, 오래 살아남은 객체는 변경 가능성이 낮다고 판단하여 더 자주 검사하지 않음으로써 가비지 컬렉션 오버헤드를 줄이기 위함입니다.

### 고려 사항
한 객체를 참조하는 수가 많을 경우 **참조 카운트를 업데이트하는 오버헤드**가 발생할 수 있습니다. 객체에 대한 참조를 추가하거나 제거할 때마다 메모리 내에서 해당 값을 읽고, 수정하고, 다시 저장하는 작업이 필요합니다. 
이런 연산이 반복되면 단순히 그 객체를 사용하거나 해제하는 비용 외에도 참조 카운트 업데이트에 따른 부가적인 CPU 연산 비용이 누적될 수 있습니다.

예를 들어, 수천 개의 복잡한 데이터 구조에서 한 객체가 여러 부분에서 참조될 경우, 참조 카운트 관리에 드는 시간이 전체 성능에 영향을 줄 수 있습니다.

OS는 새로운 메모리 블록을 할당하거나, 사용이 끝난 메모리 블록을 해제할 때 **시스템 호출**을 사용합니다. 이러한 호출은 사용자 코드에서 직접 호출하는 연산보다 훨씬 느리고 오버헤드가 큽니다.


또한, 메모리 할당/해제를 반복하면 메모리 내부에 작고 산발적인 빈 공간들이 생기는데, 이를 **메모리 단편화**(Fragmentation)라고 합니다. 단편화가 심해지면 **메모리 사용 효율이 떨어지고 큰 연속된 메모리 공간을 할당받기 어려워집니다**.


이와 같이 메모리 할당 및 해제는 비용이 크므로 Python은 **메모리 풀**과 같은 기법을 통해 메모리를 재활용합니다. 메모리 풀은 **미리 일정 크기의 메모리 블록들을 할당해 놓고 필요할 때마다 이 블록들을 재활용**하는 방식입니다.

예를 들어, CPython은 짧은 문자열이나 작은 리스트와 같은 소형 객체를 위한 전용 메모리 할당기를 사용합니다. 이 풀은 **한 번에 시스템으로부터 큰 메모리 블록**을 받아 내부에서 작고 고정된 크기의 블록들로 나눈 후, 객체 생성 시 이 블록들을 할당합니다.

이 방식을 사용하면 새로운 객체를 만들 때마다 OS에 매번 메모리 할당 요청을 보내지 않아도 되므로 **매우 빠르게 메모리를 할당**할 수 있습니다. 객체가 해제되면 해당 메모리 블록은 즉시 운영체제에 반환되지 않고 **메모리 풀에 다시 저장**되어 다음에 **재사용**됩니다.


만약 현재 **할당된 메모리 풀이 모두 사용중**이라면:
1. Python의 메모리 할당기는 OS에 추가 메모리를 요청합니다.
2. 운영체제에서 추가 메모리를 제공하면 메모리 풀은 확장되어 이후에 새로운 객체 할당에 사용됩니다.
3. 만약 운영체제에서 더 이상 메모리를 제공할 수 없다면 Python은 더 이상 객체를 위한 메모리를 할당할 수 없게 됩니다. (`MemoryError` Exception 발생)

메모리 풀 확장 시 여러 프로세스가 동시에 메모리를 요구할 수 있고 이런 상황에서는 경쟁이 발생할 수도 있습니다.

## 마무리
오늘은 파이썬에서 가비지 컬렉션이 어떻게 동작하는지 알아보았습니다. 다음엔 네트워크 관련 게시글을 올려보도록 하겠습니다. 감사합니다 :)
5:T2ede,
오늘은 이벤트 브로커와 메시지 브로커, 그리고 각각의 대표적인 예시인 Apache Kafka와 RabbitMQ에 대해 알아보겠습니다.

## 이벤트 브로커 (Event Broker)
이벤트 브로커는 **시스템 내에서 일어나는 다양한 사건이나 상태 변화를 다른 컴포넌트에 전달**하는 중개자 역할을 합니다.

예를 들어, 온라인 쇼핑몰에서는 사용자가 상품을 장바구니에 담거나 결제하는 등의 행동이 이벤트로 발생할 수 있습니다.
이러한 이벤트들은 직접적으로 다른 컴포넌트에 전달되는 것이 아니라 이벤트 브로커를 통해 전달되어 **여러 시스템이나 서비스가 동시에 반응**할 수 있도록 할 수 있습니다.

시스템의 각 부분은 이벤트 브로커를 통해 **서로 분리되어 동작**하게 되는데, 이를 통해 한 부분에서 발생한 변화가 다른 부분에 영향을 주더라도 서로 강하게 의존하지 않게 됩니다.

만일 결제 시스템에 문제가 생겨도 주문 처리나 재고 관리 시스템은 이미 발생한 이벤트를 기반으로 자신의 업무를 계속 진행할 수 있습니다.

이런 구조 덕분에 장애가 발생했을 때 **문제를 국소적으로 격리**할 수 있고 **시스템 전체의 안정성을 높일 수 있는 효과**가 있습니다. (Loose coupling)

또한, 이벤트 브로커는 발생한 이벤트 데이터를 기록하고 저장하는 기능도 제공합니다. 
예를 들어 사용자가 웹사이트에서 발생시킨 모든 행동 기록을 이벤트 브로커가 수집해 저장해 놓으면 나중에 이 데이터를 분석해 **사용자 행동 패턴을 파악**하거나 **문제 발생 시 재처리할 수 있는 기반**을 마련할 수 있습니다.

이러한 기능은 **실시간 모니터링**이나 **로그 수집**, **감사**와 같은 다양한 활용 사례에 유용하게 쓰입니다.

### Pub/Sub 모델
이벤트 브로커는 pub/sub 모델을 채택하고 있는데, 이 모델에서 이벤트를 생성하는 쪽은 **publisher**, 이벤트를 받아 처리하는 쪽은 **consumer**라고 부릅니다.

Publisher는 자신이 **생성한 이벤트를 이벤트 브로커에 전달**하고, 이벤트 브로커는 이 **이벤트를 구독하고 있는 여러 consumer들에게 동시에 전달**합니다.

예를 들어, 온라인 쇼핑몰에서 상품이 구매되면 결제 시스템, 주문 관리 시스템, 재고 관리 시스템, 심지어는 고객에게 알림을 보내는 시스템 등이 모두 이 이벤트를 받아 각각의 역할을 수행할 수 있습니다.

다른 예시를 생각해보면 이벤트 브로커는 마치 **도서관의 사서**와 같다고 볼 수 있습니다.

도서관에서 책을 요청하면 사서가 책을 찾아 여러 독자에게 전달해 주는 것처럼, 이벤트 브로커도 각 시스템의 요청이나 상태 변화를 받아 필요한 모든 곳에 전달합니다.
이 과정에서 각 시스템은 직접 서로를 호출할 필요 없이 **간접적으로 소통**할 수 있게 됩니다.

### Apache Kafka
Kafka는 이벤트 브로커의 대표적인 예시로 주로 **대용량의 실시간 데이터 스트림**을 처리하는 데 최적화되어 있습니다.

Kafka에서는 **모든 이벤트가 로그 형태로 기록**되며, 이 로그는 분산 시스템 내 여러 노드에 걸쳐 저장됩니다.

예를 들어 대규모 웹 애플리케이션에서 사용자 행동 데이터나 서버 로그 같은 이벤트가 발생하면
이 데이터를 Kafka에 기록해 여러 consumer가 동시에 실시간 분석, 모니터링, 경고 등의 작업을 수행할 수 있습니다.

Event broker의 특성처럼 Kafka의 pub/sub 모델은 publisher가 데이터를 보내면 여러 소비자가 그 로그를 구독하여 각자의 필요에 따라 데이터를 처리할 수 있습니다.
이 과정에서 이벤트가 지속적으로 기록되기 때문에 **나중에 필요할 때 과거의 데이터를 재분석하거나 시스템 에러 발생 시 재처리**를 쉽게 할 수 있습니다.

#### 동작 원리
Kafka의 기본 단위는 **토픽**입니다. 
토픽은 메시지들의 카테고리를 의미하고, 각 토픽은 하나 이상의 **파티션**으로 나뉩니다.
파티션은 실제 메시지들이 저장되는 단위로, 각 파티션 내에서는 메시지가 **순차적으로 저장**되고, 각 메시지는 고유한 **offset** 값을 갖게 됩니다.

이러한 구조 덕분에 Kafka는 **메시지의 순서를 보장**할 수 있고 파티션을 여러 서버에 **분산 저장**함으로써 확장성과 병렬 처리를 지원합니다.

Kafka 클러스터는 여러 **브로커**로 구성되어 있고, 각 브로커는 하나 이상의 파티션을 관리합니다.

데이터 안정성과 내결함성을 확보하기 위해 Kafka는 **파티션의 복제본을 여러 브로커에 분산 저장**합니다.
이 방식으로 하나의 브로커에 장애가 발생하더라도 다른 복제본에서 데이터를 제공할 수 있습니다.

데이터를 기록하는 역할은 **producer**가 담당하는데, producer는 특정 토픽에 메시지를 전송하며 **전송 시 메시지를 어느 파티션에 저장할지를 결정**할 수 있습니다.

이때 파티션 선택은 **라운드 로빈 방식**이나 **특정 키 값을 기반**으로 할 수 있는데, 키를 기반으로 할 경우 동일한 키를 가진 메시지들은 항상 같은 파티션에 저장되어 순서가 보장됩니다.

Kafka에서 데이터를 소비하는 역할은 **consumer**가 맡습니다. 
consumer는 **특정 토픽의 파티션에서 메시지를 읽어들이고** 각 consumer는 **읽은 메시지의 offset을 관리**합니다.

Kafka는 **consumer group** 이라는 개념을 통해 다수의 consumer가 같은 그룹으로 묶여 토픽의 각 파티션을 분산 처리할 수 있도록 지원합니다.
동일한 consumer group 내에서는 **하나의 파티션이 하나의 consumer에게만 할당**되어 메시지가 중복 처리되지 않도록 보장합니다.

#### 특징
Kafka의 중요한 특징은 **retention**과 **reprocessing** 입니다.

Kafka는 기본적으로 일정 기간 동안 혹은 특정 용량에 도달할 때까지 메시지를 보관합니다.
이 덕분에 소비자가 메시지를 읽은 후에도 필요에 따라 과거 데이터를 다시 읽어들일 수 있어, 실시간 분석 뿐만 아니라 이벤트 소싱이나 로그 분석 같은 다양한 용도로 활용될 수 있습니다.


## 메시지 브로커 (Message Broker)
메시지 브로커의 주요 목적은 **메시지를 안정적으로 전송하고 각 시스템이 독립적으로 작동**할 수 있도록 하는 것입니다.

메시지 브로커는 메시지를 **Queue나 Topic과 같은 구조에 저장**하고, consumer가 준비되면 해당 메시지를 전달하여 순차적 또는 병렬적으로 처리할 수 있게 합니다.

예를 들어, 사용자가 주문을 완료하면 메시지 브로커는 이 주문 데이터를 결제 처리 시스템에 전달하고, 결제가 완료된 후 다시 주문 처리 시스템에 결과를 전달하는 과정을 중개합니다.

이벤트 브로커가 도서관의 사서와 같았다면 메시지 브로커는 **우편 배달 시스템**과 비슷하다고 볼 수 있습니다.

편지를 보내는 사람이 직접 수취인에게 전달하는 대신 우체국에 맡기는 것처럼 메시지 브로커는 발신자로부터 메시지를 받아 중간에서 필요한 곳으로 전달합니다.

### RabbitMQ
RabbitMQ는 전통적인 메시지 브로커의 대표적인 예입니다.

RabbitMQ에서는 **메시지가 큐에 저장되고, consumer가 해당 큐에서 하나씩 메시지를 가져와 처리하는 방식**으로 동작합니다.

예를 들어 전자상거래 시스템에서 주문이 들어오면 주문 처리 요청 메시지가 RabbitMQ 큐에 저장되고, 주문 처리 서비스가 이 큐에서 메시지를 하나씩 꺼내 처리합니다.

RabbitMQ의 **라우팅 기능**을 이용하면 특정 조건이나 주제에 따라 메시지를 다양한 큐로 분배할 수 있어 시스템 간의 통신을 보다 세밀하게 조절할 수 있습니다.

#### 동작 원리
RabbitMQ의 기본 구성 요소는 크게 **producer, consumer, exchange, queue, binding**으로 구분할 수 있습니다.

**Producer**는 애플리케이션에서 **메시지를 생성하고 RabbitMQ에 전달**하는 역할을 합니다.
이때 메시지를 직접 queue에 넣는 것이 아니라, 먼저 **exchange로 메시지를 전송**합니다.

**Exchang**e는 들어오는 **메시지를 어떻게 queue로 라우팅할 것인지 결정**하는 중추적인 역할을 합니다.
Exchange엔 여러 종류가 있는데, 대표적으로 **direct, topic, fanout, headers** exchange가 있습니다.
각 exchange는 routing key나 바인딩 조건에 따라 메시지를 적절한 queue로 분배합니다.

**Queue**는 **실제로 메시지가 저장되는 공간**입니다.
메시지는 저장된 후, 준비된 consumer에게 전달되어 처리됩니다.

RabbitMQ는 메세지의 신뢰성과 안정성 보장을 위해 큐에 저장된 메시지에 대해 **persistence 옵션을 제공**하며, 
consumer가 메시지를 받아 처리한 후에는 메시지에 대한 **ACK을 받아야 메시지를 삭제**합니다.
이 과정은 메시지 유실이나 중복 처리 방지에 중요한 역할을 합니다.

**Binding**은 exchange와 queue 사이의 **연결 규칙을 정의**합니다.
Binding을 통해 특정 routing key나 패턴에 맞는 메시지가 어떤 queue로 전달될지 결정되므로, 메시지 흐름을 세밀하게 정의할 수 있습니다.

**Consumer**는 큐에 저장된 **메시지를 받아 처리**하는 역할을 합니다.
여러 consumer가 하나의 큐를 구독할 경우, RabbitMQ는 메시지를 **라운드 로빈 방식** 등으로 분배하여 각 consumer가 메시지를 균등하게 처리할 수 있도록 지원합니다.

Consumer가 메시지를 처리하고 난 후 ACK을 보내야하는데, 만약 메시지 처리에 실패하면 RabbitMQ는 해당 메시지를 **재전달하거나 DLX 또는 다른 큐로 라우팅** 할 수 있습니다.




## 차이점
이벤트 브로커는 **"어떤 일이 발생했다"는 사실 자체를 전파**하는 데 중점을 둡니다. 예를 들어 온라인 쇼핑몰에서 사용자가 결제를 완료했을 때 그 사건을 기록하고 여러 시스템에 동시에 알리는 역할을 할 수 있습니다.

반면, 메시지 브로커는 **특정 작업이나 요청을 안전하게 전달**하는 데 집중합니다.
예를 들어, 주문 처리를 위해 결제 요청을 보내거나 작업 큐에 저장된 작업을 하나씩 처리하는 시스템에서 메시지 브로커는 메시지를 큐잉하여 전달하고, 재시도나 배달 보증 등의 기능을 통해 데이터의 신뢰성을 보장합니다.

또한 이벤트 브로커는 이벤트 자체를 **지속적으로 기록하고 저장**하여 나중에 재처리나 분석에 활용할 수 있는 반면, 메시지 브로커는 일반적으로 메시지를 즉시 처리하는 **단기적인 데이터 전달**에 집중합니다.

이처럼 이벤트 브로커는 주로 **시스템의 상태 변화나 사건 발생의 "기록"** 을 다루고, 메시지 브로커는 **특정 작업의 "수행"** 과 관련된 데이터를 다루는 데 초점을 맞춥니다.

Kafka와 RabbitMQ 사용 사례를 비교하자면 Kafka는 **높은 처리량, 내구성, 재처리 기능** 등이 중요한 이벤트 스트리밍 환경에, RabbitMQ는 **복잡한 라우팅, 메세지 우선 순위, 큐 기반의 작업 분산 처리**와 같은 요구 사항이 있을 때 효과적인 선택이 됩니다.







7:["category","cs","d"]
0:["sXRFe75WCMStvMdq2mLiA",[[["",{"children":["blog",{"children":[["category","cs","d"],{"children":["__PAGE__?{\"category\":\"cs\"}",{}]}]}]},"$undefined","$undefined",true],["",{"children":["blog",{"children":[["category","cs","d"],{"children":["__PAGE__",{},[["$L1",["$","$L2",null,{"category":"cs","filteredPosts":[{"slug":"cs/multiprocessing-and-multithreading-in-python","categorySlug":"cs","title":{"ko":"파이썬에서의 멀티 프로세싱과 멀티 스레딩","en":"Multiprocessing and Multithreading in Python"},"date":"2025-02-21","category":{"ko":"컴퓨터 공학","en":"Computer Science"},"description":{"ko":"멀티 프로세싱과 멀티 스레딩의 파이썬에서의 동작 원리","en":"How Multiprocessing and Multithreading Work in Python"},"content":"$3"},{"slug":"cs/garbage-collection-in-python","categorySlug":"cs","title":{"ko":"파이썬에서의 가비지 컬렉션","en":"Garbage Collection in Python"},"date":"2025-02-21","category":{"ko":"컴퓨터 공학","en":"Computer Science"},"description":{"ko":"가비지 컬렉션의 파이썬에서의 동작 원리","en":"How Garbage Collection Works in Python"},"content":"$4"},{"slug":"cs/event-broker-vs-message-broker","categorySlug":"cs","title":{"ko":"이벤트 브로커와 메시지 브로커","en":"Event Broker and Message Broker"},"date":"2025-02-24","category":{"ko":"컴퓨터 공학","en":"Computer Science"},"description":{"ko":"이벤트 브로커와 메시지 브로커의 차이, RabbitMQ와 Kafka의 동작 원리","en":"Difference between event broker and message broker, how RabbitMQ and Kafka work"},"content":"$5"}]}],null],null],null]},[null,["$","$L6",null,{"parallelRouterKey":"children","segmentPath":["children","blog","children","$7","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined"}]],null]},[[null,["$","$L9",null,{"children":["$","$L6",null,{"parallelRouterKey":"children","segmentPath":["children","blog","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined"}],"params":{}}]],null],null]},[[[["$","link","0",{"rel":"stylesheet","href":"/julie/_next/static/css/2688adaac3b51e6f.css","precedence":"next","crossOrigin":"$undefined"}],["$","link","1",{"rel":"stylesheet","href":"/julie/_next/static/css/e680cef9016abb97.css","precedence":"next","crossOrigin":"$undefined"}]],["$","html",null,{"lang":"ko","suppressHydrationWarning":true,"children":["$","body",null,{"className":"__className_29e2ff","children":["$","$La",null,{"attribute":"class","defaultTheme":"system","enableSystem":true,"disableTransitionOnChange":true,"children":["$","$Lb",null,{"children":[["$","$Lc",null,{}],["$","$L6",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":"404"}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],"notFoundStyles":[]}]]}]}]}]}]],null],null],["$Ld",null]]]]
d:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"Julie Lee's Portfolio"}],["$","meta","3",{"name":"description","content":"Welcome to Julie's portfolio page."}],["$","meta","4",{"name":"next-size-adjust"}]]
1:null
