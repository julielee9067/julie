2:"$Sreact.suspense"
3:I[1523,["137","static/chunks/137-7c01c277e0f0cc48.js","269","static/chunks/269-a28aad18182cd41e.js","614","static/chunks/614-0bac26ad143a75db.js","797","static/chunks/app/blog/%5B...slug%5D/page-c538284416fbde4d.js"],"BailoutToCSR"]
4:I[3124,["137","static/chunks/137-7c01c277e0f0cc48.js","269","static/chunks/269-a28aad18182cd41e.js","614","static/chunks/614-0bac26ad143a75db.js","797","static/chunks/app/blog/%5B...slug%5D/page-c538284416fbde4d.js"],"default"]
6:I[4707,[],""]
8:I[6423,[],""]
9:I[3483,["648","static/chunks/648-3ae006cfe07c9d94.js","768","static/chunks/app/blog/layout-a0ac16c7cad7b2d1.js"],"default",1]
a:I[5495,["137","static/chunks/137-7c01c277e0f0cc48.js","648","static/chunks/648-3ae006cfe07c9d94.js","185","static/chunks/app/layout-2f9a78561536bd6f.js"],"ThemeProvider"]
b:I[4491,["137","static/chunks/137-7c01c277e0f0cc48.js","648","static/chunks/648-3ae006cfe07c9d94.js","185","static/chunks/app/layout-2f9a78561536bd6f.js"],"LanguageProvider"]
c:I[1890,["137","static/chunks/137-7c01c277e0f0cc48.js","648","static/chunks/648-3ae006cfe07c9d94.js","185","static/chunks/app/layout-2f9a78561536bd6f.js"],"Header"]
5:T2139,
## 개요
처음엔 이 글을 시스템 디자인 카테고리에 넣는게 맞나 하는 생각이 들었지만.. 이런 글은 아마 자주 올리지 않을 것 같고, 따로 카테고리를 빼기도 좀 그런 것 같아 여기에 넣기로 결정했습니다!

## 사용 사례
예를 들어, 여러 개의 주소가 있다고 가정해 봅시다.
- A: 서울특별시 강남구
- B: 서울 강남구
- C: 부산 해운대구

이 주소들이 실제로 같은 지역에 속하는지 알고 싶다면 어떻게 해야 할까요?

단순히 문자열을 비교하는 방식으로는 "서울특별시 강남구"와 "서울 강남구"가 거의 같은 의미라는 걸 판단하기 어려울 수도 있습니다. 
그래서 이런 문제를 해결하려면 **비슷한 요소들을 그룹으로 묶는 군집화(clustering)** 기법을 사용할 수 있습니다.

여기서는 **계층적 군집화(Hierarchical Clustering)** 를 사용하여 데이터 간의 유사도를 기반으로 그룹을 형성하는 방법을 설명하려고 합니다.

## 군집화 적용 과정
### 1. 유사도 매트릭스 생성

먼저, **유사도 행렬(similarity matrix)** 을 만듭니다.
이 행렬은 각 요소들 간의 유사도를 숫자로 나타내는 표입니다.

앞서 예로 든 **A, B, C** 세 개의 주소가 있다면, 가능한 조합은 **(A, B), (A, C), (B, C)** 세 쌍이 됩니다.
각 쌍의 유사도를 계산해서 아래와 같은 형태의 행렬을 만들 수 있습니다.

|  | A | B | C |
|------|-----------|---------|------|
| A | 1 | 0.95 | 0.2 |
| B | 0.95 | 1 | 0.3 |
| C | 0.2 | 0.3 | 1 |


- A와 B는 매우 비슷하므로 유사도가 **0.95**
- A와 C는 많이 다르므로 유사도가 **0.2**
- B와 C는 A보다 조금 더 비슷하지만 그래도 차이가 있으므로 **0.3**

이렇게 계산된 유사도 행렬을 기반으로 그룹을 형성할 수 있습니다.

유사도를 계산하는 기준은 문제에 따라 달라질 수 있습니다.
예를 들어, 문자열 유사도를 비교할 수도 있고, 거리 기반 계산(주소 간의 실제 거리 차이)을 활용할 수도 있습니다.


### 2. 유사도 → 거리 변환
    
**계층적 군집화는 거리(distance)를 기반으로 데이터를 그룹화** 합니다.
거리가 가까울수록 두 데이터가 더 비슷하다는 의미입니다.

유사도를 거리로 변환하는 방법 중 하나는 **거리 = 1 - 유사도** 를 사용하는 것입니다.

|  | A | B | C |
|------|-----------|---------|------|
| A | 0 | 0.05 | 0.8 |
| B | 0.05 | 0 | 0.7 |
| C | 0.8 | 0.7 | 0 |

### 3. 군집화 수행
`SciPy`의 `linkage()` 함수를 사용하여 계층적 군집화를 수행합니다.

이 함수는 처음에 각 데이터(A, B, C)를 **독립적인 그룹(군집)** 으로 간주하고,
가장 거리가 가까운 두 군집부터 점차 합쳐 나갑니다.

여기서는 **평균 연결(average linkage)** 방법을 사용했습니다.
    
평균 연결은 두 그룹 간의 모든 데이터 쌍의 거리를 평균내어 군집 간의 거리를 결정하는 방식입니다.

예를 들어, 그룹 1(A, B)과 그룹 2(C) 사이의 거리는:
- (A, C)의 거리: 0.8
- (B, C)의 거리: 0.7
- 평균 거리: (0.8 + 0.7) / 2 = 0.75

이 과정을 반복하면 데이터들이 점점 하나의 큰 그룹으로 묶이게 됩니다.

> 평균 연결 방식은 군집을 좀 더 균형 잡힌 형태로 만들기 때문에,
이상치(outlier)나 데이터의 불균형이 있는 경우에도 안정적인 군집화를 할 수 있습니다.

### 4. 덴드로그램으로 군집 분할
군집화 과정이 끝나면 덴드로그램(dendrogram) 을 활용해 그룹을 시각적으로 확인할 수 있습니다.

![덴드로그램](https://miro.medium.com/v2/resize:fit:740/1*VvOVxdBb74IOxxF2RmthCQ.png)

덴드로그램은 트리(tree) 형태로 데이터가 병합되는 과정을 보여줍니다.

이제 `fcluster()` 함수를 사용하여 **특정 임계값(THRESHOLD)** 을 기준으로 덴드로그램을 잘라 최종 군집을 결정합니다.

예를 들어, THRESHOLD를 **0.8**로 설정하면, 서로의 거리가 **0.8 이하**인 데이터들은 같은 그룹이 되고,
거리가 **0.8 이상**인 데이터들은 다른 그룹이 됩니다.

최종 결과는 아래처럼 나올 수 있습니다.
```
   -------------0.75------------
    |                           |
    |                           |
──────────────── Threshold = 0.5 ────────────────
    |                           | 
    |                           |
    |                   -------0.05------
    |                   |               |
"부산 해운대구"        "서울 강남구"    "서울특별시 강남구"


[["서울특별시 강남구", "서울 강남구"], ["부산 해운대구"]]
```

즉, 서울 강남구 관련 주소들은 같은 그룹으로 묶이고, 부산 해운대구는 별도의 그룹이 됩니다.

---

## Hierarchical Clustering (계층적 군집화)
### Agglomerative Clustering (병합형 / Bottom-Up)
각 데이터를 처음에는 개별 그룹으로 취급한 후, 가장 비슷한 두 그룹부터 차례대로 합쳐나갑니다.

친구 모임에서 처음에는 개별적으로 모였다가, 성격이나 관심사가 비슷한 사람들이 점차 하나의 모임으로 합쳐지는 과정과 비슷합니다.

처음부터 모든 데이터를 독립적으로 다루고, 데이터 간의 미세한 차이도 반영할 수 있습니다.
대신 계산 비용이 높아 데이터가 많을 때는 처리하기 어렵습니다.

### Divisive Clustering (분할형 / Top-Down)
모든 데이터를 하나의 큰 그룹으로 시작하여, 유사성이 낮은 부분부터 점차 분할하여 개별 데이터로 나누는 방식입니다.

큰 회사의 조직도를 생각해보면, 최고 경영진 아래에 여러 부서로 나뉘고, 각 부서 내에서 다시 팀으로 나뉘는 과정을 떠올릴 수 있습니다.

이 방법은 구현이 복잡하고 일반적으로 많이 사용되지 않습니다.

---

## 다른 클러스터링 기법
### K-Means Clustering
- 군집 개수(k)를 미리 정해야 함
- 각 데이터가 가장 가까운 중심(centroid)으로 이동하면서 군집을 형성
- 빠르고 효율적이지만, 데이터의 분포가 특정한 형태(구형)로 가정되는 문제가 있음
- 예시: 학생들의 성적을 기준으로 상위권, 중위권, 하위권 3개 그룹으로 나누기

### Affinity propagation
- 데이터 간의 유사도를 활용해 대표(Exemplar)를 자동으로 선택하는 방식
- 군집 수를 사전에 정할 필요가 없음
- 하지만 계산량이 많고 느리다는 단점이 있음
- 예시: SNS에서 비슷한 관심사를 가진 사용자 그룹을 자동으로 찾아내기

### Mean-Shift
- 밀도가 높은 지역을 중심으로 군집을 형성
- 군집 수를 사전에 정할 필요 없음
- 하지만 계산 비용이 높아 대량의 데이터에는 적합하지 않음
- 예시: 도시 내에서 사람들이 자주 방문하는 지역(상권 분석) 찾기

### Gaussian Mixture Model (GMM)
- 데이터가 여러 개의 가우시안 분포(정규분포)의 혼합으로 구성되었다고 가정하고, 각 데이터가 어떤 분포에 속할 확률을 계산
- 군집 개수(k)를 미리 정해야 함
- 타원형 등 다양한 모양의 군집을 모델링 가능
- 계산 비용 높음
- 예시: 학생들의 시험 점수가 명확하게 나뉘지 않고, 상위권과 하위권이 겹치는 경우 각 학생이 어느 그룹에 속할 확률을 추정하여 소프트하게 그룹을 나누는 방식

## 마무리
제가 **계층적 군집화**를 선택했던 이유는 군집화할 **데이터의 개수가 많지 않고, 미리 군집 수를 정하기 어려웠기 때문**입니다.

이처럼 각 클러스터링 기법은 **데이터의 크기, 분포, 군집 수에 대한 사전 정보, 그리고 해석의 용이성** 등 여러 요소에 따라 장단점이 있으므로 분석 목적에 맞는 방법을 선택하는 것이 중요합니다.

대규모 데이터나 실시간 처리가 필요한 경우에는 K-Means 같은 방법이 적합할 수 있고,
데이터 간의 관계를 자세히 분석하고 싶다면 계층적 군집화가 유리하며,
군집 수를 미리 정하기 어려운 경우는 Affinity Propagation이나 Mean-Shift를 고려해볼 수 있습니다.
7:["slug","system-design/hierarchical-clustering","c"]
0:["nBlwvcTFiqFjWAR0inr3E",[[["",{"children":["blog",{"children":[["slug","system-design/hierarchical-clustering","c"],{"children":["__PAGE__?{\"slug\":[\"system-design\",\"hierarchical-clustering\"]}",{}]}]}]},"$undefined","$undefined",true],["",{"children":["blog",{"children":[["slug","system-design/hierarchical-clustering","c"],{"children":["__PAGE__",{},[["$L1",["$","$2",null,{"fallback":null,"children":["$","$L3",null,{"reason":"next/dynamic","children":["$","$L4",null,{"post":{"slug":"system-design/hierarchical-clustering","categorySlug":"system-design","title":{"ko":"계층적 클러스터링","en":"Hierarchical Clustering"},"date":"2025-03-05 13:09","category":{"ko":"시스템 디자인","en":"System Design"},"description":{"ko":"계층적 클러스터링 적용 과정과 다른 클러스터링 기법과의 비교","en":"Hierarchical clustering and comparison with other clustering methods"},"content":"$5"}}]}]}],null],null],null]},[null,["$","$L6",null,{"parallelRouterKey":"children","segmentPath":["children","blog","children","$7","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined"}]],null]},[[null,["$","$L9",null,{"children":["$","$L6",null,{"parallelRouterKey":"children","segmentPath":["children","blog","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined"}],"params":{}}]],null],null]},[[[["$","link","0",{"rel":"stylesheet","href":"/julie/_next/static/css/064e10fa6619f508.css","precedence":"next","crossOrigin":"$undefined"}],["$","link","1",{"rel":"stylesheet","href":"/julie/_next/static/css/e680cef9016abb97.css","precedence":"next","crossOrigin":"$undefined"}]],["$","html",null,{"lang":"ko","suppressHydrationWarning":true,"children":["$","body",null,{"className":"__className_29e2ff","children":["$","$La",null,{"attribute":"class","defaultTheme":"system","enableSystem":true,"disableTransitionOnChange":true,"children":["$","$Lb",null,{"children":[["$","$Lc",null,{}],["$","$L6",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":"404"}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],"notFoundStyles":[]}]]}]}]}]}]],null],null],["$Ld",null]]]]
d:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"Julie Lee's Portfolio"}],["$","meta","3",{"name":"description","content":"Welcome to Julie's portfolio page."}],["$","meta","4",{"name":"next-size-adjust"}]]
1:null
