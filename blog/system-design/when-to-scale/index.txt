2:"$Sreact.suspense"
3:I[1523,["137","static/chunks/137-7c01c277e0f0cc48.js","269","static/chunks/269-a28aad18182cd41e.js","614","static/chunks/614-0bac26ad143a75db.js","797","static/chunks/app/blog/%5B...slug%5D/page-c538284416fbde4d.js"],"BailoutToCSR"]
4:I[3124,["137","static/chunks/137-7c01c277e0f0cc48.js","269","static/chunks/269-a28aad18182cd41e.js","614","static/chunks/614-0bac26ad143a75db.js","797","static/chunks/app/blog/%5B...slug%5D/page-c538284416fbde4d.js"],"default"]
6:I[4707,[],""]
8:I[6423,[],""]
9:I[3483,["648","static/chunks/648-3ae006cfe07c9d94.js","768","static/chunks/app/blog/layout-a0ac16c7cad7b2d1.js"],"default",1]
a:I[5495,["137","static/chunks/137-7c01c277e0f0cc48.js","648","static/chunks/648-3ae006cfe07c9d94.js","185","static/chunks/app/layout-2f9a78561536bd6f.js"],"ThemeProvider"]
b:I[4491,["137","static/chunks/137-7c01c277e0f0cc48.js","648","static/chunks/648-3ae006cfe07c9d94.js","185","static/chunks/app/layout-2f9a78561536bd6f.js"],"LanguageProvider"]
c:I[1890,["137","static/chunks/137-7c01c277e0f0cc48.js","648","static/chunks/648-3ae006cfe07c9d94.js","185","static/chunks/app/layout-2f9a78561536bd6f.js"],"Header"]
5:T1925,
## 개요
시스템 디자인 면접을 보면 **"분산 시스템을 어떻게 설계할까?"** 라는 질문은 빠지지 않습니다.

하지만 **"언제 분산 시스템을 사용해야 할까?"** 라는 의사결정 시점은 자주 다뤄지지 않습니다.

과거에는 분산 시스템 없이 해결하기 힘든 규모가 많았지만, 최근 하드웨어 성능이 크게 발전하면서 단일 머신으로도 예전과 비교할 수 없을 만큼 큰 규모를 처리할 수 있게 되었습니다.

스토리지를 예로 들면 단일 인스터스에서 100TB 이상의 SSD를 제공할 수 있고, 클라우드 환경에서는 S3 같은 Object storage를 PB 단위로 사용하는 일이 흔해졌습니다.
한때 데이터베이스가 100GB만 되어도 샤딩하라고 했던 것 같은데 이제는 이 기준이 너무 보수적으로 변했습니다.

이 글에선 현대 하드웨어 성능의 증가에 따라 **"언제 스케일링을 해야 하는지"** 의 기준이 어떻게 달라졌는지 적어보도록 하겠습니다.

## 1. 캐싱
인메모리 캐시 기술은 비교할 수 없을 정도로 발전했는데, 예전에는 64GB 정도의 Redis instance가 흔했지만, 지금은 **TB 단위**까지도 단일 인스턴스로 운용할 수 있습니다.
- 메모리 용량: 메모리 최적화 인스턴스의 경우 최대 1TB 이상
- Latency
    - same region: 읽기 시 1ms 미만
    - cross-region: 쓰기 시 1~2ms
- Throughput
    - read: 초당 10만 건 이상
    - write: 초당 수십만 건 이상

이처럼 캐시 하나에 상당한 규모를 담을 수 있기 때문에, 데이터의 부분적 캐싱을 고려하기 보다는 **데이터 전체를 통째로 올려도 될까**를 먼저 고민해봐야 합니다.

캐시에 대한 샤딩을 고려해야 할 때는:
- 데이터셋 크기가 1TB에 근접할 경우
- 초당 10만건 이상의 트래픽이 지속적으로 발생하는 경우
- 읽기 latency를 0.5ms 이하로 계속 유지해야 하는 경우
- hit rate이 80% 미만으로 떨어지는 경우

## 데이터베이스
PostgreSQL, MySQL 등 현대 DB engine은 단일 인스턴스로도 수십 TB를 처리할 수 있을 만큼 성능이 올라갔습니다.

보통 병목은 **"백업/복구에 너무 오래 걸린다"** 처럼 운영 관점에서 발생하는 경우가 많습니다.

- Stroage (단일 인스턴스): 최대 64TB, aurora 등에선 128TB 이상도 가능 
- Latency
    - Read: 캐시된 데이터 기준 1-5ms, 디스크에서 읽을 경우 5-30ms
    - Write: 고성능 설정일 때 5~15ms
- Throughput
    - Read: 초당 50000 TPS
    - Write: 초당 10000~20000 TPS
    - Connection: 5000~20000개 동시 연결 가능

PB 단위로 데이터를 다루지 않는 이상, 실제로 단일 데이터베이스만으로도 수백 만 ~ 수천 만 사용자까지 버틸 수 있습니다.

샤딩을 사용하기 전에, 정말 샤딩이 필요한지를 먼저 계산해봐야하고, 정말 샤딩이 필요한 경우라면 순수한 데이터의 양 때문인지, 운영 측면 문제 때문인지, 지리적 분산 때문인지 등 정확한 이유를 알아야합니다.

누가 "네이버 플레이스를 설계해봐라" 하고 물어볼 때, 만약 업체가 1000만개라고 해도 각 업체가 1KB라면 10GB에 불과하니까, 데이터 양만 봤을 때는 굳이 샤딩을 고려할 이유가 없습니다.

## 서버
애플리케이션 서버에서 가장 흔한 병목은 CPU입니다. 

요즘 서버는 동시 연결 수가 수천~수만 개여도 커버할 수 있고, 클라우드 환경에서는 부하가 늘 시 몇 초만에 새 인스턴스를 띄워서 대응할 수 있습니다.

- Connections: 인스턴스당 동시 10만+ 연결 가능
- CPU: 8~64 core
- 메모리: 보통 64~512GB, 최대 2TB 이상도 가능하긴 함
- 네트워크: 최대 25GBps
- startup time: 30~60초

서버 확장을 고려해야 하는 경우는:
- CPU 사용률이 70~80%을 꾸준히 넘가는 경우
- latency가 threshold를 초과하는 경우
- 메모리 사용률이 70~80%을 꾸준히 넘기는 경우
- network bandwidth가 20Gbps에 근접하는 경우

서버 로컬 캐싱, 인메모리 계산, 세션 처리를 적극적으로 활용해서 성능을 최적화 할 수 있고, CPU가 병목이 되는 경우 메모리를 더 끌어다 쓰는 최적화 기법을 사용할 수 있습니다.

## 메시지 큐
Kafka같은 고성능 메시지 큐는 단일 클러스터에서 초당 수백만 건의 메시지를 처리하면서도 1~5ms 단위의 latency를 유지할 수 있습니다.

- Latency: 1~5ms (same region, optimized setups)
- Throughput: 초당 최대 100만 건 이상
- 메시지 크기: 1kb~10MB
- 스토리지: 브로커 당 50TB
- Retention: 설정에 따라 몇 주에서 몇 달까지

브로커 확장을 고려해야 하는 경우는:
- 브로커 당 처리량이 초당 80만 건 이상인 경우
- 클러스터 내 파디션 수가 20만 개에 가까워진 경우
- consumer lag가 계속 증가하는 경우

## 마무리
시스템 디자인에서 가장 흔히 하는 실수 중 하나가 **너무 섣부르게 샤딩을 도입하는 것**입니다.

단일 인스턴스로도 충분히 감당 가능한 규모일 때 "샤딩을 어떻게 도입할까?"부터 고민할 때가 많습니다. 

또한, SSD에서 인덱스 조회를 하면 10ms 안팎이면 충분히 빠른데도 불필요하게 캐시 레이어를 붙이기도 합니다.

진짜로 분산 아키텍쳐가 필요한 시점이 오면 적극적으로 적용해야 하지만, 그 전에 **현재 단일 인스턴스가 어느 정도까지 버틸 수 있는가**를 구체적인 수치로 확인해본 후, Batch write, index optimization, connection pool, async commit 등 간단한 최적화부터 시도해보는게 좋습니다.

정리해보면, 
1. 수직 확장이 더 용이한 경우
    
    1. 데이터 규모와 트래픽이 충분히 적을 때
    2. 성능 튜닝을 더 할 수 있을 때
    3. 운영의 단순성이 중요할 때
    4. 병목을 단일 인스턴스 내에서 해결할 수 있을 때 (db schema, query 등의 이슈)
   
2. 수평 확장이 더 용이한 경우
    
    1. 데이터량이 압도적으로 커질 때
    2. 지리적 분산이 필요할 때
    3. 쓰기가 매우 빈번하고 병렬 처리량이 매우 많을 때
    4. 서비스 다운타임을 최소화하고 싶을 때

7:["slug","system-design/when-to-scale","c"]
0:["NaZIj2JiavFCpU3la-qKe",[[["",{"children":["blog",{"children":[["slug","system-design/when-to-scale","c"],{"children":["__PAGE__?{\"slug\":[\"system-design\",\"when-to-scale\"]}",{}]}]}]},"$undefined","$undefined",true],["",{"children":["blog",{"children":[["slug","system-design/when-to-scale","c"],{"children":["__PAGE__",{},[["$L1",["$","$2",null,{"fallback":null,"children":["$","$L3",null,{"reason":"next/dynamic","children":["$","$L4",null,{"post":{"slug":"system-design/when-to-scale","categorySlug":"system-design","title":{"ko":"언제 샤딩이 필요한가","en":"When should we shard our system"},"date":"2025-03-15 15:17","category":{"ko":"시스템 디자인","en":"System Design"},"description":{"ko":"현대 하드웨어 기준 샤딩이 정말 필요할 때","en":"When should we shard our system based on modern hardware"},"content":"$5"}}]}]}],null],null],null]},[null,["$","$L6",null,{"parallelRouterKey":"children","segmentPath":["children","blog","children","$7","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined"}]],null]},[[null,["$","$L9",null,{"children":["$","$L6",null,{"parallelRouterKey":"children","segmentPath":["children","blog","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined"}],"params":{}}]],null],null]},[[[["$","link","0",{"rel":"stylesheet","href":"/julie/_next/static/css/064e10fa6619f508.css","precedence":"next","crossOrigin":"$undefined"}],["$","link","1",{"rel":"stylesheet","href":"/julie/_next/static/css/e680cef9016abb97.css","precedence":"next","crossOrigin":"$undefined"}]],["$","html",null,{"lang":"ko","suppressHydrationWarning":true,"children":["$","body",null,{"className":"__className_29e2ff","children":["$","$La",null,{"attribute":"class","defaultTheme":"system","enableSystem":true,"disableTransitionOnChange":true,"children":["$","$Lb",null,{"children":[["$","$Lc",null,{}],["$","$L6",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":"404"}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],"notFoundStyles":[]}]]}]}]}]}]],null],null],["$Ld",null]]]]
d:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"Julie Lee's Portfolio"}],["$","meta","3",{"name":"description","content":"Welcome to Julie's portfolio page."}],["$","meta","4",{"name":"next-size-adjust"}]]
1:null
