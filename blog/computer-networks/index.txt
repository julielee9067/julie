2:I[3422,["137","static/chunks/137-7c01c277e0f0cc48.js","648","static/chunks/648-3ae006cfe07c9d94.js","269","static/chunks/269-a28aad18182cd41e.js","254","static/chunks/app/blog/%5Bcategory%5D/page-6078f51c25971824.js"],"default"]
c:I[4707,[],""]
e:I[6423,[],""]
f:I[3483,["648","static/chunks/648-3ae006cfe07c9d94.js","768","static/chunks/app/blog/layout-a0ac16c7cad7b2d1.js"],"default",1]
10:I[5495,["137","static/chunks/137-7c01c277e0f0cc48.js","648","static/chunks/648-3ae006cfe07c9d94.js","185","static/chunks/app/layout-2f9a78561536bd6f.js"],"ThemeProvider"]
11:I[4491,["137","static/chunks/137-7c01c277e0f0cc48.js","648","static/chunks/648-3ae006cfe07c9d94.js","185","static/chunks/app/layout-2f9a78561536bd6f.js"],"LanguageProvider"]
12:I[1890,["137","static/chunks/137-7c01c277e0f0cc48.js","648","static/chunks/648-3ae006cfe07c9d94.js","185","static/chunks/app/layout-2f9a78561536bd6f.js"],"Header"]
3:T3b0f,
## 라우터
라우터의 주요 임무는 **패킷을 올바른 출력 포트로 전달**하고, **라우팅 프로토콜을 실행하여 경로를 관리**하는 것입니다.
### 구성 요소
#### Forwarding Plane
Forwarding plane의 역할은 **패킷이 들어오는 인터페이스에서 적절한 output 인터페이스로 빠르게 전달**하는 것입니다.
이것은 일반적으로 몇 나노초 단위의 매우 짧은 시간에 **하드웨어**로 구현됩니다.

구성 요소는 다음과 같습니다.

1. **입력 포트**: 외부 링크의 신호를 받아들이고, 패킷의 캡슐화를 해제하고, 패킷의 목적지 IP를 확인한 후 포워딩 테이블(FIB)에서 어떤 출력 포트로 보낼지 결정합니다.
2. **Switching fabric**: 입력 포트로부터 받은 패킷을 출력 포트로 전달합니다. 메모리 기반, 버스 기반, 크로스바 방식 등이 있습니다.
3. **출력 포트**: switching fabric을 통해 전달된 패킷을 수신하고, 큐잉한 후 최종적으로 외부 링크로 전송합니다.

#### Control Plane
Control Plane은 **라우팅 프로토콜 (RIP, OSPF, BGP 등)을 실행하여 라우팅 테이블을 구성**하고 이 정보를 바탕으로 **포워딩 테이블(FIB)을 생성**하는 작업을 수행합니다.

주로 **소프트웨어로 동작**하며 라우팅 프로세서 내부에서 실행되거나 SDN 환경에서는 원격 컨트롤러가 이 역할을 대신할 수 있습니다.

### 동작 과정
패킷이 라우터에 도착하면 다음과 같은 순서로 처리됩니다.

1. **Lookup**
    
    패킷 도착 시 **입력 포트에서 목적지 IP 주소를 확인**합니다.
    
    **Longest Prefix Match** 알고리즘을 사용해 FIB에서 가장 적합한 경로를 찾습니다.
    
2. **Switching**

    Lookup 결과에 따라 패킷을 **입력 포트에서 선택된 출력 포트로 전달**합니다.
    빠른 스위칭을 위해 크로스바 스위치 등이 사용되며, 여러 입력 포트가 동일한 출력 포트로 보내려 할 경우 스케줄링 문제가 생길 수도 있습니다.
    
3. **Queueing**

    출력 포트에 전달한 패킷은 **링크 혼잡 시 임시로 대기열에 저장**됩니다.
    FIFO, WFQ 등 다양한 큐잉 방식이 사용되며 QoS를 지원합니다.
    
4. **부가 처리**
    
    IP 버전, TTL 감소, checksum 재계산 등을 수행하고 SNMP, ICMP, TCP/UDP 등의 프로토콜을 통해 관리 및 오류 보고 처리를 합니다.
    라우팅 프로토콜을 통해 업데이트된 정보를 기반으로 **FIB를 재구성**합니다.

### 스위칭 방식
라우터 내부에서 패킷을 전달하기 위한 스위칭 방식에는 여러 가지가 있습니다.
1. **메모리 기반 스위칭**

    입력 포트에서 패킷을 수신하면 interrupt를 발생시켜 **라우팅 프로세서 메모리로 패킷을 복사**합니다.
    이 때, 프로세서는 목적지 주소를 확인한 후 해당 패킷을 다시 출력 포트 버퍼로 복사합니다.
    
    프로세서 개입으로 인해 **처리 지연**이 생길 수 있습니다.

2. **버스 기반 스위칭**

    입력 포트가 패킷에 내부 헤더(출력 포트 지정 정보)를 추가한 후 공유 버스로 보냅니다.
    **모든 출력 포트가 버스의 패킷을 받지만 오직 지정된 포트만 이를 저장**합니다.
    
    버스의 대역폭 제한으로 **단일 패킷**만 전송 가능합니다.
    
3. **크로스바 스위칭**
    
    N개의 입력 포트와 N개의 출력 포트를 연결하는 2N개의 버스를 사용해서 **교차점에서 스위칭을 수행**합니다.
    서로 다른 입/출력 포트 간에 **동시에 여러 패킷을 전달**할 수 있습니다.
    
### Prefix Matching 및 Lookup 알고리즘
라우터는 패킷을 전달하기 전에 **FIB에서 목적지 주소에 맞는 경로를 찾아야** 하는데 이 때 prefix-match lookup 알고리즘이 사용됩니다.

인터넷이 커지면서 라우터에 명시적으로 모든 목적지를 저장하기 어려워지고, **IP 주소를 prefix 단위로 그룹화** 하게 되었습니다.
**CIDR(Classless Inter-Domain Routing)** 로 인해 **길이가 가변적인 prefix**들이 등장하면서 Longest prefix match 문제를 해결해야합니다.

#### 주요 기법
1. **Unibit Trie**
    
    각 노드가 **0또는 1의 두 가지 분기**를 가지며 루트에서 시작해 입력 IP의 비트를 따라 내려갑니다.
    마지막에 성공한 노드의 prefix가 longest prefix match 결과가 됩니다.

2. **Multibit Trie**

    한 노드에서 **여러 비트를 동시에 확인**하여 메모리 접근 횟수를 줄이는 방식입니다.
    
    **Fixed-Stride Trie**는 모든 노드에서 **동일한 비트 수**를 사용하여 분기하고, **Variable-Stride Trie**는 각 노드마다 최적의 분기 비트 수를 **동적으로 조절**하여 메모리 효율을 높입니다.
    
    Fixed-stride가 3인 Multibit trie를 예로 들어보겠습니다.
    
    데이터베이스에 저장된 prefix `P1: 101 (3비트), P2: 11001 (5비트), P3: 111 (3비트)`가 있을 때, P2의 길이가 5비트 이므로 3의 배수(6비트)로 맞추기 위해 **controlled prefix expansion**을 적용해야 합니다.
    
    ```
            [Root] (Level 0, 3비트)
              /      |         \
        "101": P1   "110": Node B   "111": P3
                   (Level 1, 3비트)
                     /         \
              "010": P2     "011": P2
    ```
    
    루트에서 3비트 단위로 분기할 때, 입력 주소가 `101`이면 `P1`, `111`이면 `P3`로 바로 매칭됩니다.
    
    입력 주소가 `110`으로 시작하면 하위 노드로 내려가서 다음 3비트를 확인합니다.
    
    따라서, 주소가 예를 들어 `1100101010`인 경우에는 루트에서 `110`분기를 따라 내려가고, 하위 노드에서 `010`분기를 선택해서 `P2`와 longest prefix matching이 이루어집니다.
3. **Prefix Expansion**
    
    **주어진 prefix를 선택한 stride 길이에 맞게 확장**하여 매칭 시 누락되는 경우를 방지합니다.
    이로 인해 데이터베이스 크기는 증가하지만, 룩업 속도는 향상됩니다.
    
    예를 들어, 원래 Prefix가 `101` (3비트) 이고, 선택한 stride 길이가 2비트라면 원래 Prefix 길이인 3은 2의 배수가 아니므로 가장 가까운 2의 배수인 4로 확장해야 합니다.
    
    `101`을 4비트로 확장하려면 마지막 비트를 0과 1 두 가지 경우로 채웁니다: `1010`, `1011`
    
    원래 prefix `101`은 확장 후 **두개의 접두사 `1010`과 `1011`로 대체**됩니다. 
    이렇게 확장된 prefix들은 고정 stride 방식의 multibit trie에서 룩업 시 누락없이 빠르게 처리될 수 있습니다.
### Concerns
인터넷 사용 기기의 증가와 트래픽 폭증으로 인해 처리 및 메모리 요구가 증가하고 있습니다.
또한, 고속 링크로 인한 높은 데이터 전송량 처리가 필요해졌습니다.

이 때, **빠른 룩업 속도**와 **메모리 효율** 사이의 균형이 필요하고 IP prefix의 가변 길이와 매우 큰 테이블 크기로 인해 효율적인 알고리즘 설계가 필수적입니다.

## Packet Classification
기존에는 패킷 포워딩이 주로 **목적지 IP 주소의 longest prefix match**에 의존했지만 인터넷 환경이 점점 복잡해짐에 따라 네트워크는 추가 요구사항들을 충족해야합니다.
1. **QoS (Quality of Service) 보장**
    
    실시간 영상, 음성 통화 같이 지연이나 패킷 손실에 민감한 애플리케이션의 경우, 특정 트래픽에 대해 low latency, consistent bandwidth, 낮은 변동성을 보장해야 합니다.
2. **보안 보장**

    방화벽을 통해 악의적인 트래픽을 차단하거나 특정 규칙에 따라 트래픽을 필터링하여 네트워크 보안을 강화해야 합니다.
3. **트래픽 유형 기반 라우팅**

    비디오 트래픽과 일반 데이터를 다른 경로로 전달하거나 트래픽을 분리하여 자원을 예약하는 등의 기능이 필요합니다.
    
따라서 단순히 목적지 IP 만으로 패킷을 처리하는 것으로는 부족하며, **TCP/UDP port, 출발지 IP, TCP Flag** 등 여러 필드를 기반으로 세밀한 분류가 필요합니다.

### 패킷 분류의 간단한 해결책
#### 선형 검색 (Linear Search)
Rule 데이터베이스에 있는 규칙들을 순차적으로 탐색하여 매칭되는 규칙을 찾는 방법입니다.

이 때 규칙의 수가 적을 때는 괜찮지만, 수천 개 이상의 규칙이 존재하면 매우 느려집니다.

#### 캐싱 (Caching)
최근에 매칭된 결과를 캐시에 저장하여 동일하거나 유사한 패킷이 도착할 때 빠르게 결과를 반환합니다.

하지만 캐시 적중률이 높더라도 캐시 미스가 발생할 경우 선형 검색을 수행해야 하므로 평균 탐색 시간이 늘어날 수 있습니다.

#### Passing Labels
MPLS나 DiffServ에서 사용되는 방법인데 **네트워크 엣지에서 패킷 분류를 수행**한 후, 패킷에 라벨을 부여하여 **중간 라우터에서는 라벨만 확인하고 포워딩**함으로써 복잡한 분류 과정을 피할 수 있습니다.

### 더 나아간 해결책
네트워크 환경에서 분류 규칙은 여러 종류로 구성되기 때문에 단순 선형 검색으로는 한계가 있습니다. 

#### Set-Pruning Trie
**목적지 prefix를 기반으로 Trie를 구성**한 뒤, **각 리프 노드에 해당하는 하위 트리(출발지 prefix를 포함하는)를 연결**합니다.

하지만 하나의 출발지 prefix가 여러 목적지 트리에 나타날 수 있어 **메모리 사용량이 급증**할 수 있습니다.

예를 들어, 다음과 같은 규칙이 있다고 가정해봅시다.
| **규칙** | **목적지 prefix** | **출발지 prefix**  | **설명**  |
|-----------|-------------|----------|----------|
| R1   | `00*`     | `0*`  | 목적지가 `00`으로 시작, 출발지가 `0`으로 시작하는 규칙 |
| R2   | `00*`     | `10*`  | 목적지가 `00`으로 시작, 출발지가 `10`으로 시작하는 규칙 |
| R3   | `00*`     | `0*`  | 목적지가 `00`으로 시작, 출발지가 `0`으로 시작하는 규칙 |
| R4   | `01*`     | `11*`  | 목적지가 `01`으로 시작, 출발지가 `11`으로 시작하는 규칙 |
| R5   | `00*`     | `11*`  | 목적지가 `00`으로 시작, 출발지가 `11`으로 시작하는 규칙 |

이 때, 먼저 목적지 접두사를 기준으로 trie를 구성하면 아래와 같은 형태가 될 수 있습니다.
```
                 [Root]
                    │
         (첫 번째 비트 = '0')
                    │
                [노드: "0"]
                 /       \
  (두 번째 비트 = '0')   (두 번째 비트 = '1')
           /                    \
  [노드: "00"]            [노드: "01"]
```
`00` 노드에 속한 규칙들의 출발지 prefix는 다음과 같습니다: `R1, R3: 0*, R2: 10*, R5: 11`

위 정보를 바탕으로 `00`노드에 해당하는 규칙들의 출발지 trie를 구성해보면 다음과 같습니다.
```
           [Source Root]
              /      \
         (0) /         \ (1)
            /           \
      [0-branch]      [1-branch]
            |          /       \
         "0*"       "10*"      "11*"
```

여기서 라우터는 먼저 패킷의 목적지 주소를 이용해 목적지 trie에서 longest prefix match를 진행합니다.
예를 들어, 패킷의 목적지 주소가 `001...` 이라면 `0 -> 0` 경로를 따라 `00` 노드에 매칭됩니다.

그 다음, 해당 `00`노드에 연결된 출발지 trie에서 패킷의 출발지 주소에 대해 longest prefix match를 수행합니다.
예를 들어, 패킷의 출발지 주소가 `101...`인 경우, 출발지 trie의 오른쪽 분기를 따라가며 `10*` 또는 `11*` 중 어느 것이 매칭되는지 확인하고 가장 적합한 규칙을 선택합니다.

#### Backtracking 활용 기법
각 목적지 prefix는 정확히 **해당하는 출발지 trie를 한 번만 저장**하고, 룩업 시에 목적지 trie에서 longest prefix를 찾은 후 그 **조상 노드들에 연결된 출발지 trie들을 backtracking** 합니다.

이 때 각 규칙이 한 번만 저장되므로 메모리 사용량이 줄어들지만 backtracking으로 인해 **룩업 시간이 증가**합니다.

#### Grid of Tries
사전에 **스위치 포인터(switch pointer)를 계산**하여 backtracking 시 불필요한 탐색을 건너뜁니다.

### Scheduling과 HOL(Head-of-Line) 블로킹
패킷 분류 외에도 라우터는 switching fabric을 통해 패킷을 전달할 때 패킷 스케줄링 문제에 직면합니다.

#### HOL Blocking
하나의 큐에서 가장 앞에 있는 패킷이 블로킹되면 뒤따르는 모든 패킷의 전송이 지연됩니다.

이 때, 각 **출력 포트에 별도의 큐를 구성(Output queuing)** 하여 한 출력에 문제가 생겨도 다른 출력에는 영향을 주지 않도록 한다던가, 
**단일 물리 큐를 여러 가상 큐로 나누어(Parallel Iterative Matching)** 동시에 여러 패킷을 처리할 수 있도록 만들 수 있습니다.

#### Scheduling 알고리즘
1. **Take-the-Ticket 알고리즘**
    
    각 입력은 원하는 출력에 대해 티켓을 요청하고, 출력은 요청 받은 순서대로 티켓을 부여합니다.
    
    이 때 **한 흐름이 계속 티켓을 선점**하면 다른 흐름들은 오랜 시간 대기하게 되어 **HOL Blocking이 발생**합니다.
    
2. **Deficit Round Robin (DRR)**

    **각 흐름의 고정의 할당량(quantum)과 누적 미사용량(deficit counter)을 부여**하여 할당량 내에서 패킷을 전송하고 남은 잔여량은 다음 라운드로 이월합니다.
    이렇게 하면 각 흐름에 대해 대역폭을 공정하게 분배할 수 있습니다.
    
### Traffic Scheduling: 토큰 버킷 및 누수 버킷
라우터는 **트래픽의 전송률을 제어**하여 과도한 버스트나 혼잡을 방지해야 하는데, 이를 위해 주로 사용하는 토큰 버킷과 누수 버킷 기법에 대해 알아보겠습니다.
#### 토큰 버킷 (Token Bucket)

일정 속도로 토큰이 버킷에 축적되며 패킷 전송 시 패킷 크기에 해당하는 토큰이 소모됩니다.
버킷 최대 크기가 있어 버킷이 가득 차면 추가 토큰은 버려집니다.

이로 인해 평균 전송률을 제한하면서도 **버킷에 축적된 토큰 만큼의 버스트 전송은 허용**될 수 있습니다.

#### 누수 버킷 (Leaky Bucket)
누수 버킷은 일정한 속도로 물(패킷)이 새어나가는 버킷과 유사하게 동작합니다.
버킷이 가득 차면 새로운 패킷은 버려집니다.

트래픽을 shaping 하거나, 과도한 트래픽을 걸러내어(policing) **네트워크에 일정한 전송률을 보장**합니다.
4:T26cd,
## 인터넷 생태계의 구성 요소
오늘날의 인터넷은 단일 네트워크가 아니라 서로 연결된 여러 네트워크로 구성된 복잡한 생태계입니다.
이 생태계를 구성하는 주요 요소는 다음과 같습니다.

1. **인터넷 서비스 제공자 (ISP, Internet Service Provider)**
    
    ISP는 규모와 역할에 따라 세 가지 유형으로 나뉩니다.
    
    - **Access ISP (Tier-3)**: 최종 사용자에게 직접 인터넷 연결을 제공하는 소규모 ISP
    - **Regional ISP (Tier-2)**: 여러 access ISP를 모아 연결하며 중간 규모의 네트워크를 형성
    - **Global ISP (Tier-1)**: 전 세계에 걸쳐 **backbone 네트워크**를 운영하며, 약 10여 개의 대형 Tier-1 ISP가 존재합니다.
        작은 네트워크들은 주로 regional ISP나 access ISP를 통해 Tier-1 ISP에 연결됩니다.
    
2. **인터넷 교환 지점 (IXP, Internet Exchange Points)**
    
    IXP는 여러 네트워크(예를 들어 ISP와 CDN)가 물리적인 인프라를 통해 서로 연결되어 **트래픽을 로컬에서 교환할 수 있게 해주는 시설**입니다.
    2019년 기준 전 세계에 약 500여 개의 IXP가 존재합니다.

3. **콘텐츠 전송 네트워크 (CDN, Content Delivery Network)**

    CDN은 **콘텐츠 제공자가 최종 사용자에게 콘텐츠를 더 효율적으로 전달**하고, **연결 비용을 줄이기 위해** 구축한 네트워크입니다
    
    예를 들어, Google이나 Netflix와 같은 CDN은 전 세계에 분산된 다수의 데이터 센터와 수백 대의 서버를 보유하고 있습니다.
    
위와 같은 생태계는 기본적으로 **계층적 구조**를 띄고 있습니다.

예를 들어, 소규모 access ISP는 더 큰 regional ISP의 고객이 되며, regional ISP는 다시 Tier-1 ISP의 고객이 되는 식입니다.

각 계층의 네트워크들은 **같은 유형의 다른 네트워크와 경쟁**합니다. 예를 들어 Tier-1 ISP끼리는 서로 경쟁하고, Regional ISP 역시 서로 경쟁합니다.

동시에, 경쟁 관계에 있는 ISP들도 전 세계 **고객들에게 연결성을 제공하기 위해 상호 협력**해야 합니다. 
ISP들은 고객 수나 지리적 위치에 따라 다양한 상호 연결 전략을 사용합니다.

ISP들은 다음과 같은 추가적인 상호 연결 옵션을 사용합니다.

- **PoP (Point of Presence)**: ISP 네트워크 내에 위치한 하나 이상의 라우터로, 고객 네트워크가 해당 ISP에 접속할 때 사용합니다.
- **Multihoming**: 한 ISP가 여러 제공자 네트워크에 동시에 연결되어 보다 안정적인 연결성을 확보하는 방식입니다.
- **Peering**: 두 ISP가 별도의 비용 없이 서로의 네트워크에 직접 트래픽을 전달하기 위해 합의하는 관계입니다.

## Autonomous System (AS)
각 ISP나 CDN은 하나 이상의 Autonomous System (AS)로 운영됩니다.

AS는 **동일한 관리 권한 하에 운영되는 라우터와 그 링크의 집합**입니다.

각 AS는 자체 정책을 수립하고, 트래픽 엔지니어링 결정 및 상호 연결 전략을 구현하며, 네트워크 내/외부의 트래픽 경로를 관리합니다.

라우팅 프로토콜엔 **BGP**(외부 라우팅, Border Gateway Protocol)와 **IGP**(내부 라우팅, Internal Gateway Protocol)이 있는데 IGP에 관한 내용은 Intradomain routing algorithm 포스트에서 확인하실 수 있습니다.

### AS 간 비즈니스 관계
AS 간에는 주로 두 가지 비즈니스 관계가 존재합니다.

1. **Provider-Customer 관계 (Transit)**

    **고객 AS는 제공자 AS에게 비용을 지불**하고, 제공자 AS는 고객 AS의 트래픽을 자신의 라우팅 테이블에 포함된 목적지로 전달합니다.
    
2. **Peering 관계**

    **두 AS가 서로의 고객에게 트래픽을 전달할 때 비용 없이 직접 연결**합니다.
    피어링 관계는 트래픽이 크게 비대칭적이지 않은 경우에 형성되며, 규모가 비슷한 경우 (특히 Tier-1 간) 혹은 소규모 ISP끼리 비용 절감을 위해 이루어집니다.

또한, 제공자 AS는 고객의 트래픽 양, 즉 연결 대역폭을 기반으로 과금 방법이 달라질 수 있습니다:

- **고정 가격 방식**: 미리 정해진 범위 내의 대역폭 사용 시 일정 비용을 청구합니다.
- **실제 사용량 기반 방식**: 주기적인 측정을 통해 95th percentile을 기준으로 비용을 산정합니다.
    
어떤 경우에는 라우팅 정책이 고객 트래픽의 양을 늘려 제공자의 수익을 극대화하기 위해 설계되기도 합니다.

## BGP Routing 정책
BGP에서 한 AS가 어떤 경로를 외부에 광고(Export)하고, 어떤 경로를 수신(Import)할지는 중요한 결정입니다.

### 경로 광고(Export)
- **고객으로부터 학습한 경로**
    
    고객 AS로부터 받은 경로는 **가능한 한 많은 이웃 AS에 광고**해서 고객 트래픽이 더 많이 유입되도록 합니다.

- **제공자 또는 피어로부터 학습한 경로**

    이 경우, 해당 경로는 비용 문제가 있기 때문에 일반적으로 **고객에게만 광고**하고 다른 제공자나 피어에게는 광고하지 않습니다.

### 경로 수신(Import)
여러 AS로부터 동일 목적지에 대한 경로를 수신할 경우, 우선순위는 보통 다음과 같이 결정됩니다:
1. 고객 경로
2. 피어 경로
3. 제공자 경로

이런 우선순위는 **불필요하게 다른 AS를 경유하지 않도록** 하여 비용을 최소화 하는 것이 목적입니다.

### 기본 개념
#### BGP 세션
BGP 세션은 **두 라우터(피어)가 TCP 연결을 통해 반영구적으로 유지하면서 라우팅 정보를 교환하는 연결**입니다.

**eBGP(External BGP)** 는 서로 다른 AS 간의 border router들이 설정하는 세션이고, **iBGP(Internal BGP)** 는 동일한 AS 내에서 내부 라우터들 간에 설정하는 세션입니다.

#### BGP 메시지
BGP 세션이 수립되면 다음과 같은 메시지가 교환됩니다:

- **UPDATE** 메시지
    
    **Announcement**: 새로운 경로 또는 기존 경로 업데이트를 광고
    
    **Withdrawal**: 이전에 광고한 경로가 더 이상 유효하지 않을 때 전송
    
- **KEEPALIVE** 메시지
    
    세션 유지를 위해 주기적으로 교환

#### 경로 속성
- **AS-PATH**: 경로가 거쳐온 AS 번호들의 목록으로, 루프를 방지하고 최단 경로를 선택하는 데 사용됩니다.
- **NEXT-HOP**: 목적지까지의 다음 홉 라우터의 IP 주소를 나타내며, 내부 라우터는 이를 사용해 최종 목적지로 트래픽을 전달합니다.

### BGP 결정 과정
라우터가 동일한 목적지에 대해 여러 경로를 수신할 경우, BGP는 여러 속성을 기준으로 최적의 경로를 선택합니다.

- **LocalPref (Local Preference)**

    **같은 AS 내에서 외부 경로를 선택할 때** 어떤 경로를 우선 사용할지를 결정합니다.
    
    예를 들어, 특정 AS로부터 학습한 경로에 **높은 LocalPref 값을 부여하면 그 경로가 우선 선택**되어 트래픽의 출구 지점으로 사용됩니다.
    
- **MED (Multi-Exit Discriminator)**

    여러 연결 지점이 존재할 때, **인바운드 트래픽이 어느 링크를 통해 들어올지 결정**하는데 사용됩니다.
    
    **낮은 MED 값을 가진 링크가 선호**되며 이는 AS 간의 여러 연결 상황에서 인바운드 경로를 조정하는 데 도움을 줍니다.
    
이 외에도 각 AS는 자체 정책과 비즈니스 관계에 따라 경로의 광고 및 수신을 제어합니다.

## IXP와 피어링
IXP는 **여러 AS가 물리적 인프라를 통해 서로 연결되어 트래픽을 교환**할 수 있도록 지원해줍니다.
대규모 IXP일 경우, 수만 개의 피어링 링크가 존재하며 일일 트래픽 양은 글로벌 Tier-1 ISP 수준에 필적할 정도입니다.

IXP는 DDoS 공격 완화 역할도 수행하며 여러 연구와 실제 운영에서 중요한 역할을 하고 있습니다.


### 피어링 방법
1. 각 AS는 공개 AS 번호(ASN)을 보유해야 하며 IXP 시설에 라우터를 배치하여 IXP 스위치에 연결합니다.
2. BGP를 실행할 수 있어야 하며 IXP의 약관 (GTC)에 동의해야 합니다.
3. 비용 측면에서는 초기 회선 구축 비용, 월별 포트 사용 요금, 경우에 따라 연회비 등이 발생할 수 있으나 실제 트래픽 교환은 대체로 정산 없이 (settlement-free) 이루어집니다.

### 제공 서비스
- **Public peering**: IXP 인프라를 통해 다수의 AS와 비용 부담 없이 트래픽을 교환하는 서비스
    
- **Private peering**: 두 AS 간 전용 회선을 통한 트래픽 교환
    
- **Route server**: 다수의 AS 간 피어링 세션을 중앙에서 관리하여 BGP 세션 수를 줄이고 multilateral peering 지원
    
- **Remote peering**: 물리적으로 IXP에 직접 참여하지 않더라도 제3자를 통해 IXP에 접속하는 방식

### 검증
BGP는 복잡하고 다양한 라우터 제조사의 설정 언어에 따라 달라지기 때문에 오작동이나 Misconfiguration이 발생할 수 있습니다.

이 때, BGP가 올바르게 동작하는지는 **경로 가시성(path visibility)** 과 **경로 유효성(route validity)** 으로 평가할 수 있습니다.

Path visibility는 **목적지까지의 경로가 네트워크 내에서 올바르게 전파되는 지**를 확인하는 것이고, Route validity는 **목적지로 트래픽이 실제 도달하는 지**를 확인하는 것입니다.

이를 사전에 점검하기 위해 RCC(Router Configuration Checker)와 같은 도구가 사용되며, 정적 분석을 통해 구성 오류를 사전에 탐지할 수 있습니다.

5:T33dc,
## 개요
네트워크의 근본적인 목표는 **두 호스트 간의 데이터 전송을 가능하게 하는 것**입니다.
이를 위해 데이터를 출발지에서 목적지까지 효율적으로 전달하는 **최적의 경로**를 찾는 것이 중요합니다.

이번 글에서는 단일 관리 도메인 내 라우터들 간 최적의 경로를 결정하는 **인트라도메인 라우팅 알고리즘**에 대해 알아보도록 하겠습니다.

## 라우팅 알고리즘

TCP 또는 UDP를 이용해 연결이 설정된 두 호스트를 예로 들어보겠습니다.

각 호스트는 **기본 라우터 (default router)** 를 알고 있으며, 패킷을 전송할 때 먼저 이 기본 라우터로 보냅니다.
하지만 **기본 라우터를 지난 후에는 어떤 일이 일어날까요?**

패킷이 출발지에서 목적지로 이동하는 동안, 각 **중간 라우터는 패킷을 적절한 다음 라우터로 전달하는 역할**을 합니다.

패킷이 라우터에 도착하면 라우터는 **포워딩 테이블 (Forwarding table)** 을 참조하여 해당 패킷을 어느 인터페이스를 통해 전송할지 결정합니다.
여기서 **포워딩**은 **라우터 내에서 패킷을 들어오는 링크에서 나가는 링크로 전달하는 과정**을 의미합니다.

반면 **라우팅**은 라우터들이 **라우팅 프로토콜을 사용하여 최적의 경로를 설정하는 과정**을 의미합니다.
만약 동일한 관리 도메인에 속한 라우터들 간의 경로를 설정하는 경우, 이를 **인트라도메인 라우팅** 또는 **Interior Gateway Protocol(IGP)** 라고 합니다.
서로 다른 관리 도메인에 속한 라우터들이 협력하여 경로를 결정하는 경우, 이건 **인터도메인(interdomain) 라우팅**이라고 합니다.

이번 글에서는 **인트라도메인 라우팅 알고리즘**을 중심으로 살펴볼텐데, 보다 쉽게 이해하기 위해서 네트워크를 그래프로 모델링할 수 있습니다.

이 때 **라우터는 노드(node)** 로 표현 되고, **라우터간의 연결(link)는 엣지(edge)** 로 표현할 수 있습니다.
그리고 각 엣지에는 특정한 **비용(cost)** 이 할당됩니다.

## Link-state Routing Algorithm
링크 상태 알고리즘에서는 **다익스트라 알고리즘**을 기반으로 하여 출발지에서 모든 노드까지의 최단경로 트리(Shortest Path Tree, SPT)를 구성합니다. 
여기서는 **네트워크 내 모든 노드가 전체 네트워크 토폴로지와 링크 비용**을 알고 있고, 이 정보는 **브로드캐스트**를 통해 모든 노드에게 전달됩니다.

#### 기본 용어
     u: 출발지 노드(기준 노드)
     v: 네트워크 내의 모든 다른 노드
     D(v): 출발지 노드 u에서 v까지 현재 알려진 최소 비용 경로
     p(v): 출발지 노드 u에서 v까지 현재 최소 비용 경로에서 v 바로 직전의 노드
     c(u, v): 출발지 노드 u에서 직접 연결된 이웃 v까지의 비용
     N': 출발지 노드 u에서 현재까지 확정된 최소 비용 경로에 포함된 노드의 집합
#### 알고리즘
1. **초기화**

    **다익스트라 알고리즘(Dijkstra's algorithm)** 은 먼저 **출발지 노드 `u`의 직접 연결된 이웃들에 대한 비용을 설정**하는 단계로 시작됩니다.
    출발지 `u`와 직접 연결된 노드는 링크 비용을 그대로 사용하고, 연결되지 않은 노드들은 무한대 값으로 설정됩니다.
    
    또한, `N'`은 처음에 출발지 노드 u만 포함하도록 설정됩니다.

2. **반복 연산**
    
    초기화 이후에는 반복문을 통해 **모든 목적지 노드 `v`에 대해 경로를 찾는 과정**을 거칩니다.
    
    먼저 아직 `N'`에 포함되지 않은 노드 중에서 현재까지의 최소 비용을 가진 노드 `w`를 선택하고, 그 노드를 `N'` 집합에 추가합니다.
    
    그리고 `w`의 모든 이웃 노드 `v`에 대해 `D(v)`를 업데이트 합니다.
    
    `D(v)`의 값은 기존 `D(v)` 값과, 현재까지의 최소 비용 경로 `D(w)`에 대해 `w`에서 `v`까지의 비용을 더한 값 중 작은 값으로 갱신됩니다.

    `D(v) = min(D(v), D(w) + c(w,v))`
    
    위 과정을 네트워크의 모든 노드가 `N'`에 포함될 때까지 반복합니다.

최종 결과로 **출발지 `u`에서 모든 노드까지의 최단경로 트리**를 구성하게 됩니다.

#### 계산 복잡도
이 알고리즘에서 최단 경로를 찾기위해 수행해야 하는 주요 연산은 **최소 비용을 가지는 노드를 찾는 것**과 **해당 노드를 기준으로 다른 노드들의 경로 비용을 업데이트하는 것**으로 나눌 수 있습니다.

1. 첫 번째 iteration에서는 전체 n개의 노드 중에서 최소 비용을 가지는 노드를 찾아야 합니다.
2. 두 번째 iteration에서는 남아있는 n-1 개의 노드 중에서 최소 비용 노드를 찾습니다.
3. 세 번째 iteration에서는 n-2개를 탐색하고, 이런 식으로 마지막에는 1개의 노드만 남습니다.

따라서 전체적으로 탐색해야 하는 노드 개수는 다음과 같습니다:

**`n + (n - 1) + (n - 2) + ... + 1 = n(n+1)/2`**

따라서 최악의 경우 O(n^2)의 시간 복잡도를 가지는데, 이 복잡도를 개선하기 위해 priority queue를 사용하면 최소 비용 노드를 찾는 연산을 O(log n)으로 줄일 수 있습니다.

하지만 **기본적인 다익스트라 알고리즘에서는 O(n^2) 이므로, 일반적인 링크 상태 라우팅의 시간 복잡도도 같다**고 할 수 있습니다.

또한, 출발지 노드가 u가 아닌 x인 경우에도, 이웃의 수가 달라도 알고리즘은 모든 노드가 포함될 때까지 동일한 반복 횟수를 수행합니다.

## Distance-Vector Routing Algorithm
거리 벡터 라우팅 알고리즘은 **반복적, 비동기적, 분산적** 방식으로 동작하는 방식입니다.

이 알고리즘은 **Bellman-Ford 알고리즘**을 기반으로 하는데, 각 라우터는 자신이 목적지까지 도달하는 비용 정보를 담은 거리 벡터를 유지하고
이 정보를 정기적으로 이웃 노드들과 교환하면서 네트워크의 최적 경로를 계산합니다.

#### 알고리즘
1. **초기화**

    먼저, 각 노드는 **자신이 직접 연결된 이웃 노드들과의 링크 비용을 기반으로 초기 거리 벡터를 설정**합니다.
    이웃하지 않은 노드에 대해서는 비용을 무한대로 설정합니다.

2. **거리 벡터 교환 및 업데이트**

    그 후, 각 노드는 **주기적으로** 또는 **링크 상태 변경이 감지**될 때 자신의 거리 벡터를 이웃 노드들에게 보냅니다.
    
    이웃 노드들은 수신한 거리 벡터를 기반으로 자신의 거리 벡터를 다음의 Bellman-Ford 방정식을 사용하여 업데이트합니다:
        **`Dx(y) = min{c(x,v) + Dv(y)}`**
    
    즉, 노드 `x`가 목적지 `y`에 도달하는 최소 비용을 구하기 위해 **이웃 노드 `v`를 거쳐 가는 최소 경로**들을 고려합니다.

3. **수렴**

    네트워크 내 모든 라우터가 더 이상 새로운 업데이트를 받지 않아 **각자의 거리 벡터가 변경되지 않을 때** 최종 라우팅 테이블이 완성됩니다.

거리 벡터 라우팅 알고리즘은 **구현이 간단하고 오버헤드가 적다**는 장점이 있지만
네트워크 변경이 있을 경우 안정화 하는데 **시간이 오래 걸릴 수** 있는 단점이 있습니다.

반면에 링크 상태 라우팅 알고리즘은 네트워크 전체의 토폴로지를 공유하여 **더 빠르고 안정적인 경로 설정**이 가능합니다.

### Count-to-Infinity 문제
거리 벡터 라우팅 알고리즘에서는 각 라우터가 주기적으로 자신의 거리 벡터를 이웃 라우터들에게 공유하고, 이를 기반으로 최적 경로를 갱신합니다.

하지만 **링크 비용이 급격히 증가할 경우**, 잘못된 경로 정보가 반복적으로 업데이트되면서 두 개 이상의 노드가 서로를 통해 목적지에 도달한다고 잘못 판단하며 비용이 점진적으로 증가하는 **무한 루프 현상**이 발생할 수 있습니다.

이를 해결하기 위해 **Split Horizon**이나 **Poison Reverse** 방법을 사용할 수 있습니다.
#### Poison Reverse
```
            [X]
           /   \
      (비용 4)  (비용 5)
         /         \
      [Y]  <---->   [Z]
```
여기서 Y와 Z는 각각 X로 가는 경로를 가지고 있으며, 서로 정보를 교환합니다.
만약 Z가 X로 가는 최적 경로가 Y를 통해서라고 판단한다면, Z는 Y의 정보를 참고하여 경로를 설정합니다.

예를 들어, Y와 X 사이의 직접 연결 비용이 급격하게 증가하여 4에서 60이 되었다고 가정해봅시다.
Y는 직접 연결 비용이 높아졌으므로, “혹시 Z를 통해 X에 도달할 수 있지 않을까?” 하고 Z의 정보를 확인하게 됩니다.
만약 Z 역시 Y를 통해 X에 도달하는 경로를 사용 중이라면, 잘못된 업데이트로 인해 Y와 Z가 서로를 참조하는 루프가 발생할 수 있습니다.
```
                  [X]
                 /   \
        (직접 비용 60)  (직접 비용 5)
               /           \
            [Y]  <------>   [Z]
                    ↑
    (Poison Reverse: Z는 Y에게 X 비용을 ∞로 전달)
```
Poison Reverse 기법을 사용하면 **라우터 Z는 자신이 X로 가는 최적 경로가 Y를 경유하는 경우, Y에게 “X로 가는 비용이 ∞입니다”라고 광고**합니다.
이렇게 되면, Y는 Z로부터 받은 정보에 따라 “내가 X로 가기 위해 Z를 경유하는 것은 불가능하다(비용이 무한대)”고 판단하여, 루프 형성을 방지할 수 있습니다.

단, 이 방법은 두 노드 간의 문제 해결에는 효과적이지만 3개 이상의 노드가 관련된 경우에는 해결책이 되지 않습니다.

## Routing protocol 예제
### RIP (Routing Information Protocol)
RIP는 거리 벡터 알고리즘을 기반으로 하는 애플리케이션 레벨 프로세스 프로토콜로, **홉 수(Hop count)** 를 메트릭으로 사용합니다. 

인접 라우터 간에 주기적으로 RIP 응답 메시지를 통해 자신의 거리 벡터(목적지까지의 홉 수 정보)를 교환하고, 
각 라우터는 목적지 서브넷, 해당 목적지로 가기 위한 최단 경로상의 다음 라우터, 그리고 홉 수 정보를 포함하는 라우팅 테이블을 유지합니다.

만약 라우터가 **일정 시간동안 인접 라우터로부터 업데이트를 받지 못하면**, 해당 이웃을 연결이 끊긴 것으로 간주하고 라우팅 테이블을 갱신합니다.

하지만 **경로 업데이트의 지연, 수렴 시간, 그리고 count-to-infinity 문제** 등이 RIP의 단점으로 지적됩니다.

### OSPF (Open Shortest Path First)
OSPF는 링크 상태 라우팅 프로토콜로 대규모 네트워크나 ISP (Internet Service Provider) 환경에서 주로 사용됩니다.

OSPF에서는 모든 라우터가 **Link State Advertisement (LSA)** 를 통해 자신과 입접 라우터의 링크 상태를 브로드캐스트하고, 전체 네트워크의 토폴로지를 구성합니다.

여기서 네트워크를 여러 영역으로 나눌 수 있으며, 이 중 하나의 영역은 **백본 영역(Backbone area)** 으로 지정되어 다른 영역 간의 라우팅을 담당합니다.

각 라우터는 다익스트라 알고리즘을 사용하여 **자신을 기준으로 SPT를 구성**하고, 이를 기반으로 **포워딩 정보(FIB)를 업데이트** 합니다.

링크 상태 변화가 감지되면 즉시 LSA를 플러딩하여 네트워크 전체에 전파하며, 정기적으로도 갱신됩니다.

#### OSPF 메시지 처리 과정
1. **LS 업데이트 수신**
    
    인접 라우터로부터 LS 업데이트 패킷(여러 LSA 포함)을 수신하면 OSPF processor가 이를 분석하여 새로운 LSA인지 중복 LSA인지를 확인합니다. 
    
2. **링크 상태 데이터베이스 갱신 및 SPF 예약**
    
    새로운 LSA일 경우, **링크 상태 데이터베이스를 갱신**하고, 이후 다익스트라 기반의 **SPF 계산을 예약**합니다.
    
3. **LSA 플러딩**
    
    처리된 LSA는 적절한 인터페이스를 통해 인접 라우터로 다시 플러딩 됩니다.
    
4. **SPF 계산 및 FIB 업데이트**

    예약된 SPF 계산이 실행되어 SPT를 구성하고, 그 결과가 FIB에 저장됩니다.
    
5. **데이터 패킷 전달**

    업데이트된 FIB를 참고하여 실제 데이터 패킷이 적절한 인터페이스로 전송됩니다.

## Hot Potato Routing
대규모 네트워크에서는 내부 라우팅(IGP)와 외부 라우팅(BGP)이 함께 사용됩니다.

목적지가 네트워크 외부인 경우, 네트워크 내부에서는 여러 개의 출구 지점(egress point) 중 **IGP 비용이 가장 낮은**,
즉 **가장 가까운 출구를 선택하여 패킷을 빠르게 외부로 내보내는 방식**을 Hot Potato Routing이라고 합니다.
6:Te56,
인터넷 프로토콜 스택은 모래시계 형태의 계층 구조를 가지고 있습니다. 하지만 인터넷 아키텍쳐가 처음부터 이런 구조를 가지고 있었던 것은 아닙니다.

1990년대 초반까지만 해도 인터넷의 네트워크 계층은 IPv4 하나로 통일된 것이 아니라, **여러 개의 경쟁 프로토콜이 존재했던 시기**였습니다.
예를 들어, IPX(Internetwork Packet Exchange), X.25 Frame Relay Protocol 등이 IPv4와 경쟁하며 사용되었는데 시간이 지나면서 다른 프로토콜들은 점점 사라지게 되었습니다.

인터넷 프로토콜 스택이 모래시계 모양을 갖게 된 이유는 **상위 계층(애플리케이션 계층)과 하위 계층(물리 계층)의 변화는 활발하게 이루어지는 반면, 중간 계층(네트워크/전송 계층)은 오랜 기간 유지되었기 때문**입니다.

#### 상위 계층에서의 혁신
애플리케이션 계층에서는 새로운 서비스와 프로토콜이 지속적으로 등장하고 사라지는 것이 일반적입니다. 
웹 브라우징을 위한 **HTTP/HTTPS**, 파일 전송을 위한 **FTP**, 이메일을 위한 **SMTP, IMAP, POP3** 등 수많은 프로토콜이 등장했고, 최근에는 **RESTful API, gRPC** 등 새로운 애플리케이션 계층 기술도 발전하고 있습니다.
애플리케이션 계층은 새로운 사용자 요구사항과 기술 발전에 맞춰 빠르게 변화하기 때문에 지속적인 혁신이 이루어집니다.

#### 하위 계층에서의 변화
물리 계층도 새로운 전송 매체가 등장하면서 지속적으로 변화하고 있습니다.
데이터 전송 속도를 높이고, 더 안정적인 네트워크를 구축하는 것이 주요 목표이기 때문에 하드웨어 기술이 발전함에 따라 새로운 프로토콜과 기술이 빠르게 도입됩니다.

### 중간 계층의 안정성: IPv4, UDP, TCP가 쉽게 바뀌지 않는 이유
네트워크 및 전송 계층은 인터넷의 핵심 기능을 담당하며, **모든 상위 및 하위 계층이 이 계층에 의존**하기 때문에 쉽게 대체되기 어렵습니다.

1. **호환성과 네트워크 효과**
    - 네트워크 계층에서 하나의 프로토콜이 표준으로 자리 잡으면, 모든 네트워크 장비(라우터, 스위치, 서버 등)가 이를 지원해야 합니다.
    - IPv4는 초기에 널리 채택되었고, 이후 네트워크 인프라 대부분이 IPv4를 기반으로 구축되었기 때문에 다른 네트워크 계층 프로토콜이 경쟁에서 도태되었습니다.
    - 전송 계층에서도 TCP/UDP가 거의 모든 인터넷 애플리케이션에서 사용되었기 때문에, 새로운 전송 계층 프로토콜이 등장하더라도 기존의 네트워크와 호환성을 유지하는 것이 어렵습니다.
2. **대체 비용이 높음**
    - 새로운 네트워크 계층 프로토콜이 등장했더라도, 기존의 인프라와 완전히 호환되지 않으면 적용하기 어렵습니다.
    - IPv6은 1990년대부터 개발되었지만, 여전히 IPv4가 널리 이용되는 이유도 기존 인프라와의 호환성 문제와 전환 비용 때문입니다.
3. **핵심 기능의 단순성**
    - 네트워크 계층의 역할은 **데이터를 최적의 경로를 통해 전달**하는 것입니다.
    - 전송 계층의 TCP와 UDP는 각각 **신뢰성이 필요한 통신**과 **빠른 데이터 전송이 필요한 통신** 이라는 단순하고 강력한 역할을 수행합니다.
    - 이러한 기본적인 기능이 잘 동작하기 때문에 새로운 프로토콜을 도입할 유인이 적습니다.
7:T130b,
컴퓨터 네트워크에는 호스트 간 연결을 제공하거나 서로 다른 네트워크를 연결하는 다양한 장치들이 존재합니다.
이러한 장치들은 서로 다른 계층에서 동작하며, 각각 고유한 기능과 한계를 가지고 있습니다.

## 계층별 장치
### 물리 계층 (L1) 장치: 리피터(Repeater)와 허브(Hub)
리피터와 허브는 **물리 계층**에서 동작하는 장치로, **디지털 신호를 수신하고 그대로 재전송하여 ethernet 세그먼트 간 연결을 제공**합니다.

**리피터**는 신호가 약해지는 것을 방지하기 위해 신호를 증폭하여 전달하는 역할을 합니다.

**허브**는 여러 호스트를 물리적으로 연결하는 장치로, 수신된 데이터를 네트워크에 연결된 모든 장치로 전달합니다.

이런 장치들은 대부분 **단순하고 저렴하며, 계층적으로 구성할 수 있다는 장점**이 있습니다. 
하지만, **연결된 모든 호스트가 동일한 충돌 도메인(Collision domain)에 족하게 되어 하나의 링크를 공유하는 방식으로 데이터 충돌이 발생할 가능성이 높습니다.**

### 데이터 링크 계층 (L2) 장치: 브릿지(Bridge)와 L2 스위치(L2 Switch)
브릿지와 스위치는 **데이터링크 계층**에서 동작하며, **MAC 주소를 기반으로 패킷을 전달**하는 역할을 합니다.

**브릿지**는 두 개의 네트워크 세그먼트를 연결하며 수신한 패킷의 MAC 주소를 확인하여 적절한 포트로 전달합니다.

**L2 스위치**는 여러 개의 포트를 가지고 있으며, 각 포트마다 MAC 주소를 학습하여 목적지 MAC 주소에 따라 패킷을 전송합니다.

이 장치들은 **직접 연결되지 않은 호스트 간의 통신을 가능**하게 하며, 네트워크 충돌을 줄이는 역할을 합니다.
하지만 출력 포트의 대역폭이 제한되어 있어 **트래픽 도착 속도가 출력 용량을 초과하면 버퍼링이 필요**하며, **버퍼가 가득 차면 패킷 손실이 발생**할 수 있습니다.

#### 학습 브릿지 (Learning Bridge)
브릿지는 여러 개의 입출력을 가지고 있는데, 모든 프레임을 무조건 전송하는 것이 아니라 학습 과정을 통해 목적지에 따라 프레임을 선택적으로 전달할 수 있습니다.

이를 위해 **포워딩 테이블**을 유지하며 프레임이 불필요한 포트로 전달되는 것을 방지합니다.


**브릿지의 프레임 전달 방식**
1. 브릿지는 처음에 모든 포트를 통해 프레임을 전달합니다. (Unknown unicast)
2. 수신된 프레임의 출발지 주소를 확인해서 **해당 호스트가 어느 포트에 위치하는지 학습**합니다.
3. 포워딩 테이블을 구축해서 이후엔 필요한 포트로만 프레임을 전달합니다.
4. 동일한 포트에 있는 호스트 간의 통신은 해당 포트 내에서만 처리하여 네트워크 트래픽을 최적화합니다.

#### 스패닝 트리 알고리즘과 루프 방지
브릿지를 사용하여 LAN을 확장하는 경우 **네트워크 내에 루프가 발생하면 패킷이 무한히 순환하는 문제가 발생**할 수 있습니다.
이는 브릿지가 들어오는 프레임을 여러 개의 포트로 중복 전송하면서 발생하는 현상입니다.

이 문제를 해결하기 위해 **스패닝 트리 알고리즘**을 사용할 수 있습니다. 
이 알고리즘은 **네트워크 토폴로지를 트리 형태로 변환**하여 루프를 제거하는 역할을 합니다.

스패닝 트리 알고리즘은 아래와 같이 동작합니다.
1. 모든 브릿지가 초기에는 자신을 루트로 간주하고 메시지를 보냅니다.
2. 네트워크 내에서 가장 작은 ID를 가진 브릿지가 루트 브릿지로 선택됩니다.
3. 각 브릿지는 루트까지의 최단 경로를 찾고, 그 정보를 업데이트하여 공유합니다.
4. 루프를 방지하기 위해 일부 링크(포트)가 비활성화 됩니다.
5. 결과적으로 트리 구조가 형성되며 패킷 루프 문제가 해결됩니다.

### 네트워크 계층 (L3) 장치: 라우터(Router)와 L3 스위치 (L3 Switch)
라우터와 L3 스위치는 **IP 주소를 기반으로 서로 다른 네트워크 간의 데이터 전달을 수행**합니다.
이 장치들은 네트워크를 여러 개의 서브넷으로 분할하여 트래픽을 효율적으로 관리할 수 있도록 도와주고, **라우팅 프로토콜을 사용하여 패킷을 최적의 경로로 전달**합니다.

**라우터**는 IP 주소를 확인하여 최적의 경로를 선택하고, 패킷을 전달하는 기능을 수행합니다.

**L3 스위치**는 라우팅 기능이 포함된 스위치로, 일반적인 L2 스위치보다 더 빠른 속도로 IP 패킷을 전달할 수 있습니다.

8:T10ed,
## 멀티플렉싱/디멀티플렉싱
전송 계층의 주요 기능 중 하나는 **한 호스트에서 여러 애플리케이션이 동시에 네트워크를 사용할 수 있도록 하는 멀티플렉싱** 기능입니다.

멀티플렉싱은 **송신 호스트**가 여러 **애플리케이션의 데이터를 수집하고, 이를 전송 계층 세그먼트로 변환**하는 과정입니다. 

반대로, 디멀티플렉싱은 **수신 호스트**가 네트워크 계층에서 전달받은 **세그먼트를 확인하고, 올바른 애플리케이션으로 데이터를 전달**하는 과정입니다.

### 멀티플렉싱이 필요한 이유
컴퓨터에서 여러 애플리케이션이 동시에 네트워크를 사용할 때, **각 애플리케이션이 올바른 데이터 패킷을 받도록 보장**하는 것이 중요합니다.

예를 들어 한 사용자가 인스타그램을 사용하면서 동시에 spotify에서 음악을 듣고 있다면 두 개의 애플리케이션이 각각 다른 서버와 데이터를 송수신해야 합니다.

하지만 네트워크 계층에서는 오직 IP 주소만 사용하기 때문에, **패킷이 어떤 애플리케이션으로 전달되어야 하는지**를 구분할 수 없습니다.

#### 멀티플렉싱 동작 원리

전송 계층에서는 각 애플리케이션을 구분하기 위해 **포트 번호**를 사용합니다.
1. 각 애플리케이션은 고유한 포트 번호를 할당받고, 이를 통해 통신을 진행합니다.
2. 애플리케이션이 네트워크를 사용할 때, 소켓을 열어서 특정 포트에서 데이터를 수신하도록 설정합니다.
3. 따라서 패킷이 도착하면 **전송 계층은 포트 번호를 확인하고 해당 포트와 연결된 애플리케이션으로 데이터를 전달**합니다.


만약 위 예제 사용자의 상황이라면 전송 계층은 **각 애플리케이션이 사용하는 포트 번호**를 기반으로 데이터를 분류해서 처리해야 합니다.
- 인스타그램 -> 포트 443 (HTTP) 사용
- spotify -> 포트 4070 사용

전송 계층은 이 정보를 기반으로 **멀티플렉싱하여 패킷을 송신**하고, **수신 측에서는 디멀티플렉싱**하여 해당 애플리케이션으로 데이터를 전달합니다.
### 멀티플렉싱 종류
멀티플렉싱 방식은 **연결을 설정하는지 여부**에 따라 두 가지로 나뉩니다.

1. **비연결형 (Connectionless) 멀티플렉싱**
    - **UDP 기반** 멀티플렉싱
    - 송신자가 수신자와 연결을 설정하지 않고 바로 데이터를 전송
    - **패킷 손실 가능성이 있지만 빠르고 간단**한 방식
    - DNS, VoIP, 온라인 게임 등에서 사용
2. **연결형 (Connection-Oriented) 멀티플렉싱**
    - **TCP 기반** 멀티플렉싱
    - 송신자와 수신자가 먼저 연결을 설정한 후 데이터를 전송 **(3-way handshake)**
    - **데이터의 신뢰성과 순서** 보장
    - 웹 브라우징, 이메일, 파일 전송 등에서 사용
    
## 전송 계층의 소켓 식별 방법
전송 계층은 소켓을 식별하기 위해 세그먼트의 특정 필드를 활용합니다. 

### UDP의 소켓 식별 방법
UDP는 `Two-Tuple`을 사용하여 소켓을 식별합니다. 

UDP 소켓은 **목적지 IP 주소**와 **목적지 포트 번호**로 구분되는데, 송신 호스트가 **어떤 출발지 포트를 사용하든 상관없이** 동일한 목적지 포트로 전송된 데이터는 같은 소켓으로 전달됩니다. 

따라서 **여러 호스트가 동일한 서버의 같은 포트**로 데이터를 보낼 수도 있습니다.

### TCP의 소켓 식별 방법
TCP는 `Four-Tuple`을 사용하여 소켓을 식별합니다.

TCP 소켓은 **출발지 IP 주소, 출발지 포트, 목적지 IP, 목적지 포트**로 구분됩니다.

즉, 같은 서버의 동일한 포트로 여러 클라이언트가 접속하더라도, **각 클라이언트의 출발지 IP 및 포트가 다르므로 개별적인 연결을 유지**할 수 있습니다.

### 웹 서버에서의 멀티플렉싱
웹 서버는 하나의 포트에서 다수의 클라이언트 요청을 처리해야 합니다. 이를 위해 웹 서버는 다수의 클라이언트의 동시 접속을 각기 다른 세션으로 구분하여 처리할 수 있습니다.

9:T52ed,

## 3-Way Handshake
TCP는 신뢰성을 보장하는 연결 지향형 프로토콜로, 데이터를 전송하기 전에 **반드시 연결을 설정**하는 과정을 거쳐야 합니다.

이때 사용하는 방식이 **3-way handshake** 입니다. 
이 과정에서는 클라이언트와 서버가 서로 통신이 가능한 상태인지 확인하고, 데이터 전송을 위한 준비를 완료합니다.

1. 먼저 클라이언트는 서버에 **연결 요청(SYN 패킷)** 을 보냅니다. 
이때 **SYN 플래그를 1**로 설정하고, **초기 순서 번호(ISN, Initial Sequence Number)** 를 포함하여 서버로 전송합니다.

2. 서버는 이 요청을 수락한 후, **SYN-ACK 패킷**을 응답합니다.
이 패킷에는 클라이언트의 **ISN에 1을 더한 값**과 **서버의 ISN**이 포함됩니다.

3. 마지막으로, 클라이언트는 서버의 응답을 확인한 후 **ACK 패킷**을 다시 서버로 전송합니다.

이렇게 TCP 3-way handshake가 완료되면, 클라이언트와 서버는 신뢰할 수 있는 데이터 전송을 시작할 준비가 완료됩니다.

### 4-Way Handshake
TCP 연결이 설정되었다면 **연결 종료 시에도 신뢰성을 보장**하기 위해 4단계 과정을 거치게 됩니다. 이를 **4-way Handshake**라고 합니다.

1. 먼저, 클라이언트가 더 보낼 데이터가 없을 경우 **FIN 패킷**을 서버로 전송합니다.

2. 서버는 이 요청을 수락한 후, **ACK 패킷**으로 응답합니다.
이 단계에서 서버는 클라이언트의 연결 종료 요청을 수락했지만 아직 데이터를 보낼 수 있는 상태입니다.

3. 서버도 더 이상 보낼 데이터가 없을 경우, **FIN 패킷**을 클라이언트로 전송합니다.

4. 클라이언트는 서버의 FIN 패킷을 수신한 후, **ACK 패킷**을 서버로 전송하며 연결 종료를 완료합니다.
이 과정에서 TCP는 신뢰성을 보장하기 위해 **일정 시간 동안 대기**한 후 최종적으로 연결을 종료합니다.

## TCP의 신뢰성 보장
**네트워크 계층은 기본적으로 신뢰성이 보장되지 않기** 때문에 패킷이 손실되거나 순서가 뒤바뀌어 도착할 가능성이 있습니다.
이러한 문제는 일부 패킷이 유실되면 파일이 손실될 수 있기 때문에 파일 다운로드와 같은 애플리케이션에서 심각한 영향을 줄 수 있습니다.

이 문제를 해결하는 방법 중 하나는 UDP처럼 애플리케이션 개발자가 직접 네트워크 손실을 감지하고 복구하도록 하는 것입니다.
하지만 신뢰성이 중요한 서비스에서는 TCP를 사용하는 것이 훨씬 더 효율적입니다. 
TCP는 **데이터가 손실되지 않고, 순서대로 도착하고, 오류 없이 전달**되는 것을 보장합니다.

TCP에서 신뢰성을 보장하려면 송신 측에서 수신 측이 어떤 데이터를 정상적으로 받았는지, 어떤 데이터가 손실되었는지를 알아야 합니다.
이를 위해 **ACK**을 사용합니다.

수신 측은 받은 데이터를 확인하는 메시지를 송신 측에 보내고, 만약 송신 측이 일정 시간 내에 ACK을 받지 못하면 해당 패킷이 손실된 것으로 간주하고 재전송합니다.
이를 **자동 재전송 요청 (ARQ, Automatic Repeat reQuest)** 이라고 합니다.

### 신뢰성 보장 기법
1. **Stop-and-Wait ARQ (정지 대기 ARQ)**: 가장 단순한 방식으로, **송신 측이 하나의 패킷을 보낸 후 수신 측의 ACK을 기다렸다가 다시 다음 패킷을 보내는 방식**입니다.
하지만 이 방법은 대기 시간이 길어질 경우 전송 속도가 매우 느려진다는 단점이 있습니다.
2. **Sliding window** 방식: stop-and-wait의 단점을 개선하기 위해 **한 번에 여러 개의 패킷을 전송**할 수 있도록 한 방법입니다.
송신 측이 미리 **정해진 윈도우 크기(Window size) 만큼의 패킷**을 연속으로 보내고, 수신 측으로부터 ACK을 받으면 추가적인 패킷을 전송할 수 있습니다.

### 데이터 손실 복구 방식
1. **Go-Back-N** 방식: 수신 측이 **받은 패킷의 순서가 맞지 않으면 그 이후의 모든 패킷을 폐기**하고, 송신 측은 **폐기된 패킷 이후의 모든 데이터를 다시 전송**하는 방식입니다.
이 방식은 간단하지만 하나의 패킷이 손실될 경우 많은 데이터를 다시 전송해야 하는 비효율적인 점이 있습니다.
2. **Selective Acknowledgement (SACK, 선택적 확인 응답)**: Go-Back-N의 단점을 개선한 방식으로, 수신 측이 받은 패킷에 대한 정보를 개별적으로 송신 측에 알리고, 송신 측은 **손실된 패킷만 다시 보내는 방법**입니다.

### 패킷 손실 감지 방법
1. **Timeout 기반 재전송**: 일정 시간동안 ACK이 도착하지 않으면 해당 패킷이 손실된 것으로 판단하고 다시 전송합니다.
2. **빠른 재전송 (Fast Retransmit)**: TCP는 **중복된 ACK**을 활용하여 패킷 손실을 보다 빠르게 감지합니다.
동일한 데이터에 대해 **3번 이상의 중복된 ACK을 수신**하면 해당 패킷이 손실되었다고 판단하고 즉시 재전송합니다.
예를 들어 패킷 7이 손실되었을 때, 수신 측은 계속해서 패킷 7에 대한 ACK을 보냅니다. 
송신 측이 같은 ACK을 3번 받으면 바로 패킷 7을 다시 전송하는 방식입니다.

## 전송 속도 제어 메커니즘
네트워크에서 데이터를 전송할 때 전송 속도를 적절히 조절하는 것이 매우 중요합니다.

예를 들어 사용자가 1GB 파일을 원격 호스트로 전송하려고 할 때, **전송 속도를 얼마로 설정**해야 할까요?

이상적으로는 100Mbps 네트워크를 사용한다면 100Mbps로 전송하는 것이 최적일 것처럼 보이지만, 현실적으로는 그렇지 않습니다.

첫 번째 문제는 **송신자가 링크의 정확한 용량을 알지 못한다**는 점입니다. 네트워크 환경은 항상 변동되며, 현재 사용 가능한 대역폭이 얼마인지 미리 알 수 없습니다.

두 번째로, 네트워크에는 여러 사용자가 존재하며 **같은 링크를 여러 명이 공유할 경우 공정한 분배가 필요**합니다.
만약 한 사용자가 과도한 속도로 데이터를 전송한다면 다른 사용자의 네트워크 품질이 저하될 수 있습니다.
또한, 수신자가 여러 개의 파일을 동시에 받고 있다면 송신자는 이를 고려해야 합니다.

그럼 전송 속도를 조절하는 기능을 **네트워크 스택의 어느 계층에서** 구현해야 할까요?

한 가지 방법은 애플리케이션 개발자가 **직접 속도 제어 메커니즘을 구현**하는 것입니다. 
UDP가 이러한 방식을 사용하며 데이터 전송 속도를 애플리케이션이 직접 관리하도록 합니다.
하지만 대부분의 애플리케이션에서 전송 속도 제어는 필수적인 기능이므로 이를 **전송 계층에서 제공**하는 것이 훨씬 효율적입니다.

### 흐름 제어 메커니즘 (Flow Control)
TCP에서 전송 속도를 제어하는 첫 번째 이유는 **수신 버퍼가 넘치는 것을 방지하기 위해서**입니다.
TCP는 **수신 측에서 데이터를 버퍼에 저장한 후 애플리케이션이 이를 읽어가도록** 합니다.
하지만 수신 측이 여러 프로세스를 동시에 처리하고 있거나 데이터를 즉시 읽지 못하는 경우 버퍼에 데이터가 쌓일 수 있습니다.

이러한 문제를 해결하지 위해 TCP는 **송신 속도를 수신 속도에 맞추는** Flow control 메커니즘을 제공합니다.

이 메커니즘의 핵심은 송신자가 현재 수신자가 처리할 수 있는 데이터 양을 파악하는 것입니다.
이를 위해 TCP는 **수신 윈도우(receive window, `rwnd`)** 라는 변수를 유지하며 이는 수신자가 처리할 수 있는 여유 공간을 나타냅니다.

#### 동작 방식
TCP 연결을 통해 두 호스트 A와 B가 통신하는 상황을 가정해 보겠습니다.
A가 B로 파일을 전송하려고 할 때 B는 이 연결을 위해 **수신 버퍼(`RcvBuffer`)** 를 할당합니다.

수신 측에서는 다음 두 개의 변수를 유지합니다:
- **`LastByteRead`**: 애플리케이션이 버퍼에서 읽은 마지막 바이트의 번호
- **`LastByteRcvd`**: 네트워크에서 수신하여 버퍼에 저장된 마지막 바이트의 번호

Buffer overflow를 방지하려면 다음 조건이 항상 유지되어야 합니다.

**`LastByteRcvd - LastByteRead <= RcvBuffer`**

여유 공간을 계산할 때는 `rwnd`를 사용합니다.

**`rwnd = RcvBuffer - (LastByteRcvd - LastByteRead)`**

수신자는 매번 송신자에게 ACK을 보낼 때 `rwnd`값을 포함하여 현재 수신할 수 있는 공간을 알립니다.
송신자는 다음 두 변수를 유지하며 수신자의 여유 공간을 고려합니다:

- **`LastByteSent`**: 송신자가 전송한 마지막 바이트의 번호
- **`LastByteAcked`**: 송신자가 전송한 데이터 중 수신자로부터 ACK을 받은 마지막 바이트의 번호

송신자는 unacked data sent를 계산하여 `rwnd`를 초과하지 않도록 보장해야 합니다.

**`LastByteSent - LastByteAcked <= rwnd`**

#### Flow control에서 발생할 수 있는 문제와 해결책
위와 같은 방식에서는 한 가지 문제가 발생할 수 있습니다.

예를 들어, 수신자가 송신자에게 `rwnd = 0`이라고 알리면 송신자는 데이터 전송을 중단합니다. 
그리고 수신측에서는 애플리케이션이 데이터를 읽어가면서 버퍼에 남는 공간이 생길 수도 있습니다. 하지만 **송신자는 이를 알 방법이 없기 때문에 새로운 데이터를 전송하지 못하는 문제**가 발생합니다.

이 문제를 해결하기 위해 TCP는 `rwnd = 0` 상태에서도 송신자가 **1 byte 크기의 세그먼트를 주기적으로 전송**하도록 합니다.

이를 통해 송신자는 수신자로부터 **ACK을 받을 때마다 최신 `rwnd`값을 확인**할 수 있으며, 수신 버퍼에 여유 공간이 생기면 즉시 데이터를 전송할 수 있습니다.

### 혼잡 제어 메커니즘 (Congestion Control)
전송 속도를 제어해야 하는 또 다른 중요한 이유는 네트워크에서 **혼잡(congestion)** 을 방지하기 위해서입니다.
네트워크가 혼잡해지면 패킷 손실이 증가하고 지연 시간이 길어지는 문제가 생길 수 있습니다.

네트워크는 동적인 환경이므로 **사용자들이 네트워크에 접속하고 연결을 종료하는 일이 지속적으로 발생**합니다. 따라서 네트워크의 혼잡 상태도 끊임없이 변하게 됩니다.

이러한 변동성 때문에 혼잡 제어 메커니즘은 단순히 정적인 속도 제한을 설정하는 것이 아니라 **네트워크의 상태를 지속적으로 감지하고 이에 따라 전송 속도를 조정**할 수 있어야 합니다.

#### Congestion Control 특징
1. **효율성**: 네트워크 자원을 최대한 활용하면서 불필요한 혼잡을 방지하는 균형점을 찾아야합니다.
2. **공정성**: 네트워크를 사용하는 모든 사용자들이 **동일한 병목 링크(Bottleneck link)** 를 공유할 때, 각 사용자가 공정한 대역폭을 가져야합니다.
(네트워크 정책에 따라 달라지지만) 일반적으로 같은 조건의 Flow들은 **동일한 네트워크 자원을 균등하게 할당**받아야 합니다.
3. **낮은 지연**: 지연을 최소화 하면서 높은 성능을 유지하는 방법으로 설계되어야 합니다.
4. **빠른 수렴**: 네트워크에서 flow가 공정한 대역폭을 배분받기까지 걸리는 시간이 짧아야 합니다.

#### 구현 방법
1. **네트워크 기반(Network-assisted) congestion control**

    이 방식에서는 네트워크 자체가 혼잡 상태를 감지하고 송신자에게 **Explicit feedback**을 제공하여 혼잡을 해결하도록 돕습니다.
    
    예를 들어 라우터가 **ICMP 소스 퀀치** 메시지를 보내 송신자에게 혼잡이 발생했음을 알릴 수 있습니다. 송신자는 이를 받아들이고 전송 속도를 줄일 수 있습니다.
    
    하지만 이 방법에는 몇 가지 한계가 있습니다. 네트워크가 심각하게 혼잡해지면 **ICMP 패킷조차 손실될 가능성**이 있어 피드백이 효과적으로 전달되지 않을 수 있습니다.
    또한, 네트워크 장비가 혼잡 제어를 지원하려면 추가적인 프로토콜과 기능이 필요하므로 **구현이 복잡해지고 비용이 증가**할 수 있습니다.
    
2. **종단 간(End-to-End) congestion control**

    이 방식에서는 네트워크가 혼잡 상태를 직접 알리지 않고 **송신자가 네트워크의 상태를 스스로 추론**하여 전송 속도를 조절합니다.
    즉, 네트워크에서 발생하는 패킷 손실, 지연 증가 등을 기반으로 **송신자가 혼잡을 감지하고 대응**하는 방식입니다.
    
    TCP는 바로 이 **e2e congestion control**을 사용합니다. 이건 종단 간 원칙과도 잘 맞아떨어지는 개념인데, 네트워크 계층에서는 패킷 전달을 담당하고 혼잡 제어는 전송 계층에서 처리하는 것이 이상적이라는 설계 철학이 반영된 것입니다.
    
    그러나 현대 네트워크에서는 일부 라우터가 **Explicit Congestion Notification (ECN)** 이나 **Quantized Congestion Notification (QCN)** 과 같은 프로토콜을 사용하여 송신자에게 혼잡 상태를 알릴 수 있습니다.
    이렇게 종단 간 방식을 고수하기 보다는 네트워크의 피드백을 활용하는 하이브리드 방식도 점점 활용되고 있습니다.

#### TCP의 혼잡 감지 방법
TCP는 혼잡을 감지하기 위해 **두 가지 주요 신호**를 사용합니다.

1. **패킷 지연 (Packet delay)**

    네트워크가 혼잡해지면 라우터의 버퍼에 패킷이 대기하면서 **큐가 쌓이고 전송 지연이 증가**하게 됩니다.
    이로 인해 왕복 시간(RTT, Rount Trip Time)이 증가하는데 송신자는 ACK 패킷을 기반으로 RTT를 측정하여 혼잡을 감지할 수 있습니다.
    
    하지만 delay-based congestion inference는 구현이 쉽지 않습니다.
    네트워크의 지연 시간은 혼잡 외에도 다양한 요인에 의해 변동될 수 있기 때문입니다. 따라서 **TCP는 기본적으로 패킷 지연을 직접적인 혼잡 신호로 사용하지 않습니다.**
    
2. **패킷 손실 (Packet loss)**

    네트워크가 심하게 혼잡해지면 라우터의 버퍼가 가득 차서 패킷을 드롭하게 됩니다. 
    패킷 손실의 원인엔 여러 가지가 있지만 (TTL 만료, 네트워크 혼잡, 하드웨어 오류 등등) 대부분의 손실은 네트워크 혼잡으로 인해 발생합니다.
    
초기 TCP 구현에서는 **패킷 손실이 감지되면 이를 혼잡의 신호로 해석하고 전송 속도를 줄이는 방식**을 사용했습니다.

#### 동작 방식
TCP는 혼잡 제어를 위해 `cwnd` 개념을 사용합니다.
이는 **송신자가 한 번에 보낼 수 있는 데이터의 최대 크기**를 의미합니다.

`cwnd`는 `rwnd`와 유사하지만, 수신 측이 아닌 **네트워크의 혼잡 상태를 기반으로 조절**된다는 차이가 있습니다.

TCP는 **probe-and-adapt** 방식을 통해 `cwnd` 크기를 조절합니다.
네트워크가 안정적인 경우, `cwnd`를 점진적으로 증가시켜 더 많은 데이터를 전송하도록 시도합니다.
패킷 손실이 감지되면 혼잡이 발생한 것으로 판단하고 창 크기를 줄여 혼잡을 완화합니다.

송신자는 **네트워크의 상태(`cwnd`) 또는 수신자의 처리 능력(`rwnd`) 중 더 작은 값**에 맞춰 전송 속도를 조절해야합니다.

#### AIMD
TCP가 혼잡에 따라 송신 윈도우 크기를 조절하는 방식은 **AIMD (Additive Increase / Multiplicative Decrease)** 라고 불립니다.

1. **Additive Increase(가산 증가)** 방식

    TCP 연결은 초기 송신 윈도우 크기를 일정하게 설정한 후, 점진적으로 증가시킵니다.
    일반적으로 초기 윈도우 크기는 2로 설정되며 매 RTT(Rount Trip Time)마다 선형적으로 증가하는 방식입니다.
    
    즉, **송신자가 `cwnd` 개수만큼의 패킷을 성공적으로 전송하면 `cwnd`의 크기가 증가**합니다. 
    
    또한 TCP는 모든 패킷의 ACK을 기다린 후 증가시키는 것이 아니라, **개별적인 ACK을 수신할 때마다 즉시 증가**시키는 방식을 사용합니다.

    증가량은 MSS(Maximum Segment Size)에 기반하며 아래의 수식을 따릅니다.
    
    **`Increment = MSS * (MSS/cwnd)`**
    
2. **Multiplicative Decrease(배수 감소)** 방식
    
    TCP는 패킷 손실이 발생하면 `cwnd` 값을 **기존 값의 절반**으로 줄입니다. `cwnd` 값은 **최소 1**까지 줄어들 수 있고 그 이하로는 내려가지 않습니다.
    
이러한 과정이 반복되면서 `cwnd`는 지속적으로 증가했다가 감소하는 패턴을 보이는데, 이를 **톱니형 패턴**이라고 합니다.

TCP의 여러 구현 방식 중에서 TCP Reno는 두 가지 종류의 패킷 손실을 기반으로 혼잡을 감지합니다. 
1. **세 번의 중복 ACK을 수신하는 경우**: 네트워크가 경미한 혼잡 상태에 있다는 신호이며, `cwnd` 값을 절반으로 줄입니다.
2. **특정 시간 동안 ACK을 받지 못하는 타임아웃 이벤트**: 타임아웃은 심각한 혼잡 상태로 간주되며, `cwnd` 값을 초기 윈도우 상태로 재설정합니다.

#### Slow Start
Slow start는 송신 호스트가 네트워크의 용량을 모를 때, 즉 **새로운 연결이 시작될 때 적용**됩니다. 
초기에는 송신 윈도우 크기를 1로 설정하고, **각 ACK을 받을 때마다 윈도우 크기를 두 배씩 증가**시킵니다.

즉, 처음 1개의 패킷을 보내고, 다음에는 2개, 그 다음에는 4개, 8개 식으로 증가합니다. 

이를 통해 네트워크가 허용하는 최적의 전송 속도를 신속하게 찾을 수 있습니다.

하지만 Slow start가 계속되면 송신 윈도우가 과도하게 증가하여 네트워크 혼잡이 발생할 수 있습니다.
이를 방지하기 위해 **congestion threshold를 넘어서면 AIMD 방식으로 전환**됩니다. 

#### TCP 공정성이 보장되지 않는 경우
1. **RTT의 차이**

    TCP Reno는 ACK을 기반으로 `cwnd` 크기를 조정하는데, **RTT가 짧은 연결일수록 ACK을 빨리** 받을 수 있어 `cwnd`를 더 빨리 증가시킬 수 있습니다.
    
    반면, RTT가 긴 연결은 같은 속도로 증가하지 못하고 상대적으로 낮은 전송 속도를 유지해야 합니다.
        
2. **여러 개의 병렬 TCP 연결을 사용하는 경우**

    다수의 연결을 가진 애플리케이션이 불공정하게 더 많은 네트워크 자원을 가져갈 수 있습니다.

위와 같은 문제로 인해 일부 네트워크 환경에서는 다양한 조정 기법이 도입되기도 합니다.

예를 들어 TCP의 경쟁적인 특성을 완화하고자 **RTT를 고려한 대역폭 할당 방식**을 적용하거나, **다중 연결 사용을 제한하는 정책을 활용**하는 방법이 있습니다.

#### TCP Cubic
기존의 TCP Reno는 네트워크 대역폭이 높거나 지연 시간이 큰 경우 네트워크 활용도가 낮다는 문제가 있었습니다.
이를 해결하기 위해 TCP의 여러 개선 버전이 등장했고, 그 중 하나가 TCP CUBIC 입니다. 

TCP CUBIC은 **CUBIC 다항식 항수를 사용하여 `cwnd` 크기를 조절**합니다.

**핵심 아이디어**

TCP가 세 개의 중복 ACK을 받았을 때, `cwnd` 크기를 절반으로 감소시킵니다. 

윈도우 크기가 `W_max`일 때 패킷 손실이 발생하여 혼잡이 감지되었다고 가정하면, 다시 윈도우 크기를 증가시킬 때 **처음에는 빠르게 증가시키지만 `W_max`에 가까워질수록 증가 속도를 점진적으로 줄이는 방식**을 사용합니다.

만약 `W_max`에 도달했는데도 패킷 손실이 발생하지 않는다면 이전 손실이 transient congestion이나 기타 원인으로 발생한 것일 수 있습니다.

이 경우, **이후에는 윈도우 크기를 더 적극적으로 증가**시키는 방식으로 아래와 같이 동작합니다:

        W(t) = C(t-K)^3 + W_max

        W_max: 마지막 패킷 손실이 발생했을 때 윈도우 크기
        C: 스케일링 상수 (네트워크 환경에 따라 조정)
        K: cwnd가 W_max로 도달하는데 걸리는 시간

특히 TCP CUBIC의 중요한 특징은 **시간을 기준으로 윈도우 크기를 조절**한다는 점입니다.
이를 통해 TCP CUBIC은 RTT가 다른 연결 간에도 보다 공정하게 네트워크 자원을 공유하는 **RTT-fair** 한 특성을 가질 수 있습니다.
a:T3657,
## 개요
인터넷 아키텍쳐는 **서로 다른 네트워크에 위치한 동일한 애플리케이션을 실행하는 호스트를 연결**할 수 있도록 해줍니다. 
컴퓨터 네트워크는 여러 구성 요소로 이루어진 복잡한 시스템이며 다양한 기술을 기반으로 합니다. 
즉, 서로 다른 유형의 네트워크로 구성될 수 있고, 다양한 애플리케이션을 호스팅할 수도 있습니다.

예를 들어, 두 개의 이메일 클라이언트는 **서로 다른 네트워크(Wifi vs. ethernet 케이블)를 사용하면서도 정상적으로 통신**할 수 있습니다. 
그렇다면 이렇게 다양한 기술과 구성 요소들이 어떻게 하나로 연결되어 각 애플리케이션이 필요한 기능을 수행할 수 있을까요?

네트워크 프로토콜을 설계하는 과정에서, 이런 복잡한 시스템을 보다 체계적으로 만들기 위해 **계층(layer)** 개념이 도입되었습니다.

### 계층
**네트워크 아키텍쳐에서는 기능을 여러 계층으로 나누어 구현**합니다. 각 계층은 특정 기능을 담당하며, 아래 계층에서 제공하는 서비스를 기반으로 동작합니다.
또한, 상위 계층이 원활하게 동작할 수 있도록 필요한 서비스를 제공합니다.

항공 시스템으로 비유를 해보겠습니다.
1. 승객은 티켓을 구매하고, 수하물을 맡기고, 공항 게이트를 통과합니다.
2. 비행기가 출발하면 탑승한 승객은 목적지까지 이동합니다.
3. 도착지에서는 비행기에서 내려 게이트를 통과한 후, 수하물을 찾고 공항을 나갑니다.

이 과정에서 각 단계는 특정한 역할을 수행하고, 이전 단계에서 제공한 서비스를 기반으로 운영됩니다. 즉, **한 단계가 끝나야 다음단계가 진행**될 수 있습니다.

네트워크 아키텍쳐에서도 동일한 원리가 적용됩니다. 각 계층은 특정 기능을 수행하고, 모두 연결되어 네트워크가 정상적으로 동작하도록 합니다.

#### 계층 구조의 장점
1. 확장성: 새로운 기술이나 기능을 쉽게 추가할 수 있습니다.
2. 모듈성: 각 기능이 독립적으로 설계되어 유지보수가 편리합니다.
3. 유연성: 특정 계층을 수정하거나 교체하더라도 전체 시스템에 큰 영향을 미치지 않습니다.

위와 같은 이유로 인터넷 아키텍쳐는 계층적인 구조를 기반으로 설계되었고, 효율적이고 비용친화적인 네트워크 구현이 가능합니다.

이렇게 기능을 계층별로 분리하는 것은 분명 여러 장점을 제공하지만, 몇 가지 단점도 존재합니다.

#### 계층 구조의 단점
1. 계층 간 종속성: 일부 계층의 기능이 다른 계층의 정보를 필요로 하는 경우, 계층 구분의 원칙이 어긋날 수 있습니다.
2. 중복된 기능: 오류 복구와 같은 특정 기능이 하위/상위 계층에서 중복으로 구현될 수 있습니다.
3. 추가적인 오버헤드: 계층 간의 추상화로 인해 성능 저하 및 불필요한 데이터 처리가 발생할 수 있습니다.

## OSI 7계층 모델
국제 표준화 기구(ISO)는 네트워크 통신을 구조화하기 위해 아래와 같은 모델을 제안했습니다.
| 계층 |
|-----------|
| 애플리케이션 계층 (Application Layer)   |
| 프레젠테이션 계층 (Presentation Layer)  |
| 세션 계층 (Session Layer)   |
| 전송 계층 (Transport Layer)  |
| 네트워크 계층 (Network Layer)  |
| 데이터 링크 계층 (Data Link Layer)  |
| 물리 계층 (Physical Layer)  |

### 7계층: 애플리케이션 계층 (Application Layer)
애플리케이션 계층은 다양한 **애플리케이션을 지원하는 여러 프로토콜을 포함**합니다. 대표적인 프로토콜은 다음과 같습니다.
- HTTP (HyperText Transfer Protocol): 웹페이지 요청 및 전송
- SMTP (Simple Mail Transfer Protocol): 이메일 송수신
- FTP (File Transfer Protocol): 파일 전송
- DNS (Domain Name System): 도메인 이름을 IP 주소로 변환

애플리케이션 계층에서는 구현된 애플리케이션에 따라 다양한 서비스를 제공하고, 이 계층을 이용하는 인터페이스와 사용되는 프로토콜도 애플리케이션에 따라 달라집니다.

**애플리케이션 계층에서는 데이터를 `메시지 (Message)`라고 부릅니다.**

### 6계층: 프레젠테이션 계층 (Presentation Layer)
프레젠테이션 계층은 **데이터 형식을 변환하는 역할**을 하며, 하위 계층에서 받은 정보를 애플리케이션 계층이 이해할 수 있도록 변환합니다.

예를 들어, 비디오 스트림을 특정 형식으로 변환하거나 숫자 데이터를 big endian에서 little endian으로 변환하는 것 등이 있습니다.

### 5계층: 세션 계층 (Session Layer)
세션 계층은 애플리케이션 간의 세션을 관리하는 역할을 합니다. **동일한 애플리케이션 프로세스에서 여러 개의 전송 스트림이 존재할 경우, 이를 하나의 세션으로 묶어 관리**합니다.

예를 들어, 화상 회의 애플리케이션에서 오디오 스트림과 비디오 스트림을 동기화하여 올바르게 전달하도록 합니다. 세션 계층이 있어야 오디오와 비디오가 일관되게 전달되고 하나의 통합된 세션으로 유지될 수 있습니다.

### 4계층: 전송 계층 (Transport Layer)
전송 계층은 **호스트 간(end-to-end) 통신**을 담당하는 계층으로, 두 가지 주요 프로토콜이 사용됩니다.

#### 1. TCP (Transmission Control Protocol)
- 연결 지향적 서비스 (Connection-oriented service)
- 애플리케이션 계층 메시지의 신뢰성 보장 (**Guaranteed delivery**)
- 흐름 제어 (**Flow control**): 송신자와 수신자의 속도 조정
- 혼잡 제어 (**Congestion control**): 네트워크 혼잡이 감지되면 송신 속도 조절
#### 2. UDP (User Datagram Protocol)
- 연결 없는 **connectionless** 서비스
- **Best-effort 전송**: 신뢰성, 흐름 제어, 혼잡 제어가 없음
- 실시간 스트리밍, VoIP, 온라인 게임 등 **속도가 중요한 애플리케이션**에서 주로 사용

즉, 이 계층은 데이터가 중간에 손실되거나 순서가 뒤바뀌지 않도록 관리하여 최종 사용자에게 올바른 정보를 전달합니다.
**전송 계층에서는 데이터를 `세그먼트 (Segment)`라고 부릅니다.**

### 3계층: 네트워크 계층 (Network Layer)
네트워크 계층의 역할은 **호스트 간 데이터그램(Datagram) 전달**입니다. 라우팅 프로토콜을 통해 최적의 경로를 선택하고, 그 경로를 통해 데이터를 전달합니다.

**데이터 전달 과정**
1. **전송 계층 → 네트워크 계층 전달**: 먼저, 송신 호스트의 4계층인 전송 계층에서 생성된 데이터를 네트워크 계층으로 넘깁니다. 이 데이터는 아직 `세그먼트` 형태로 존재합니다.
2. **데이터그램 변환 및 라우팅**: 네트워크 계층은 받은 세그먼트를 **데이터그램으로 변환**합니다. 이때, 각 데이터그램에는 데이터의 목적지 주소, 출발지 주소 등 필요한 정보가 포함됩니다. 이 정보들을 바탕으로 데이터그램이 목적지에 도착할 수 있도록 **최적의 경로를 찾아 여러 라우터를 거쳐 전송**합니다.
3. **목적지 도착 및 재구성**: 최종적으로 데이터그램들은 목적지 호스트에 도착하면 다시 모여 **원래의 세그먼트 형태로 재구성**되고, 이후 4계층인 전송 계층으로 전달되어 최종 데이터로 사용됩니다.

**핵심 프로토콜**
- **IP (Internet Protocol)**
  - 인터넷의 핵심 프로토콜, 모든 인터넷 호스트 및 네트워크 장치는 IP 프로토콜을 실행해야 함
  - 데이터그램의 **헤더 구조 및 주소 지정 방식 정의**
  - 출발지와 목적지 간 패킷 전송 지원
- **라우팅 프로토콜 (Routing Protocol)**
  - 데이터그램이 송신지에서 목적지까지 **어떤 경로를 따라 이동할지 결정**
  - EX) OSPF, BGP, RIP

**네트워크 계층에서는 데이터를 `데이터그램 (Datagram)`이라고 부릅니다.**

### 2계층: 데이터 링크 계층 (Data Link Layer)
데이터 링크 계층은 **인접한 네트워크 장비 간의 안정적인 데이터 전송**을 담당 합니다. 데이터를 프레임 단위로 묶어, 물리적 연결에서 오류 검출과 재전송 기능을 수행합니다.

**주요 프로토콜 예시**: Ethernet, PPP (Point-to-Point Protocol), WiFi

**데이터 전송 과정**
1. **데이터 준비**: 네트워크 계층에서 생성된 데이터그램이 각 노드(호스트 또는 라우터)로 전달됩니다.
2. **프레임 캡슐화**: 데이터 링크 계층은 이 데이터그램을 프레임으로 포장하면서, 오류 검출 및 수정에 필요한 정보를 추가합니다.
3. **단일 링크 전송**: 프레임은 물리 계층을 통해 바로 인접한 다음 네트워크 장비로 전송됩니다.
4. **프레임 해체**: 다음 노드는 도착한 프레임의 오류를 검사하고, 문제가 없으면 프레임을 열어 원래의 데이터그램을 추출해 네트워크 계층으로 전달합니다.

데이터 링크 계층은 **신뢰성 있는 데이터 전송(Reliable delivery)** 을 기반으로 합니다. 단, 이것은 TCP의 신뢰성 보장과는 다릅니다. TCP는 송신지에서 수신지까지의 전체 경로를 보장하지만, 데이터 링크 계층은 단일 링크에서만 보장합니다.

**데이터 링크 계층에서는 데이터를 `프레임 (Frame)`이라고 부릅니다.**

### 1계층: 물리 계층 (Physical Layer)
물리 계층은 **하드웨어와 직접 상호작용 하며, 물리적 링크를 통해 비트를 전송**하는 역할을 합니다.

프레임 내의 비트들을 송수신하고, 네트워크의 물리적인 전송 매체(케이블, 무선 신호 등)에 따라 다른 방식으로 데이터를 전달합니다.

물리 계층에서 사용 되는 주요 기술 및 매체에는 꼬임쌍선(Twisted-Pair copper wire), 동축 케이블(coaxial cable), 광섬유(single-mode fiber optics) 등이 있습니다.

데이터 링크 계층의 대표적인 프로토콜인 이더넷(Ethernet)은 **물리 계층의 전송 매체에 따라 다른 물리적 프로토콜을 사용**합니다. 예를 들어, UTP(비차폐 꼬임쌍선) 케이블, 무선(Wifi) 등 다양한 매체에서 동작할 수 있도록 설계되었습니다.

**물리 계층에서는 데이터를 `비트 (Bits)`단위로 다룹니다.**

### OSI 7계층을 통한 end-to-end 데이터 이동 경로

한 호스트에서 다른 호스트로 데이터가 이동하는 과정을 OSI 7계층 모델을 이용해 단계별로 살펴보겠습니다.
```
         송신 호스트                                               수신 호스트
──────────────────────────────────────────────────────────────────────────────
     [ 애플리케이션 계층 ]                                         [ 애플리케이션 계층 ]  
      HTTP, FTP, SMTP                                          HTTP, FTP, SMTP 
              │                                                       ▲  
              ▼                                                       │ 
      [ 프레젠테이션 계층 ]                                        [ 프레젠테이션 계층 ]  
       데이터 압축/암호화                                          데이터 복호화/압축 해제  
              │                                                       ▲  
              ▼                                                       │ 
         [ 세션 계층 ]                                             [ 세션 계층 ]  
        세션 설정 및 유지                                          세션 동기화 및 종료  
              │                                                       ▲  
              ▼                                                       │ 
         [ 전송 계층 ]                                             [ 전송 계층 ]  
       TCP/UDP 포트 관리                                        TCP/UDP 데이터 재조립  
              │                                                       ▲  
              ▼                                                       │ 
       [ 네트워크 계층 ]                                           [ 네트워크 계층 ]  
     IP 주소 지정 및 라우팅                                       목적지 IP 확인 및 전달  
              │                                                       ▲  
              ▼                                                       │ 
      [ 데이터 링크 계층 ]                                         [ 데이터 링크 계층 ]  
    MAC 주소 지정 및 프레임화                                     프레임 해체 및 MAC 검증  
              │                                                       ▲  
              ▼                                                       │ 
         [ 물리 계층 ] ─────────────────────────────────────▶       [ 물리 계층 ]  
 비트 스트림 전송 (WiFi, LAN)                                 신호를 비트로 변환하여 상위 전달  

```

## 마무리
이번 포스트에서는 OSI 7 layer 에 대해 간단히 알아보았습니다. 다음 게시글에서는 계층 간의 캡슐화, end-to-end principle 등에 대해 알아보겠습니다.
b:T2c12,
## 개요
네트워크 계층과 각 계층에서 실행되는 프로토콜들이 서로 어떻게 소통하는지 이해하기 위해 캡슐화(encapsulation)과 디캡슐화(de-encapsulation) 개념을 살펴보겠습니다.

## 캡슐화 과정 (Encapsulation)
캡슐화는 송신 호스트에서 데이터를 보낼 때 각 계층이 자신의 헤더를 추가하면서 이루어집니다.
 
가장 먼저, 애플리케이션 계층에서 생성된 메시지는 전송 계층으로 전달됩니다. 
전송 계층에서는 이 메시지에 **전송 계층 헤더(HT, Transport Layer Header)** 를 추가하여 **세그먼트**를 형성합니다. 
이 추가된 정보는 수신 호스트에서 올바른 애플리케이션으로 데이터를 전달할 수 있도록 돕고, 오류 감지 및 데이터 무결성을 확인하는 역할을 합니다.

세그먼트는 네트워크 계층으로 전달되며, 네트워크 계층에서는 **네트워크 계층 헤더(HN, Network Layer Header)** 를 추가하여 **데이터그램**을 생성합니다.
이 헤더에는 **송신지 및 목적지의 IP 주소**가 포함되어 있어, 데이터가 정확한 목적지로 전송될 수 있도록 합니다.

다음으로, 데이터그램은 데이터 링크 계층으로 이동하며 **데이터 링크 계층 헤더(HL, Link Layer Header)** 를 추가하여 **프레임**을 생성합니다.
프레임은 물리 계층을 통해 비트 단위로 변환되며, 실제 네트워크 매체를 통해 전송됩니다.

## 디캡슐화 과정 (De-encapsulation)
수신 호스트에서는 위 과정을 반대로 수행합니다. 

물리 계층에서 수신된 비트들은 데이터 링크 계층으로 전달되며, 여기서 **프레임의 헤더(HL)** 가 제거된 후 네트워크 계층으로 전달됩니다.

네트워크 계층에서는 **데이터그램의 헤더(HN)** 를 확인하고 제거한 후, 전송 계층으로 데이터를 넘깁니다.

마지막으로 전송 계층에서는 **세그먼트의 헤더(HT)** 를 분석하여 올바른 애플리케이션으로 데이터를 전달합니다. 최종적으로 애플리케이션 계층은 메시지를 해석하고 사용자에게 출력합니다.

### 중간 장치와 캡슐화
송신지에서 목적지까지의 경로에는 **라우터**나 **스위치** 같은 네트워크 장치들이 포함될 수 있습니다. 이러한 장치들은 네트워크 계층을 처리하는 방식이 다릅니다.

**라우터**는 **물리 계층, 데이터 링크 계층, 네트워크 계층 (1-3계층)** 을 처리하며, 패킷을 분석하여 최적의 경로를 찾아 전송합니다.

**스위치**는 **물리 계층과 데이터 링크 계층 (1-2계층)** 까지만 처리하며, 프레임을 기반으로 목적지를 결정합니다.

## 종단 간 원칙 (End-to-End Principle)
종단 간 원칙(E2E principle)은 현재의 인터넷 아키텍쳐를 형성하는데 중요한 역할을 한 설계원칙입니다. 
이 원칙은 특정한 애플리케이션 기능을 네트워크 코어(핵심부)에서 처리하는 것이 아니라, **가능하면 네트워크의 끝단(end systems)** 에서 구현해야 한다는 개념을 제안합니다.

즉, **네트워크 자체는 단순하고 최소한의 역할만 수행해야 하며, 복잡한 기능과 지능은 애플리케이션이 실행되는 종단에서 구현하는 것이 바람직하다**는 철학입니다.

네트워크 설계의 기초가 된 논문 "End-to-End Arguments in System Design" (Saltzer, Reed, Clark)에 따르면, 어떤 기능이 완벽하게 구현되려면 **해당 기능을 필요로 하는 애플리케이션이 직접 수행해야 한다**고 설명합니다.
네트워크 자체에서 특정 기능을 제공하려 해도, 개별 애플리케이션이 이를 완전히 활용하거나 맞춤형으로 조정하기 어렵기 때문입니다.

또한, 모든 애플리케이션이 동일한 기능을 필요로 하는 것이 아니기 때문에, 네트워크 코어에 특정 기능을 추가하면 이를 필요로 하지 않는 애플리케이션에도 강제 적용되는 문제가 발생할 수 있습니다.
따라서, 네트워크 코어는 필수적이고 공통적인 기능만 수행하도록 설계해야 합니다.

종단 간 원칙 덕분에 인터넷은 빠르게 성장할 수 있었습니다. 네트워크의 핵심부를 바꾸는 것은 어렵지만, 끝단에서 혁신적인 애플리케이션과 서비스가 자유롭게 개발될 수 있었기 때문입니다.
다양한 애플리케이션이 유연하게 설계될 수 있었던 것도 네트워크의 코어가 아닌 엔드포인트에서 기능을 구현하는 방식을 따랐기 때문입니다.

결과적으로, **하위 계층의 프로토콜은 특정 애플리케이션에 의존하지 않고, 네트워크 자원을 효율적으로 관리하는 역할에 집중**할 수 있습니다.
이처럼 상위 계층은 개별 애플리케이션에 맞게 설계되고, 하위 계층은 애플리케이션과 무관하게 네트워크 인프라를 최적화하는 것이 종단 간 원칙의 핵심입니다.

### 종단 간 원칙의 위반 사례
종단 간 원칙은 인터넷의 발전과 확장에 많은 이점을 제공했지만, 현실적인 이유로 인해 이 원칙이 지켜지지 못하는 경우도 존재합니다.
대표적인 사례로 **방화벽(Firewall)** 과 **네트워크 주소 변환(NAT, Network address translation) 박스**가 있습니다.

#### 방화벽과 트래픽 필터링
방화벽은 네트워크의 경계에서 동작하며, 네트워크를 통해 들어오거나 나가는 트래픽을 모니터링하는 역할을 합니다.
보안 정책에 따라 정상적인 트래픽은 허용하고, 악의적인 트래픽은 차단합니다.

이건 보안 측면에서 매우 중요하지만, **중간 네트워크 장치가 엔드 호스트 간의 통신을 차단할 수 있기 때문에** 종단 간 원칙을 위반하는 사례가 됩니다.
방화벽이 특정 패킷을 차단하면 송신 호스트와 수신 호스트가 직접 통신하는 것이 불가능해질 수 있기 때문입니다.

#### NAT (Network Address Translation) 박스
인터넷 주소 공간이 부족해지면서 등장한 해결책 중 하나가 **NAT** 입니다. 
NAT은 **하나의 공인 IP 주소를 여러 개의 사설 IP 주소를 사용하는 내부 네트워크와 공유하도록 하는 기술**입니다.

**NAT의 동작 방식**

가정에서 여러 대의 기기를 인터넷에 연결한다고 가정해보면, 보통 Internet service provider(ISP)는 공유기에 **단 하나의 public IP 주소**를 할당합니다.
하지만 가정 내의 **각 장치는 사설 네트워크에서 개별적인 private IP 주소**를 가질 수 있습니다.

이 때, NAT이 동작하는 방식은 다음과 같습니다.
1. 내부 네트워크의 장치가 public internet 상의 호스트로 데이터를 전송하려고 하면, 공유기는 **출발지 IP 주소를 자신의 public IP 주소로 변환**한 후 외부로 전송합니다.
2. 외부에서 오는 응답 패킷의 목적지 IP는 공유기의 public IP 주소이므로, 공유기는 **NAT 변환 테이블을 참고하여 적절한 내부 IP로 변환한 후 전달**합니다.

NAT 변환 테이블은 **public IP 주소 및 포트 번호**와 **내부 네트워크의 IP 주소 및 포트 번호**를 매핑하여 관리합니다.
예를 들어, 내부 호스트 `10.0.0.4`가 포트 `3345`를 사용하여 public IP `120.70.39.4`의 포트 `5001`과 통신한다고 가정하면:
- `출발지 IP 10.0.0.4, 출발지 포트 3345` → 변환 후 `IP: 120.70.39.4, 출발지 포트: 5001`
- `목적지 IP 120.70.39.4, 목적지 포트 5001` → 변환 후 `IP: 10.0.0.4, 목적지 포트: 3345`

이런 방식으로 NAT는 **단 하나의 public IP address를 이용해 다수의 내부 장치가 인터넷과 통신**할 수 있도록 해줍니다.

#### NAT가 종단 간 원칙을 위반하는 이유
NAT를 사용하는 네트워크 내부의 호스트는 public internet에서 직접 접근할 수 없습니다. 즉, 외부 호스트가 NAT 내부의 호스트로 직접 연결을 시도하는 것이 기본적으로 불가능합니다.

종단 간 원칙의 핵심은 **인터넷의 엔드포인트(호스트)들이 직접 통신할수 있도록 하는 것**인데, NAT은 이 원칙을 깨고 중간에서 IP 주소를 변환하고 트래픽을 조정하는 역할을 합니다.

따라서 NAT는 **네트워크 코어에서 특정한 기능을 수행하면서, 엔드 호스트 간 직접적인 통신을 방해하기 때문에** E2E 원칙을 위반하는 사례로 간주됩니다.

#### NAT 문제를 해결하기 위한 우회 방법
NAT로 인해 공인 인터넷의 호스트가 NAT 내부 호스트와 직접 통신할 수 없는 문제가 발생하지만, 이를 해결하기 위한 몇 가지 우회 기법이 존재합니다.
- **STUN (Session Traversal Utilities for NAT)**
  - NAT가 사용되는 환경에서 클라이언트가 **자신의 공인 IP 주소와 포트 번호를 발견할 수 있도록 도와주는 프로토콜**입니다.
  - NAT 뒤에 있는 호스트가 외부 서버를 통해 자신이 사용하는 public IP/port를 확인하고, 이를 통해 통신을 설정할 수 있습니다.
- **UDP Hole Punching**
  - UDP 기반의 연결을 설정할 때, NAT를 통해 양쪽 호스트가 서로 직접 연결을 수립하는 기법입니다.
  - 양쪽 호스트가 **동시에 NAT 바깥의 공용 서버에 패킷을 전송**함으로써, **각 공유기의 NAT 변환 테이블을 조작**하여 직접적인 UDP 연결을 가능하게 합니다.
  - P2P network (Skype, 온라인 게임 등)에서 주로 사용됩니다.
  
  
그럼, **종단 간 원칙을 위반하지 않는 사례**도 살펴보겠습니다.

WiFi와 같은 일부 데이터 링크 계층 프로토콜은 기본적인 오류 수정 기능을 포함하고 있습니다. 이는 물리적 매체가 간섭이나 노이즈로 인해 쉽게 오류가 발생할 수 있기 때문입니다.

그렇다면 **이러한 오류 수정 기능이 E2E principle을 위반하는 것일까요?**

정답은 **위반이 아니다** 입니다.

종단 간 원칙의 위반은 일반적으로 **특정 기능이 엔드 호스트에서만 완벽하게 구현될 수 있음에도 불구하고, 네트워크 내부에서 이를 처리하려고 할 때 발생**합니다. 

하지만 WiFi의 오류 수정 기능은 이와 다릅니다. **물리적 계층의 특성상 반드시 필요한 기능이기 때문**입니다.
무선 네트워크는 유선 네트워크보다 더 많은 간섭과 신호 감쇠를 겪기 때문에, 기본적인 오류 검출 및 수정 기능이 없으면 안정적인 통신이 불가능해집니다.

즉, 이러한 기능이 없으면 상위 계층(전송 계층, 애플리케이션 계층 등)에서 원활한 데이터 송수신이 어려워지므로, 네트워크의 전반적인 신뢰성이 떨어질 수 있습니다.
데이터 링크 계층에서 이루어지는 오류 수정은 종단 간 원칙을 위반하는 것이 아니라, **네트워크의 안정성을 보장하기 위한 현실적인 조치**라고 볼 수 있습니다.
d:["category","computer-networks","d"]
0:["YK1rAVTkmTwTsLaFN9a5H",[[["",{"children":["blog",{"children":[["category","computer-networks","d"],{"children":["__PAGE__?{\"category\":\"computer-networks\"}",{}]}]}]},"$undefined","$undefined",true],["",{"children":["blog",{"children":[["category","computer-networks","d"],{"children":["__PAGE__",{},[["$L1",["$","$L2",null,{"category":"computer-networks","filteredPosts":[{"slug":"computer-networks/router-design","categorySlug":"computer-networks","title":{"ko":"라우터 디자인","en":"Router Design"},"date":"2025-02-24 22:15","category":{"ko":"컴퓨터 네트워크","en":"Computer Networks"},"description":{"ko":"라우터 디자인과 그 알고리즘에 대해 알아봅시다","en":"Router design and its algorithms"},"content":"$3"},{"slug":"computer-networks/AS-and-interdomain-routing-algorithm","categorySlug":"computer-networks","title":{"ko":"AS와 인터도메인 라우팅 알고리즘","en":"AS and Interdomain Algorithm"},"date":"2025-02-24 21:18","category":{"ko":"컴퓨터 네트워크","en":"Computer Networks"},"description":{"ko":"AS와 인터도메인 라우팅에 대해 알아봅시다","en":"Autonomous System and Interdomain Algorithm"},"content":"$4"},{"slug":"computer-networks/intradomain-routing-algorithm","categorySlug":"computer-networks","title":{"ko":"인트라도메인 라우팅 알고리즘","en":"Intradomain Routing Algorithm"},"date":"2025-02-23 14:21","category":{"ko":"컴퓨터 네트워크","en":"Computer Networks"},"description":{"ko":"인트라도메인 라우팅에 대해 자세히 알아봅시다","en":"Deep dive into Intradomain Routing Algorithm"},"content":"$5"},{"slug":"computer-networks/internet-protocol-stack","categorySlug":"computer-networks","title":{"ko":"인터넷 프로토콜 스택 구조","en":"Hourglass Shape of Internet Protocol Stack"},"date":"2025-02-23 00:00","category":{"ko":"컴퓨터 네트워크","en":"Computer Networks"},"description":{"ko":"인터넷 프로토콜 스택과 모래시계 아키텍쳐에 대한 설명","en":"Internet protocol stack and its hourglass shape"},"content":"$6"},{"slug":"computer-networks/hosts-and-networks","categorySlug":"computer-networks","title":{"ko":"계층별 장치와 스패닝 트리 알고리즘","en":"Layer Devices and Spanning Tree Algorithm"},"date":"2025-02-23 00:00","category":{"ko":"컴퓨터 네트워크","en":"Computer Networks"},"description":{"ko":"물리, 데이터링크, 네트워크 계층의 장치들과 네트워크 간 연결 방법","en":"L1, L2, L3 devices and interconnecting hosts"},"content":"$7"},{"slug":"computer-networks/multiplexing-demultiplexing","categorySlug":"computer-networks","title":{"ko":"전송 계층의 멀티플렉싱과 디멀티플렉싱","en":"Transport layer's Multiplexing and Demultiplexing"},"date":"2025-02-23 00:00","category":{"ko":"컴퓨터 네트워크","en":"Computer Networks"},"description":{"ko":"전송 계층의 멀티플렉싱/디멀티플렉싱에 대해 알아봅시다","en":"How multiplexing/demultiplexing work in transport layer"},"content":"$8"},{"slug":"computer-networks/tcp","categorySlug":"computer-networks","title":{"ko":"TCP 프로토콜","en":"TCP Protocol"},"date":"2025-02-23 00:00","category":{"ko":"컴퓨터 네트워크","en":"Computer Networks"},"description":{"ko":"TCP 프로토콜에 대해 자세히 알아봅시다","en":"Deep dive into TCP Protocol"},"content":"$9"},{"slug":"computer-networks/intro-to-internet-architecture","categorySlug":"computer-networks","title":{"ko":"인터넷 아키텍쳐 개요","en":"Introduction to Internet Architecture"},"date":"2025-02-22 00:00","category":{"ko":"컴퓨터 네트워크","en":"Computer Networks"},"description":{"ko":"인터넷 아키텍쳐와 OSI 7계층에 대한 간단한 설명","en":"Intro to internet architecture and OSI 7 layers"},"content":"$a"},{"slug":"computer-networks/encapsulation-de-encapsulation","categorySlug":"computer-networks","title":{"ko":"계층 간 캡슐화와 디캡슐화, 종단 간 원칙","en":"Layer Encapsulation and De-encapsulation, E2E principle"},"date":"2025-02-22 00:00","category":{"ko":"컴퓨터 네트워크","en":"Computer Networks"},"description":{"ko":"계층 간 캡슐화, 디캡슐화에 대한 설명","en":"How layer encapsulation and de-encapsulation work"},"content":"$b"}]}],null],null],null]},[null,["$","$Lc",null,{"parallelRouterKey":"children","segmentPath":["children","blog","children","$d","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$Le",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined"}]],null]},[[null,["$","$Lf",null,{"children":["$","$Lc",null,{"parallelRouterKey":"children","segmentPath":["children","blog","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$Le",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined"}],"params":{}}]],null],null]},[[[["$","link","0",{"rel":"stylesheet","href":"/julie/_next/static/css/064e10fa6619f508.css","precedence":"next","crossOrigin":"$undefined"}],["$","link","1",{"rel":"stylesheet","href":"/julie/_next/static/css/e680cef9016abb97.css","precedence":"next","crossOrigin":"$undefined"}]],["$","html",null,{"lang":"ko","suppressHydrationWarning":true,"children":["$","body",null,{"className":"__className_29e2ff","children":["$","$L10",null,{"attribute":"class","defaultTheme":"system","enableSystem":true,"disableTransitionOnChange":true,"children":["$","$L11",null,{"children":[["$","$L12",null,{}],["$","$Lc",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$Le",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":"404"}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],"notFoundStyles":[]}]]}]}]}]}]],null],null],["$L13",null]]]]
13:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"Julie Lee's Portfolio"}],["$","meta","3",{"name":"description","content":"Welcome to Julie's portfolio page."}],["$","meta","4",{"name":"next-size-adjust"}]]
1:null
