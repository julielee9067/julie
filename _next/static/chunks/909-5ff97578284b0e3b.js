"use strict";(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[909],{4491:function(n,e,t){t.d(e,{LanguageProvider:function(){return s},Z:function(){return c}});var o=t(7437),r=t(2265);let i={ko:{name:"이은지",role:"소프트웨어 엔지니어",sections:{skills:"기술 스택",experience:"경력",education:"학력",projects:"프로젝트",blog:"블로그"},buttons:{viewAll:"모든 글 보기",viewProject:"프로젝트 보기",source:"소스 코드",downloadResume:"이력서 다운로드"},theme:{light:"라이트 모드",dark:"다크 모드",system:"시스템 설정"},gpa:"학점",period:"기간",current:"현재"},en:{name:"Julie Lee",role:"Software Engineer",sections:{skills:"Skills",experience:"Experience",education:"Education",projects:"Projects",blog:"Blog"},buttons:{viewAll:"View All",viewProject:"View Project",source:"Source Code",downloadResume:"Download Resume"},theme:{light:"Light Mode",dark:"Dark Mode",system:"System"},gpa:"GPA",period:"Period",current:"Present"}},a=r.createContext(void 0);function s(n){let{children:e}=n,[t,s]=r.useState("ko");r.useEffect(()=>{let n=localStorage.getItem("preferredLanguage");("ko"===n||"en"===n)&&s(n)},[]);let c=r.useCallback(n=>{s(n),localStorage.setItem("preferredLanguage",n)},[]),d=r.useCallback(n=>{let e=function(n,e){let t=n;for(let n of e){if(!t||"string"==typeof t)return;t=t[n]}return t}(i[t],n.split("."));return"string"==typeof e?e:n},[t]);return(0,o.jsx)(a.Provider,{value:{language:t,setLanguage:c,t:d},children:e})}function c(){let n=r.useContext(a);if(!n)throw Error("useLanguage must be used within a LanguageProvider");return n}},5974:function(n,e,t){t.d(e,{C:function(){return s}});var o=t(7437);t(2265);var r=t(535),i=t(4508);let a=(0,r.j)("inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2",{variants:{variant:{default:"border-transparent bg-primary text-primary-foreground hover:bg-primary/80",secondary:"border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80",destructive:"border-transparent bg-destructive text-destructive-foreground hover:bg-destructive/80",outline:"text-foreground"}},defaultVariants:{variant:"default"}});function s(n){let{className:e,variant:t,...r}=n;return(0,o.jsx)("div",{className:(0,i.cn)(a({variant:t}),e),...r})}},9398:function(n,e,t){t.d(e,{n:function(){return o},o:function(){return r}});let o=[{slug:"cs/multiprocessing-and-multithreading-in-python",categorySlug:"cs",title:{ko:"파이썬에서의 멀티 프로세싱과 멀티 스레딩",en:"Multiprocessing and Multithreading in Python"},date:"2025-02-21",category:{ko:"컴퓨터 공학",en:"Computer Science"},description:{ko:"멀티 프로세싱과 멀티 스레딩의 파이썬에서의 동작 원리",en:"How Multiprocessing and Multithreading Work in Python"},content:'\n## 개요\n대규모 데이터 파이프라인을 운영하다보면 **병목 현상**을 자주 목격하게 됩니다. 이 때, 마이크로서비스가 실행 중인 컨테이너들을 수평적으로 확장하는 것도 중요하지만, 때로는 컨테이너 확장만으로는 해결되지 않는 문제들도 있습니다.\n\n예를 들어, 특정 서비스에서 복잡한 연산 때문에 한 개의 메시지를 처리하는 데 시간이 너무 오래 걸린다면, 멀티 프로세싱 기법을 도입하여 문제를 해결할 수 있습니다. 또한, 한 서비스가 다른 서비스의 네트워크 응답을 기다려야 하는 상황에서는, 멀티 스레딩을 활용하여 대기 시간 동안 다른 작업을 병행할 수 있습니다.\n\n이 글에서는 멀티 프로세싱과 멀티 스레딩의 차이가 무엇인지, 그리고 이 방법들을 파이썬에서 어떻게 사용할 수 있을지 알아보도록 하겠습니다.\n\n## 멀티 프로세싱\n먼저, 프로세스의 개념에 대해서 알아보겠습니다.\n\n**프로세스**: **컴퓨터에서 실행 중인 하나의 프로그램**이라고 생각하면 됩니다. 예를 들어, 웹 브라우저, 미디어 플레이어 등이 각각 하나의 프로세스입니다.\n\n각 프로세스는 운영체제로부터 독립된 메모리 공간(힙, 스택 등)과 자원을 할당 받고, 한 프로세스에 문제가 발생해도 다른 프로세스에는 영향을 주지 않습니다.\n\nCPU 코어를 활용해 위와 같은 여러 개의 프로세스들을 병렬로 실행할 수 있으며, 프로세스 간 통신은 **IPC**(Inter-Process Communication)을 사용합니다.\n예를 들어, 한 컴퓨터에서 웹 브라우저와 미디어 플레이어를 동시에 실행하는 경우, 두 개의 독립된 프로세스가 작동합니다.  \n\n아래는 Python에서 multiprocessing을 구현할 수 있는 간단한 예제입니다.\n```python\nfrom multiprocessing import Process\nimport time\n\ndef process_file(file_name):\n    print(f"[프로세스] {file_name} 처리 시작")\n    # 실제 파일 처리는 생략하고, 2초간 대기합니다.\n    time.sleep(2)\n    print(f"[프로세스] {file_name} 처리 완료")\n\ndef main():\n    files = [\'file1.csv\', \'file2.csv\']\n    processes = []\n\n    # 각 파일에 대해 별도의 프로세스를 생성합니다.\n    for file in files:\n        p = Process(target=process_file, args=(file,))\n        processes.append(p)\n        p.start()  # 각 프로세스 시작\n\n    # 모든 프로세스가 끝날 때까지 대기합니다.\n    for p in processes:\n        p.join()\n\n    print("모든 프로세스 작업 완료")\n\nif __name__ == "__main__":\n    main()\n```\n#### 동시에 실행할 수 있는 프로세스의 수\n그럼, **동시에 실행되는 프로세스의 수**는 어떻게 결정하는 것이 좋을까요?\n\n\n보통 **CPU bound** 작업일 경우, 일반적으로 **실행할 프로세스의 수를 CPU 코어 수와 동일**하게 맞추는 것이 좋습니다. 예를 들어, 8코어 시스템에서는 8개의 프로세스를 동시에 실행하면 각 프로세스가 별도의 코어에서 동작하며 최적의 성능을 낼 수 있습니다.\n\n만약 작업이 **I/O bound**일 경우, CPU 사용률이 낮으므로 **CPU 코어 수보다 더 많은 프로세스**를 실행해도 문제가 없을 수 있습니다. 하지만 동시에 실행되는 프로세스가 많아지면, 각 프로세스가 사용하는 메모리와 자원에 대한 부담이 커지기 때문에 시스템의 **메모리 용량**과 **자원 사용량**을 고려하여 정해야 합니다.\n\n#### IPC (Inter-Process Communication)\nIPC, 프로세스 간 통신은 서로 독립적으로 실행되는 여러 프로세스들이 데이터를 주고받을 수 있도록 해주는 메커니즘입니다.\n\n**IPC 방법들**\n1. **Pipe와 FIFO (Named Pipe)**  \n    **파이프**: 두 프로세스 간에 데이터를 일방향으로 전달하는 통신 채널입니다. 보통 부모/자식 프로세스 사이에서 사용됩니다.  \n    **FIFO (Named Pipe)**: 이름이 있는 파이프로, 관련 없는 독립적인 프로세스들 간에도 통신할 수 있습니다.\n2. **메시지 큐**  \n  여러 프로세스가 데이터를 메시지 단위로 보내고 받을 수 있는 큐입니다.\n  메시지는 순서대로 저장되고, 한 프로세스가 메시지를 보내면 다른 프로세스가 이를 꺼내어 처리합니다.\n3. **공유 메모리**  \n  여러 프로세스가 같은 메모리 영역에 접근할 수 있게 하는 방법입니다.\n  접근 속도가 매우 빠르지만, race condition(동기화 문제)를 해결하기 위한 추가 메커니즘이 필요합니다.\n4. **소켓**  \n  네트워크를 통해 프로세스 간 통신을 할 수 있고, 동일 컴퓨터 내의 프로세스 뿐만 아니라 다른 컴퓨터의 프로세스와도 통신할 수 있습니다.\n\n파이썬에서는 사용의 편의성과 안정성 면에서 메시지 큐(`multiprocessing.Queue`)가 가장 널리 사용됩니다. \n\n#### 멀티 프로세싱 풀 (Pool)\n멀티 프로세싱 풀은 미리 정해진 수의 프로세스(작업자)를 생성해두고, 이를 통해 작업을 분산하여 실행하는 방식입니다. 이렇게 하면 매번 새로운 프로세스를 생성하는 오버헤드를 줄일 수 있어, 다수의 작업을 효율적으로 처리할 수 있습니다.\n\n**작동 원리**\n1. 풀은 시작할 때 **지정한 수의 프로세스를 미리 생성**합니다. 예를 들어, **CPU 코어 수나 작업량**에 맞게 4개, 8개 등의 프로세스를 만들어 둡니다.\n2. 여러 작업을 풀에 제출하면, 풀에 있는 프로세스들이 작업을 나눠서 실행합니다. **작업이 끝난 프로세스는 다시 대기** 상태로 돌아가 다음 작업을 처리할 준비를 합니다.\n3. 한 번 생성된 프로세스는 여러 작업에 대해 **재사용**됩니다.\n\n## 멀티 스레딩\n**스레드**: 스레드는 하나의 프로세스 내에서 **실제로 작업을 수행하는 작은 실행 단위**입니다. 즉, 하나의 프로세스 안에서 여러 가지 일을 동시에 진행할 수 있도록 도와주는 역할을 합니다. 예를 들면, 크롬(프로세스)에서 여러 개의 탭마다 웹사이트를 불러오는 작업은 멀티 스레딩으로 이루어집니다.\n\n같은 프로세스 내의 스레드들은 **모두 동일한 메모리(데이터, 변수 등)를 공유**하며, 스레드들끼리 데이터를 쉽게 주고받을 수 있습니다. 하지만, 동시에 **같은 데이터에 접근하다 보면 서로 충돌**할 수도 있어 주의해야 합니다.\n\n#### Python에서 멀티 스레딩과 GIL (Global Interpreter Lock)\nPython의 가장 널리 쓰이는 interpreter인 CPython에는 **GIL**이라는 메커니즘이 있습니다. GIL은 한 번에 **오직 하나의 스레드**만 Python 코드를 실행하도록 하는 잠금장치입니다.\n\n\nPython은 **Garbage collection**을 사용해 메모리를 자동으로 관리합니다. GIL은 **여러 스레드가 동시에 메모리를 변경하는 일을 방지**하고, 프로그램이 복잡해져도 메모리 관리가 안전하게 이루어지도록 도와줍니다.\n\n하지만, GIL으로 인해 여러 스레드를 사용해도 한 시점에 오직 하나의 스레드만이 실제로 코드를 실행합니다. 따라서, 복잡한 계산이나 **CPU를 많이 사용하는 작업(CPU bound)은 여러 스레드로 병렬 처리했을 때 기대만큼의 성능 향상을 얻기 어렵습니다**.\n\n반면에, 파일 입출력, 네트워크 통신 등과 같이 **기다리는 시간이 상대적으로 많은 작업**(I/O bound)들에서는 **스레드가 대기 상태로 있을 때 다른 스레드가 실행**될 수 있으므로 GIL의 영향이 덜합니다. 이 경우, CPU는 한 스레드에만 국한되지 않고 다른 스레드로 전환되어 작업을 진행합니다.\n\n예를 들면, 파일을 읽거나 쓸 때, CPU는 집중적으로 계산하는 것이 아니라, 외부 장치(디스크 등)와 데이터를 주고받느라 기다리는 시간이 발생합니다. 이 때 스레드가 **대기 상태**로 들어가면서 GIL을 해제하게 됩니다. 이로 인해 다른 스레드들이 CPU를 사용할 수 있게 되어, 여러 파일을 동시에 읽거나 쓸 수 있습니다.\n  \n엄밀히 말하면 CPU가 여러 작업을 번갈아 실행하기 때문에, 동시에 실행되는 것처럼 보이지만 실제로는 **컨텍스트 스위칭**이 계속 발생하며 작업을 처리합니다.\n\nCPython에서는 GIL이 interpreter의 핵심 설계 요소이기 때문에 Python 자체에서 **GIL을 완전히 해제하거나 제거하는 것은 불가능**합니다.\n\n#### 동시에 실행할 수 있는 스레드의 수\n멀티 스레딩에서 **동시에 실행할 수 있는 스레드의 수**는 작업의 종류에 따라 달라집니다.\n\n**CPU 집약적인 작업**의 경우, CPython의 GIL 때문에 한 번에 한 스레드만 Python 바이트코드를 실행합니다. 따라서, CPU 코어 수에 맞춰 스레드를 구성하는 것이 좋습니다. 이렇게 하면 불필요한 스레드 전환(컨텍스트 스위칭) 오버헤드를 줄일 수 있습니다.\n\n반면, **I/O 바운드 작업**처럼 파일 입출력이나 네트워크 요청과 같이 대기 시간이 긴 작업에서는, CPU 사용이 크게 발생하지 않으므로 CPU 코어 수보다 훨씬 많은 스레드를 사용할 수 있습니다. 예를 들어, 네트워크 요청이 많은 애플리케이션에서는 수십 개 이상의 스레드를 사용해도 오히려 성능 향상을 기대할 수 있습니다.\n\n#### 멀티 스레딩에서의 풀\n멀티 프로세싱에서 풀을 사용하는 것과 같이, 스레딩에서도 풀 개념을 적용할 수 있습니다. Python에서는 주로 `cuncurrent.futures.ThreadPoolExecutor`를 사용하여 풀을 구성합니다. 이를 통해 **미리 정해진 수의 스레드를 생성하고, 작업을 해당 스레드들에 분산**시켜 실행할 수 있습니다.\n'},{slug:"cs/garbage-collection-in-python",categorySlug:"cs",title:{ko:"파이썬에서의 가비지 컬렉션",en:"Garbage Collection in Python"},date:"2025-02-21",category:{ko:"컴퓨터 공학",en:"Computer Science"},description:{ko:"가비지 컬렉션의 파이썬에서의 동작 원리",en:"How Garbage Collection Works in Python"},content:"\n## 가비지 컬렉션 (Garbage Collection)\nPython의 가비지 컬렉션은 메모리 관리를 자동으로 수행하는 메커니즘입니다. 이 메커니즘은 크게 두 가지 방법을 사용합니다.\n### 1. 참조 카운팅 (Reference Counting)\n어떤 물건을 여러 사람이 공유하고 있을 때 몇 명이 그 물건을 사용 중인지 숫자로 세어보는 것과 비슷합니다.\n\n**작동 원리**\n1. Python에서 어떤 데이터를 저장하는 객체(list, dictionary, etc)가 만들어지면 이 객체를 사용하고 있는 변수가 몇 개인지 기록합니다.\n2. 만약 변수가 그 객체를 사용하면 숫자가 1 증가하고, 더 이상 사용하지 않게 되면 숫자가 1 감소합니다.\n3. 이 **참조 카운트가 0**이 되면 그 객체는 아무도 사용하지 않는 것으로 판단되어 청소부가 그 객체를 메모리에서 제거합니다.\n```python\na = [1, 2, 3]    # 리스트 객체 생성 (참조 카운트 증가)\n\nb = a            # b가 a를 참조 (참조 카운트 증가)\n\ndel b            # b 삭제 (참조 카운트 감소)\n```\n### 2. 순환 가비지 컬렉터 (Cyclic Garbage Collector)\n때로는 두 개 이상의 객체가 서로를 참조하면서 **서로를 잡아먹는** 상황이 생깁니다. 예를 들어, A가 B를, B가 A를 참조하고 있으면 외부에서는 둘 다 사용하지 않더라도 참조 카운트가 0이 되지 않습니다.\n\n```python\nclass A:\n    def __init__(self):\n        self.other = None\n\n# 두 객체 생성 후 서로를 참조하게 만듭니다.\na = A()\nb = A()\na.other = b  # a는 b를 참조\nb.other = a  # b는 a를 참조\n\n# 외부 참조 제거\na = None\nb = None\n\n# 이제 두 객체는 외부에서 접근할 수 없지만 서로를 참조하므로 참조 카운트는 0이 되지 않습니다.\n```\nPython은 이러한 순환 참조 문제를 해결하기 위해 정기적으로 청소를 하는 **순환 가비지 컬렉터** 시스템을 사용합니다. 이 시스템은 주기적으로 객체 그래프를 탐색하여, **외부에서는 접근할 수 없지만 내부적으로 서로 참조하는 객체들**을 찾아냅니다.\n#### 세대 개념\n객체는 **얼마나 오래 살아남았느냐**에 따라 몇 개의 세대로 분류됩니다. 최근에 생성된 객체는 0세대, 조금 오래된 객체는 1세대, 가장 오래된 객체는 2세대로 분류됩니다.\n\n이렇게 세대를 구분하는 이유는 대부분의 객체가 짧은 수명을 가지고 있고, 오래 살아남은 객체는 변경 가능성이 낮다고 판단하여 더 자주 검사하지 않음으로써 가비지 컬렉션 오버헤드를 줄이기 위함입니다.\n\n### 고려 사항\n한 객체를 참조하는 수가 많을 경우 **참조 카운트를 업데이트하는 오버헤드**가 발생할 수 있습니다. 객체에 대한 참조를 추가하거나 제거할 때마다 메모리 내에서 해당 값을 읽고, 수정하고, 다시 저장하는 작업이 필요합니다. \n이런 연산이 반복되면 단순히 그 객체를 사용하거나 해제하는 비용 외에도 참조 카운트 업데이트에 따른 부가적인 CPU 연산 비용이 누적될 수 있습니다.\n\n예를 들어, 수천 개의 복잡한 데이터 구조에서 한 객체가 여러 부분에서 참조될 경우, 참조 카운트 관리에 드는 시간이 전체 성능에 영향을 줄 수 있습니다.\n\nOS는 새로운 메모리 블록을 할당하거나, 사용이 끝난 메모리 블록을 해제할 때 **시스템 호출**을 사용합니다. 이러한 호출은 사용자 코드에서 직접 호출하는 연산보다 훨씬 느리고 오버헤드가 큽니다.\n\n\n또한, 메모리 할당/해제를 반복하면 메모리 내부에 작고 산발적인 빈 공간들이 생기는데, 이를 **메모리 단편화**(Fragmentation)라고 합니다. 단편화가 심해지면 **메모리 사용 효율이 떨어지고 큰 연속된 메모리 공간을 할당받기 어려워집니다**.\n\n\n이와 같이 메모리 할당 및 해제는 비용이 크므로 Python은 **메모리 풀**과 같은 기법을 통해 메모리를 재활용합니다. 메모리 풀은 **미리 일정 크기의 메모리 블록들을 할당해 놓고 필요할 때마다 이 블록들을 재활용**하는 방식입니다.\n\n예를 들어, CPython은 짧은 문자열이나 작은 리스트와 같은 소형 객체를 위한 전용 메모리 할당기를 사용합니다. 이 풀은 **한 번에 시스템으로부터 큰 메모리 블록**을 받아 내부에서 작고 고정된 크기의 블록들로 나눈 후, 객체 생성 시 이 블록들을 할당합니다.\n\n이 방식을 사용하면 새로운 객체를 만들 때마다 OS에 매번 메모리 할당 요청을 보내지 않아도 되므로 **매우 빠르게 메모리를 할당**할 수 있습니다. 객체가 해제되면 해당 메모리 블록은 즉시 운영체제에 반환되지 않고 **메모리 풀에 다시 저장**되어 다음에 **재사용**됩니다.\n\n\n만약 현재 **할당된 메모리 풀이 모두 사용중**이라면:\n1. Python의 메모리 할당기는 OS에 추가 메모리를 요청합니다.\n2. 운영체제에서 추가 메모리를 제공하면 메모리 풀은 확장되어 이후에 새로운 객체 할당에 사용됩니다.\n3. 만약 운영체제에서 더 이상 메모리를 제공할 수 없다면 Python은 더 이상 객체를 위한 메모리를 할당할 수 없게 됩니다. (`MemoryError` Exception 발생)\n\n메모리 풀 확장 시 여러 프로세스가 동시에 메모리를 요구할 수 있고 이런 상황에서는 경쟁이 발생할 수도 있습니다.\n\n## 마무리\n오늘은 파이썬에서 가비지 컬렉션이 어떻게 동작하는지 알아보았습니다. 다음엔 네트워크 관련 게시글을 올려보도록 하겠습니다. 감사합니다 :)\n"},{slug:"system-design/messaging-service",categorySlug:"system-design",title:{ko:"메시징 서비스 시스템 디자인",en:"Design Messaging Service"},date:"2025-02-20",category:{ko:"시스템 디자인",en:"System Design"},description:{ko:"대규모 메시징 서비스 설계",en:"Let's design messaging service"},content:'\n`Togather` 프로젝트 (북미 대학생을 위한 익명 커뮤니티 앱) 를 만들면서 자연스럽게 커뮤니티 플랫폼과 채팅 서비스의 시스템 디자인에 대해 관심을 갖게 되었습니다.\n\n이번 글에서는 대규모 사용자를 대상으로 한 채팅 서비스의 시스템 디자인에 대해 살펴보겠습니다.\n\n## 기능적 요구사항\n1. **그룹 채팅 지원** – 여러 명이 함께 대화할 수 있는 그룹 메시지 기능이 필요함.\n2. **메시지 송수신 기능** – 사용자가 메시지를 보내고 받을 수 있어야 함.\n3. **오프라인 수신 가능** – 사용자가 오프라인 상태일 때도 메시지를 받을 수 있어야 하며, 다시 온라인이 되면 확인할 수 있어야 함.\n4. **사진 및 미디어 전송 지원** – 텍스트뿐만 아니라 사진, 동영상 등 미디어 파일도 주고받을 수 있어야 함.\n\n## 비기능적 요구사항\n1. **빠른 메시지 전달 속도** – 온라인 상태인 사용자는 500ms(0.5초) 이내에 메시지를 받아야 함.\n2. **메시지 전달 보장** – 메시지가 유실되지 않고 반드시 수신자에게 전달되어야 함.\n3. **확장성** – 수십억 명의 사용자가 이용해도 원활하게 동작해야 함.\n4. **필요한 메시지만 저장** – 메시지는 필요한 만큼만 보관하고, 불필요한 데이터는 자동으로 삭제되도록 관리해야 함.\n5. **안정성 보장** – 특정 서버나 기능이 고장 나더라도 전체 서비스가 중단되지 않도록 시스템이 복구 및 대응할 수 있어야 함.\n## Core entities\n- Users\n- Chats\n- Messages\n- Clients (devices)\n## API 디자인\n메시지가 매우 자주 주고받아지는 환경에서는 매번 요청을 보내고 응답을 받는 REST API 방식은 비효율적입니다. REST API는 요청이 올 때마다 새로운 연결을 만들고, 응답을 받은 후 연결을 종료하기 때문에 실시간성이 중요한 서비스에서는 지연이 발생할 수 있습니다.\n\n반면, 양방향 소켓 연결 (bi-directional socket connection) 은 한 번 연결을 설정하면 계속 유지되므로 서버와 클라이언트가 실시간으로 데이터를 주고받을 수 있습니다. \n예를 들어, 채팅 서비스에서는 사용자가 메시지를 보내면 서버가 즉시 상대방에게 전달해야 하는데 소켓 연결을 사용하면 별도의 요청 없이도 빠르게 메시지를 받을 수 있습니다.\n\n\n즉, 자주 변하는 데이터를 실시간으로 주고받아야 하는 서비스에서는 REST API보다 소켓 연결이 훨씬 효율적입니다.\n\n### 전송되는 명령\n#### Create Chat: 대화방 생성\n**Request**\n```json\n{\n    "participants": ["user1", "user2"],\n    "name": "Study Group"\n}\n```\n\n#### Send Message: 메시지 전송\n**Request**\n```json\n{\n    "chatId": 1,\n    "message": "hi",\n    "attachments": ["sampleFile"]\n}\n```\n\n#### Create Attachment: 첨부파일 생성\n**Request**\n```json\n{\n    "body": ...,\n    "hash": ""\n}\n```\n\n#### Modify Chat Participants, 대화방 인원 수정\n**Request**\n```json\n{\n    "chatId": 1,\n    "userId": 1,\n    "operation": "ADD" | "REMOVE"\n}\n```\n위에 나열한 각 요청은 다른 클라이언트들에게도 동시에 전송됩니다. 클라이언트가 요청을 받으면 서버에 `"명령을 정상적으로 받았다"`는 ACK (확인 응답) 메시지를 보냅니다.\n\n이렇게 하면 서버는 `"이제 이 메시지를 다시 보낼 필요가 없겠구나"` 하고 확인합니다. (만약 ACK을 받지 못하면 서버는 메시지가 제대로 전달되지 않았다고 판단하고 다시 보낼 수도 있습니다.)\n\n\n### 수신되는 명령\n#### New Message, 새로운 메시지 수신\n**Request**\n```json\n{\n    "chatId": 1,\n    "userId": 1\n    "message": "hi",\n    "attachments": []\n}\n```\n\n#### Chat Update, 대화방 업데이트\n**Request**\n```json\n{\n    "chatId": 1,\n    "participants": ["user1"],\n}\n```\n\n## High-Level Design\n### 1. 그룹 채팅 지원: 최대 100명\n```plaintext\n+-----------+   (WebSocket Conn)    +---------+      +-------------+      +--------------------+\n|  Client   | --------------------> |  L4 LB  | ---> | Chat Server | ---> | Database (DynamoDB) |\n+-----------+                       +---------+      +-------------+      +--------------------+\n```\n\n#### 플로우\n1. 사용자가 서비스에 연결한 후 createChat 요청을 보냅니다.\n2. 서버는 한 트랜잭션 내에서 새로운 채팅방(Chat) 데이터를 생성하고, 해당 채팅방의 참여자(ChatParticipant) 정보도 함께 저장합니다.\n3. 채팅방이 성공적으로 생성되면 서버는 생성된 chatId를 사용자에게 반환합니다.\n\n#### 사용 기술\n- **L4(4계층) 로드밸런서**: 웹소켓 연결을 지원하며 실시간 통신이 필요한 메시징 서비스에 적합합니다.\n- **AWS DynamoDB**: 채팅방 생성 시 관련 데이터(참여자 정보, 생성 시간 등)를 저장하기 위해 사용됩니다. 빠른 Key-Value 성능과 뛰어난 확장성(Scalability) 을 제공하여 대규모 사용자 환경에서도 안정적으로 동작합니다.\n\n여기서 다른 데이터베이스가 아닌 `AWS DynamoDB`를 사용하는 이유는 다음과 같습니다.\n- **확장성**: 자동으로 수평 확장 되므로 사용자가 많이 늘어나는 상황에서도 안정적으로 동작합니다. RDBMS는 일정 규모가 넘어가면 샤딩을 직접 관리해야 하는데, DynamoDB는 이를 자동으로 처리해줍니다. 같은 NoSQL 데이터베이스인 MongoDB와 같은 경우에도 수평 확장이 가능하지만, 샤딩과 클러스터 관리를 직접 해야합니다.\n- **Low latency**: key-value 기반이라 초당 수백만건의 요청을 빠르게 처리할 수 있습니다. 지연 시간을 최소화 하기 좋습니다. 쿼리 기능은 제한적이지만 Composite key와 GSI를 이용해 특정 조회 패턴을 빠르게 지원합니다.\n- **비용 효율성**: 온디맨드 모델을 사용하면 실제 사용한 만큼만 비용을 지불합니다. 고성능 환경에서 RDBMS를 유지하려면 서버 증설 등에 비용이 크게 늘어날 수 있습니다.\n\n#### DB Index 설계: `ChatParticipant` 테이블\n`ChatParticipant` 테이블은 다음과 같은 두 가지 기능을 지원해야 합니다.\n1. 특정 채팅방에 참여한 모든 사용자 조회\n2. 특정 사용자가 참여 중인 모든 채팅방 조회\n\n이를 위해, DynamoDB의 `Composite primary key`와 `GSI(Global Secondary Indexes)`를 활용해야 합니다.\nDynamoDB는 테이블을 만들 때 기본 키로 설정되는 두 가지 유형의 Primary key를 지원하는데, 단일 partition key (우리가 아는 기본 primary key), composite key (partition key + sort key) 로 나누어져 있습니다.\n\nDynamoDB의 composite key는 partition key + sort key 조합으로 테이블을 구성하는 방식인데, 같은 Partition key 값을 가진 여러 개의 데이터를 저장할 수 있습니다. Partition key로 데이터를 그룹화하고 Sort key로 정렬하는 방식입니다.\n\n\n우리가 `chatId`를 **Partition Key**, `participantId`를 **Sort Key**로 설정하면 특정 채팅방(`chatId`)에 속한 모든 사용자를 손쉽게 조회할 수 있습니다. 하지만 **"특정 사용자가 속한 모든 채팅방을 알고 싶다"** 라는 쿼리를 실행하려면 `participantId`를 기준으로 검색해야 합니다. 이를 가능하게 하기 위해 **GSI(Global Secondary Index)** 를 추가해야 합니다.\n**GSI**는 DynamoDB에서 테이블 생성 후 추가 가능한 추가적인 조회 패턴을 지원하기 위해 사용되는 인덱스입니다. 여기서 Partition key를 `participantId`로, sort key를 `chatId`로 설정하면 특정 유저가 참여한 모든 채팅방을 효율적으로 조회할 수 있습니다.\n\nGSI가 **"Global"한 이유**는 **기본 테이블의 Partition Key와 상관없이 전역적으로 데이터를 검색할 수 있기 때문**입니다. 반면, **LSI(Local Secondary Index)** 는 특정 Partition 내부에서만 작동하므로 예를 들어 특정 채팅방 내에서 가장 최근 메시지를 검색할 때(`chatId -> timestamp`) LSI를 활용할 수 있습니다.\n\n**요약**\n1. Composite Primary Key(`chatId` + `participantId`)를 사용하면 특정 `chatId`에 속한 모든 사용자를 빠르게 조회할 수 있습니다.\n2. GSI(`participantId` + `chatId`)를 추가하면 특정 사용자가 속한 모든 채팅방을 효율적으로 검색할 수 있습니다.\n\n### 2. 메시지 송수신 기능\n우선 문제를 단순화하기 위해 **서버가 하나만 존재한다고 가정**해보겠습니다. 또한, 앞서 언급한 것처럼 **웹소켓(WebSocket) 연결을 사용하여 실시간 메시지를 주고받도록 설계**합니다.\n\n\n유저가 채팅 서버에 웹소켓을 통해 연결하면 **서버는 해당 유저의 연결 정보를 해시맵(HashMap)에 저장**합니다. 이렇게 하면 **현재 어떤 유저가 서버에 연결되어 있는지 파악할 수 있으며, 연결된 유저에게 메시지를 직접 전달**할 수 있습니다.\n\n#### 메시지 송신 플로우 (1차 버전)\n1. 유저가 `sendMessage` 요청을 서버에 보냅니다.  \n2. 서버는 데이터베이스의 `ChatParticipant` 테이블을 조회하여 **해당 채팅방에 속한 모든 참여자 목록을 가져옵니다.**  \n3. 서버는 **내부 해시맵을 확인하여 현재 웹소켓 연결이 활성화된 유저들에게만 메시지를 전송합니다.**  \n\n이 방식에서는 다음과 같은 **제약 사항**이 존재합니다.  \n- 모든 유저가 웹소켓 연결 상태여야만 메시지를 받을 수 있음\n- 유저가 반드시 같은 서버에 연결되어 있어야 함\n- 각 유저마다 웹소켓을 유지하고 관리해야 함\n\n위에서 언급한 제약 사항들은 이후 섹션에서 해결 방법을 다룰 예정입니다.  \n### 3. 오프라인 수신 기능 (최대 30일)\n오프라인 수신 기능을 만들기 위해 앞에서 가정했던 일부 조건들을 다시 생각해보겠습니다. 오프라인 상태인 유저에게 메시지를 전달하려면 메시지를 데이터베이스에 저장해야 할 필요가 생깁니다.\n\n각 유저별로 **메시지 수신함**을 만들고 여기에 **아직 전달되지 않은 메시지들을 저장**하는 방식으로 설계해보겠습니다.\n메시지가 전송되면 **수신자의 수신함에 메시지를 저장**하고, 만약 수신자가 온라인 상태라면 메시지 즉시 전달을 시도합니다. 만일 유저가 오프라인 상태라면 메시지를 저장한 후 나중에 다시 접속했을 때 전달하도록 하겠습니다.\n#### 메시지 송신 플로우 (2차 버전)\n1. 유저가 `sendMessage` 요청을 서버에 보냅니다.  \n2. 서버는 데이터베이스의 `ChatParticipant` 테이블을 조회하여 **해당 채팅방에 속한 모든 참여자 목록을 가져옵니다.**  \n3. 서버는 한 트랜잭션 내에서 (1) `Message` 테이블에 메시지를 저장하고, (2) 채팅방의 각 참여자의 `Inbox`에 해당 메시지 정보를 저장합니다.\n4. 서버는 클라이언트에게 **성공/실패 응답 + `messageId`** 를 반환합니다.  \n5. 서버는 **웹소켓 연결 정보 해시맵**을 확인하여 현재 온라인 상태인 수신자에게 `newMessage` 명령을 통해 메시지를 즉시 전달합니다.  \n6. **연결된 수신자**는 메시지를 받은 후, **`ack` 메시지를 서버에 반환**합니다. 서버는 `Inbox` 테이블에서 해당 유저에게 전달된 메시지를 삭제하여 중복 전송을 방지합니다.\n\n#### 연결되지 않은 수신자 플로우\n오프라인 상태였던 유저가 다시 서버에 연결되었을 때, 이전까지 전달되지 않았던 메시지를 정상적으로 받을 수 있도록 처리해야 합니다.\n1. 수신자가 서버에 연결되면 **서버는 해당 유저의 `Inbox` 테이블을 조회하여 아직 남아있는 메시지 ID 목록을 가져옵니다.**  \n2. 각 `messageId` 에 해당하는 메시지를 `Message` 테이블에서 조회합니다.  \n3. 온라인 상태인 수신자에게 `newMessage` 명령을 통해 메시지들을 전달합니다.\n4. **연결된 수신자**는 메시지를 받은 후, **`ack` 메시지를 서버에 반환**합니다. 서버는 `Inbox` 테이블에서 해당 유저에게 전달된 메시지를 삭제하여 중복 전송을 방지합니다.\n\n마지막으로, **간단한 Cron Job을 활용하여 30일 이상 전달되지 않은 `Inbox` 메시지를 정리(cleanup)** 할 수 있습니다. \n### 4. 사진 및 미디어 전송 기능\n이상적인 접근 방식은 **사용자가 직접 Blob Storage(예: AWS S3, GCS)에 업로드할 수 있도록 권한을 부여하는 것**입니다.  \n이를 위해 **Pre-Signed URL**을 활용하면 채팅 서버를 거치지 않고도 사용자가 직접 파일을 업로드할 수 있습니다. 이 방식은 제가 `Togather` 프로젝트에서 사용자가 게시글을 올릴 때 미디어를 첨부하는 과정에서도 적용했던 방식입니다.\n\n#### 파일 업로드 플로우\n1. 사용자가 `getAttachmentTarget` 요청을 **Chat Server**에 보냅니다.  \n2. **Chat Server**는 **Pre-Signed URL**을 생성하여 사용자에게 반환합니다.  \n3. 사용자는 이 **Pre-Signed URL**을 이용해 **Blob Storage에 직접 파일을 업로드**합니다.  \n4. 업로드가 완료되면 사용자는 **업로드된 파일의 URL을 Chat Server에 전달**하여 메시지와 함께 저장합니다.  \n\n#### 파일 다운로드 플로우\n1. 사용자가 특정 첨부 파일을 다운로드하려고 하면 서버에 Pre-Signed URL을 요청합니다.  \n2. **Chat Server**는 Blob Storage에서 해당 파일에 접근할 수 있는 **Pre-Signed URL을 반환**합니다.  \n3. 사용자는 **해당 URL을 통해 직접 Blob Storage에서 파일을 다운로드**합니다.  \n\n이상적으로는 모든 수신자가 파일을 다운로드한 후 자동 삭제하는 것이 가장 효율적이므로, 메시지 전송 후 수신자가 다운로드 했는지 확인하는 로직이 필요합니다. 또한 파일을 일정 기간 이후 자동 삭제하는 정책을 적용시킬 수도 있습니다.\n## 상세 설계\n### 1. 수십억 명의 유저가 동시 접속할 경우 어떻게 처리할 것인가?\n위에서는 단일 서버를 가정했지만, **단일 서버로 수십억 명의 유저를 처리하는 것은 현실적으로 불가능**합니다.  \n가장 직관적인 해결 방법은 **서버를 늘려서 트래픽을 분산하는 것(수평 확장, Horizontal Scaling)** 입니다.  \n\n예를 들어, **전 세계적으로 10억 명의 유저가 있다면 2억 명이 동시 접속하는 것도 충분히 가능한 시나리오**입니다.  \n그러나 단순히 서버를 늘리는 것만으로는 해결되지 않는 문제들도 존재합니다.  \n\n먼저, **유저가 서로 다른 서버에 연결될 경우 메시지 전송이 불가능**해집니다. 예를 들어, A 유저가 서버 1에 연결되어 있고, B 유저가 서버 2에 연결되어 있다면 두 유저 간 메시지를 주고받기 위해서는 서버 간의 데이터 동기화가 필요해집니다.\n\n이 문제를 해결하기 위해 **Redis Pub/Sub과 같은 메시지 브로커 시스템을 활용**할 수 있습니다.  \nRedis는 **가벼운 해시맵(HashMap) 기반의 소켓 연결 관리 기능을 제공하여 메시지를 빠르게 라우팅**할 수 있습니다. \n \n#### Redis Pub/Sub 기반 메시지 전달 플로우\n**메시지를 받을 때**\n1. 사용자가 서버에 웹소켓을 연결합니다.\n2. 서버는 Redis Pub/Sub에서 해당 유저 ID를 구독 (subscribe) 합니다.\n3. 이후, 해당 유저에게 전달되는 메시지는 **구독된 Pub/Sub 채널을 통해 서버로 전달**됩니다.\n4. 서버는 받은 메시지를 웹소켓을 통해 유저에게 전달합니다.\n\n**메시지를 보낼 때**\n1. 송신자가 메시지를 보내면 **서버는 수신자의 Pub/Sub 채널에 메시지를 Publish**합니다.  \n2. 해당 메시지는 **수신자를 구독(Subscribe) 중인 모든 서버에서 수신**됩니다.  \n3. 각 서버는 **수신자가 현재 연결된 상태인지 확인하고, 연결된 경우 웹소켓을 통해 메시지를 전달**합니다.  \n\n여기서 Redis Pub/Sub의 한계도 존재합니다. Redis Pub/Sub은 **"At most once"** 전송 방식을 가지고 있는데, **구독자가 없을 경우 메시지는 손실**될 수 있습니다.\n\n하지만, 우리는 이미 `Inbox` 테이블을 통해 메시지 내구성을 보장하고 있기 때문에 문제가 되지 않습니다.\n\n그러나 수십억 명의 유저를 감당하려면 Redis Pub/Sub 자체도 확장 가능하게 설계해야 합니다.\nRedis는 클러스터 모드(Redis Cluster)를 지원하지만, Pub/Sub 자체는 기본적으로 클러스터 샤딩을 지원하지 않습니다. 즉, 단순히 Redis Cluster를 활성화한다고 해서 Pub/Sub 메시지가 자동으로 여러 노드에 분산되지 않습니다.\n\n따라서, **수동으로 유저 ID를 기준으로 특정 Redis 노드에 Pub/Sub 메시지를 라우팅하는 방식**을 적용해야 합니다.\n\n#### Redis Cluster 기반 샤딩 적용 플로우\nRedis Cluster는 데이터를 **키(Key) 값에 따라 여러 노드(Shard)로 분산 저장**하는 기능을 제공합니다.  \n이러한 방식은 **Consistent Hashing**을 활용하여 **유저 ID를 기준으로 항상 동일한 노드에서 Pub/Sub 메시지를 처리할 수 있도록 보장**합니다.  \n\n1. **유저 ID를 기반으로 특정 Redis 노드(Shard)를 할당**합니다. (Consistent Hashing 사용)  \n2. 각 서버는 **특정 Redis 노드에서만 Pub/Sub 메시지를 Publish & Subscribe** 합니다.  \n3. **메시지를 보내는 서버가 수신자의 Redis 노드를 찾아 Publish** 합니다.  \n4. 수신자가 연결된 서버는 해당 Redis 노드에서 구독(Subscribe)한 후, 메시지를 전달합니다.  \n\n### 2. 다중 기기 지원 문제\n지금까지는 유저가 하나의 기기만 사용한다고 가정했습니다. 그러나 현실적으로 대부분의 유저는 여러 기기를 사용합니다.\n\n예를 들어, 내 휴대폰에서는 메시지를 받았지만 노트북이 꺼져있었다면 노트북을 켰을 때 **누락된 메시지를 받아서 최신 상태로 동기화** 할 수 있어야 합니다. \n하지만 기존 **유저 단위로 메시지 전달을 추적**하는 `Inbox` 테이블 만으로는 이를 해결할 수 없습니다.\n\n다중 기기 지원 시, 고려해야할 사항은 다음과 같습니다.\n- 유저가 사용하는 모든 기기를 추적해야 합니다. 또한, 유저가 로그인하면 현재 활성화된 모든 기기를 관리할 방법이 필요합니다.\n- 더 이상 사용되지 않는 기기를 자동으로 비활성화 해야합니다.\n- 기기별로 메시지 전송을 관리해야합니다.\n\n이를 해결하기 위해 기존 설계를 최대한 변경하지 않고 방법을 찾아보겠습니다.\n#### 1. `Clients` 테이블 추가 (유저별 활성화된 기기 추적)\n| **userId** | **clientId (device identifier)** | **lastActive** |\n|-----------|-----------------------------------|----------------|\n| user123   | phone_abc                         | 2025-02-20     |\n| user123   | laptop_xyz                        | 2025-02-19     |\n| user456   | tablet_def                        | 2025-02-18     |\n\n#### 2. `Inbox` 테이블을 유저 단위가 아닌 "기기 단위"로 변경\n각 기기가 개별적으로 메시지를 관리할 수 있으므로 기기 간 메시지 동기화 문제를 해결할 수 있고, 기기가 오프라인 상태였다가 다시 연결되었을 때 `Inbox` 테이블을 조회하여 전과 같은 방식으로 최신 메시지들을 받을 수 있습니다.\n\n**변경 전 (유저 단위 Inbox)**\n| **userId** | **messageId** | **status**  |\n|-----------|-------------|----------|\n| user123   | msg_001     | pending  |\n| user123   | msg_002     | pending  |\n\n**변경 후 (기기 단위 Inbox)**\n| **clientId** | **messageId** | **status**  |\n|--------------|---------------|-------------|\n| phone_abc    | msg_001       | pending     |\n| laptop_xyz   | msg_001       | pending     |\n| phone_abc    | msg_002       | pending     |\n| laptop_xyz   | msg_002       | pending     |\n\n#### 3. Pub/Sub 구독 방식 변경\n기존에는 유저 ID 기준으로 서버가 Pub/Sub을 구독했지만 이제는 기기 ID 기준으로 구독하도록 변경합니다.\n또한, 기존에는 **유저 ID**를 기준으로 메시지를 보냈지만 이제는 **유저의 활성화된 모든 기기(Client)를 조회하여 각각 메시지를 전송**해야 합니다.\n\n**메시지를 보낼 때**  \n1. 송신자가 메시지를 보냅니다.\n2. 서버는 **수신자의 `Clients` 테이블을 조회하여 활성화된 기기 목록**을 가져옵니다. \n3. **각 기기의 Pub/Sub 채널에 메시지를 Publish** 합니다.  \n4. 해당 기기에 연결된 Chat Server가 메시지를 받아 웹소켓을 통해 전달합니다.  \n5. **각 기기가 메시지를 받은 후 `ack`를 반환하면, 해당 기기의 `Inbox`에서 메시지를 삭제**합니다.  \n\n## 마무리\n오늘은 위와 같이 대규모 사용자를 대상으로 한 채팅 서비스를 디자인 해보았습니다. 다음 번엔 대규모 사용자를 위한 게시판 서비스를 디자인 해보겠습니다. 감사합니다.\n\n### Reference\n- https://redis.io/docs/latest/develop/interact/pubsub/\n- https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-indexes-general.html\n- https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GSI.html\n- https://youtu.be/cr6p0n0N-VA\n'},{slug:"computer-networks/intro-to-internet-architecture",categorySlug:"computer-networks",title:{ko:"인터넷 아키텍쳐 개요",en:"Introduction to Internet Architecture"},date:"2025-02-22",category:{ko:"컴퓨터 네트워크",en:"Computer Networks"},description:{ko:"인터넷 아키텍쳐와 OSI 7계층에 대한 간단한 설명",en:"Intro to internet architecture and OSI 7 layers"},content:"\n## 개요\n인터넷 아키텍쳐는 **서로 다른 네트워크에 위치한 동일한 애플리케이션을 실행하는 호스트를 연결**할 수 있도록 해줍니다. \n컴퓨터 네트워크는 여러 구성 요소로 이루어진 복잡한 시스템이며 다양한 기술을 기반으로 합니다. \n즉, 서로 다른 유형의 네트워크로 구성될 수 있고, 다양한 애플리케이션을 호스팅할 수도 있습니다.\n\n예를 들어, 두 개의 이메일 클라이언트는 **서로 다른 네트워크(Wifi vs. ethernet 케이블)를 사용하면서도 정상적으로 통신**할 수 있습니다. \n그렇다면 이렇게 다양한 기술과 구성 요소들이 어떻게 하나로 연결되어 각 애플리케이션이 필요한 기능을 수행할 수 있을까요?\n\n네트워크 프로토콜을 설계하는 과정에서, 이런 복잡한 시스템을 보다 체계적으로 만들기 위해 **계층(layer)** 개념이 도입되었습니다.\n\n### 계층\n**네트워크 아키텍쳐에서는 기능을 여러 계층으로 나누어 구현**합니다. 각 계층은 특정 기능을 담당하며, 아래 계층에서 제공하는 서비스를 기반으로 동작합니다.\n또한, 상위 계층이 원활하게 동작할 수 있도록 필요한 서비스를 제공합니다.\n\n항공 시스템으로 비유를 해보겠습니다.\n1. 승객은 티켓을 구매하고, 수하물을 맡기고, 공항 게이트를 통과합니다.\n2. 비행기가 출발하면 탑승한 승객은 목적지까지 이동합니다.\n3. 도착지에서는 비행기에서 내려 게이트를 통과한 후, 수하물을 찾고 공항을 나갑니다.\n\n이 과정에서 각 단계는 특정한 역할을 수행하고, 이전 단계에서 제공한 서비스를 기반으로 운영됩니다. 즉, **한 단계가 끝나야 다음단계가 진행**될 수 있습니다.\n\n네트워크 아키텍쳐에서도 동일한 원리가 적용됩니다. 각 계층은 특정 기능을 수행하고, 모두 연결되어 네트워크가 정상적으로 동작하도록 합니다.\n\n#### 계층 구조의 장점\n1. 확장성: 새로운 기술이나 기능을 쉽게 추가할 수 있습니다.\n2. 모듈성: 각 기능이 독립적으로 설계되어 유지보수가 편리합니다.\n3. 유연성: 특정 계층을 수정하거나 교체하더라도 전체 시스템에 큰 영향을 미치지 않습니다.\n\n위와 같은 이유로 인터넷 아키텍쳐는 계층적인 구조를 기반으로 설계되었고, 효율적이고 비용친화적인 네트워크 구현이 가능합니다.\n\n이렇게 기능을 계층별로 분리하는 것은 분명 여러 장점을 제공하지만, 몇 가지 단점도 존재합니다.\n\n#### 계층 구조의 단점\n1. 계층 간 종속성: 일부 계층의 기능이 다른 계층의 정보를 필요로 하는 경우, 계층 구분의 원칙이 어긋날 수 있습니다.\n2. 중복된 기능: 오류 복구와 같은 특정 기능이 하위/상위 계층에서 중복으로 구현될 수 있습니다.\n3. 추가적인 오버헤드: 계층 간의 추상화로 인해 성능 저하 및 불필요한 데이터 처리가 발생할 수 있습니다.\n\n## OSI 7계층 모델\n국제 표준화 기구(ISO)는 네트워크 통신을 구조화하기 위해 아래와 같은 모델을 제안했습니다.\n| 계층 |\n|-----------|\n| 애플리케이션 계층 (Application Layer)   |\n| 프레젠테이션 계층 (Presentation Layer)  |\n| 세션 계층 (Session Layer)   |\n| 전송 계층 (Transport Layer)  |\n| 네트워크 계층 (Network Layer)  |\n| 데이터 링크 계층 (Data Link Layer)  |\n| 물리 계층 (Physical Layer)  |\n\n### 7계층: 애플리케이션 계층 (Application Layer)\n애플리케이션 계층은 다양한 **애플리케이션을 지원하는 여러 프로토콜을 포함**합니다. 대표적인 프로토콜은 다음과 같습니다.\n- HTTP (HyperText Transfer Protocol): 웹페이지 요청 및 전송\n- SMTP (Simple Mail Transfer Protocol): 이메일 송수신\n- FTP (File Transfer Protocol): 파일 전송\n- DNS (Domain Name System): 도메인 이름을 IP 주소로 변환\n\n애플리케이션 계층에서는 구현된 애플리케이션에 따라 다양한 서비스를 제공하고, 이 계층을 이용하는 인터페이스와 사용되는 프로토콜도 애플리케이션에 따라 달라집니다.\n\n**애플리케이션 계층에서는 데이터를 `메시지 (Message)`라고 부릅니다.**\n\n### 6계층: 프레젠테이션 계층 (Presentation Layer)\n프레젠테이션 계층은 **데이터 형식을 변환하는 역할**을 하며, 하위 계층에서 받은 정보를 애플리케이션 계층이 이해할 수 있도록 변환합니다.\n\n예를 들어, 비디오 스트림을 특정 형식으로 변환하거나 숫자 데이터를 big endian에서 little endian으로 변환하는 것 등이 있습니다.\n\n### 5계층: 세션 계층 (Session Layer)\n세션 계층은 애플리케이션 간의 세션을 관리하는 역할을 합니다. **동일한 애플리케이션 프로세스에서 여러 개의 전송 스트림이 존재할 경우, 이를 하나의 세션으로 묶어 관리**합니다.\n\n예를 들어, 화상 회의 애플리케이션에서 오디오 스트림과 비디오 스트림을 동기화하여 올바르게 전달하도록 합니다. 세션 계층이 있어야 오디오와 비디오가 일관되게 전달되고 하나의 통합된 세션으로 유지될 수 있습니다.\n\n### 4계층: 전송 계층 (Transport Layer)\n전송 계층은 **호스트 간(end-to-end) 통신**을 담당하는 계층으로, 두 가지 주요 프로토콜이 사용됩니다.\n\n#### 1. TCP (Transmission Control Protocol)\n- 연결 지향적 서비스 (Connection-oriented service)\n- 애플리케이션 계층 메시지의 신뢰성 보장 (**Guaranteed delivery**)\n- 흐름 제어 (**Flow control**): 송신자와 수신자의 속도 조정\n- 혼잡 제어 (**Congestion control**): 네트워크 혼잡이 감지되면 송신 속도 조절\n#### 2. UDP (User Datagram Protocol)\n- 연결 없는 **connectionless** 서비스\n- **Best-effort 전송**: 신뢰성, 흐름 제어, 혼잡 제어가 없음\n- 실시간 스트리밍, VoIP, 온라인 게임 등 **속도가 중요한 애플리케이션**에서 주로 사용\n\n즉, 이 계층은 데이터가 중간에 손실되거나 순서가 뒤바뀌지 않도록 관리하여 최종 사용자에게 올바른 정보를 전달합니다.\n**전송 계층에서는 데이터를 `세그먼트 (Segment)`라고 부릅니다.**\n\n### 3계층: 네트워크 계층 (Network Layer)\n네트워크 계층의 역할은 **호스트 간 데이터그램(Datagram) 전달**입니다. 라우팅 프로토콜을 통해 최적의 경로를 선택하고, 그 경로를 통해 데이터를 전달합니다.\n\n**데이터 전달 과정**\n1. **전송 계층 → 네트워크 계층 전달**: 먼저, 송신 호스트의 4계층인 전송 계층에서 생성된 데이터를 네트워크 계층으로 넘깁니다. 이 데이터는 아직 `세그먼트` 형태로 존재합니다.\n2. **데이터그램 변환 및 라우팅**: 네트워크 계층은 받은 세그먼트를 **데이터그램으로 변환**합니다. 이때, 각 데이터그램에는 데이터의 목적지 주소, 출발지 주소 등 필요한 정보가 포함됩니다. 이 정보들을 바탕으로 데이터그램이 목적지에 도착할 수 있도록 **최적의 경로를 찾아 여러 라우터를 거쳐 전송**합니다.\n3. **목적지 도착 및 재구성**: 최종적으로 데이터그램들은 목적지 호스트에 도착하면 다시 모여 **원래의 세그먼트 형태로 재구성**되고, 이후 4계층인 전송 계층으로 전달되어 최종 데이터로 사용됩니다.\n\n**핵심 프로토콜**\n- **IP (Internet Protocol)**\n  - 인터넷의 핵심 프로토콜, 모든 인터넷 호스트 및 네트워크 장치는 IP 프로토콜을 실행해야 함\n  - 데이터그램의 **헤더 구조 및 주소 지정 방식 정의**\n  - 출발지와 목적지 간 패킷 전송 지원\n- **라우팅 프로토콜 (Routing Protocol)**\n  - 데이터그램이 송신지에서 목적지까지 **어떤 경로를 따라 이동할지 결정**\n  - EX) OSPF, BGP, RIP\n\n**네트워크 계층에서는 데이터를 `데이터그램 (Datagram)`이라고 부릅니다.**\n\n### 2계층: 데이터 링크 계층 (Data Link Layer)\n데이터 링크 계층은 **인접한 네트워크 장비 간의 안정적인 데이터 전송**을 담당 합니다. 데이터를 프레임 단위로 묶어, 물리적 연결에서 오류 검출과 재전송 기능을 수행합니다.\n\n**주요 프로토콜 예시**: Ethernet, PPP (Point-to-Point Protocol), WiFi\n\n**데이터 전송 과정**\n1. **데이터 준비**: 네트워크 계층에서 생성된 데이터그램이 각 노드(호스트 또는 라우터)로 전달됩니다.\n2. **프레임 캡슐화**: 데이터 링크 계층은 이 데이터그램을 프레임으로 포장하면서, 오류 검출 및 수정에 필요한 정보를 추가합니다.\n3. **단일 링크 전송**: 프레임은 물리 계층을 통해 바로 인접한 다음 네트워크 장비로 전송됩니다.\n4. **프레임 해체**: 다음 노드는 도착한 프레임의 오류를 검사하고, 문제가 없으면 프레임을 열어 원래의 데이터그램을 추출해 네트워크 계층으로 전달합니다.\n\n데이터 링크 계층은 **신뢰성 있는 데이터 전송(Reliable delivery)** 을 기반으로 합니다. 단, 이것은 TCP의 신뢰성 보장과는 다릅니다. TCP는 송신지에서 수신지까지의 전체 경로를 보장하지만, 데이터 링크 계층은 단일 링크에서만 보장합니다.\n\n**데이터 링크 계층에서는 데이터를 `프레임 (Frame)`이라고 부릅니다.**\n\n### 1계층: 물리 계층 (Physical Layer)\n물리 계층은 **하드웨어와 직접 상호작용 하며, 물리적 링크를 통해 비트를 전송**하는 역할을 합니다.\n\n프레임 내의 비트들을 송수신하고, 네트워크의 물리적인 전송 매체(케이블, 무선 신호 등)에 따라 다른 방식으로 데이터를 전달합니다.\n\n물리 계층에서 사용 되는 주요 기술 및 매체에는 꼬임쌍선(Twisted-Pair copper wire), 동축 케이블(coaxial cable), 광섬유(single-mode fiber optics) 등이 있습니다.\n\n데이터 링크 계층의 대표적인 프로토콜인 이더넷(Ethernet)은 **물리 계층의 전송 매체에 따라 다른 물리적 프로토콜을 사용**합니다. 예를 들어, UTP(비차폐 꼬임쌍선) 케이블, 무선(Wifi) 등 다양한 매체에서 동작할 수 있도록 설계되었습니다.\n\n**물리 계층에서는 데이터를 `비트 (Bits)`단위로 다룹니다.**\n\n### OSI 7계층을 통한 end-to-end 데이터 이동 경로\n\n한 호스트에서 다른 호스트로 데이터가 이동하는 과정을 OSI 7계층 모델을 이용해 단계별로 살펴보겠습니다.\n```\n         송신 호스트                                               수신 호스트\n──────────────────────────────────────────────────────────────────────────────\n     [ 애플리케이션 계층 ]                                         [ 애플리케이션 계층 ]  \n      HTTP, FTP, SMTP                                          HTTP, FTP, SMTP \n              │                                                       ▲  \n              ▼                                                       │ \n      [ 프레젠테이션 계층 ]                                        [ 프레젠테이션 계층 ]  \n       데이터 압축/암호화                                          데이터 복호화/압축 해제  \n              │                                                       ▲  \n              ▼                                                       │ \n         [ 세션 계층 ]                                             [ 세션 계층 ]  \n        세션 설정 및 유지                                          세션 동기화 및 종료  \n              │                                                       ▲  \n              ▼                                                       │ \n         [ 전송 계층 ]                                             [ 전송 계층 ]  \n       TCP/UDP 포트 관리                                        TCP/UDP 데이터 재조립  \n              │                                                       ▲  \n              ▼                                                       │ \n       [ 네트워크 계층 ]                                           [ 네트워크 계층 ]  \n     IP 주소 지정 및 라우팅                                       목적지 IP 확인 및 전달  \n              │                                                       ▲  \n              ▼                                                       │ \n      [ 데이터 링크 계층 ]                                         [ 데이터 링크 계층 ]  \n    MAC 주소 지정 및 프레임화                                     프레임 해체 및 MAC 검증  \n              │                                                       ▲  \n              ▼                                                       │ \n         [ 물리 계층 ] ─────────────────────────────────────▶       [ 물리 계층 ]  \n 비트 스트림 전송 (WiFi, LAN)                                 신호를 비트로 변환하여 상위 전달  \n\n```\n\n## 마무리\n이번 포스트에서는 OSI 7 layer 에 대해 간단히 알아보았습니다. 다음 게시글에서는 계층 간의 캡슐화, end-to-end principle 등에 대해 알아보겠습니다.\n"},{slug:"computer-networks/encapsulation-de-encapsulation",categorySlug:"computer-networks",title:{ko:"계층 간 캡슐화와 디캡슐화, 종단 간 원칙",en:"Layer Encapsulation and De-encapsulation, E2E principle"},date:"2025-02-22",category:{ko:"컴퓨터 네트워크",en:"Computer Networks"},description:{ko:"계층 간 캡슐화, 디캡슐화에 대한 설명",en:"How layer encapsulation and de-encapsulation work"},content:'\n## 개요\n네트워크 계층과 각 계층에서 실행되는 프로토콜들이 서로 어떻게 소통하는지 이해하기 위해 캡슐화(encapsulation)과 디캡슐화(de-encapsulation) 개념을 살펴보겠습니다.\n\n## 캡슐화 과정 (Encapsulation)\n캡슐화는 송신 호스트에서 데이터를 보낼 때 각 계층이 자신의 헤더를 추가하면서 이루어집니다.\n \n가장 먼저, 애플리케이션 계층에서 생성된 메시지는 전송 계층으로 전달됩니다. \n전송 계층에서는 이 메시지에 **전송 계층 헤더(HT, Transport Layer Header)** 를 추가하여 **세그먼트**를 형성합니다. \n이 추가된 정보는 수신 호스트에서 올바른 애플리케이션으로 데이터를 전달할 수 있도록 돕고, 오류 감지 및 데이터 무결성을 확인하는 역할을 합니다.\n\n세그먼트는 네트워크 계층으로 전달되며, 네트워크 계층에서는 **네트워크 계층 헤더(HN, Network Layer Header)** 를 추가하여 **데이터그램**을 생성합니다.\n이 헤더에는 **송신지 및 목적지의 IP 주소**가 포함되어 있어, 데이터가 정확한 목적지로 전송될 수 있도록 합니다.\n\n다음으로, 데이터그램은 데이터 링크 계층으로 이동하며 **데이터 링크 계층 헤더(HL, Link Layer Header)** 를 추가하여 **프레임**을 생성합니다.\n프레임은 물리 계층을 통해 비트 단위로 변환되며, 실제 네트워크 매체를 통해 전송됩니다.\n\n## 디캡슐화 과정 (De-encapsulation)\n수신 호스트에서는 위 과정을 반대로 수행합니다. \n\n물리 계층에서 수신된 비트들은 데이터 링크 계층으로 전달되며, 여기서 **프레임의 헤더(HL)** 가 제거된 후 네트워크 계층으로 전달됩니다.\n\n네트워크 계층에서는 **데이터그램의 헤더(HN)** 를 확인하고 제거한 후, 전송 계층으로 데이터를 넘깁니다.\n\n마지막으로 전송 계층에서는 **세그먼트의 헤더(HT)** 를 분석하여 올바른 애플리케이션으로 데이터를 전달합니다. 최종적으로 애플리케이션 계층은 메시지를 해석하고 사용자에게 출력합니다.\n\n### 중간 장치와 캡슐화\n송신지에서 목적지까지의 경로에는 **라우터**나 **스위치** 같은 네트워크 장치들이 포함될 수 있습니다. 이러한 장치들은 네트워크 계층을 처리하는 방식이 다릅니다.\n\n**라우터**는 **물리 계층, 데이터 링크 계층, 네트워크 계층 (1-3계층)** 을 처리하며, 패킷을 분석하여 최적의 경로를 찾아 전송합니다.\n\n**스위치**는 **물리 계층과 데이터 링크 계층 (1-2계층)** 까지만 처리하며, 프레임을 기반으로 목적지를 결정합니다.\n\n## 종단 간 원칙 (End-to-End Principle)\n종단 간 원칙(E2E principle)은 현재의 인터넷 아키텍쳐를 형성하는데 중요한 역할을 한 설계원칙입니다. \n이 원칙은 특정한 애플리케이션 기능을 네트워크 코어(핵심부)에서 처리하는 것이 아니라, **가능하면 네트워크의 끝단(end systems)** 에서 구현해야 한다는 개념을 제안합니다.\n\n즉, **네트워크 자체는 단순하고 최소한의 역할만 수행해야 하며, 복잡한 기능과 지능은 애플리케이션이 실행되는 종단에서 구현하는 것이 바람직하다**는 철학입니다.\n\n네트워크 설계의 기초가 된 논문 "End-to-End Arguments in System Design" (Saltzer, Reed, Clark)에 따르면, 어떤 기능이 완벽하게 구현되려면 **해당 기능을 필요로 하는 애플리케이션이 직접 수행해야 한다**고 설명합니다.\n네트워크 자체에서 특정 기능을 제공하려 해도, 개별 애플리케이션이 이를 완전히 활용하거나 맞춤형으로 조정하기 어렵기 때문입니다.\n\n또한, 모든 애플리케이션이 동일한 기능을 필요로 하는 것이 아니기 때문에, 네트워크 코어에 특정 기능을 추가하면 이를 필요로 하지 않는 애플리케이션에도 강제 적용되는 문제가 발생할 수 있습니다.\n따라서, 네트워크 코어는 필수적이고 공통적인 기능만 수행하도록 설계해야 합니다.\n\n종단 간 원칙 덕분에 인터넷은 빠르게 성장할 수 있었습니다. 네트워크의 핵심부를 바꾸는 것은 어렵지만, 끝단에서 혁신적인 애플리케이션과 서비스가 자유롭게 개발될 수 있었기 때문입니다.\n다양한 애플리케이션이 유연하게 설계될 수 있었던 것도 네트워크의 코어가 아닌 엔드포인트에서 기능을 구현하는 방식을 따랐기 때문입니다.\n\n결과적으로, **하위 계층의 프로토콜은 특정 애플리케이션에 의존하지 않고, 네트워크 자원을 효율적으로 관리하는 역할에 집중**할 수 있습니다.\n이처럼 상위 계층은 개별 애플리케이션에 맞게 설계되고, 하위 계층은 애플리케이션과 무관하게 네트워크 인프라를 최적화하는 것이 종단 간 원칙의 핵심입니다.\n\n### 종단 간 원칙의 위반 사례\n종단 간 원칙은 인터넷의 발전과 확장에 많은 이점을 제공했지만, 현실적인 이유로 인해 이 원칙이 지켜지지 못하는 경우도 존재합니다.\n대표적인 사례로 **방화벽(Firewall)** 과 **네트워크 주소 변환(NAT, Network address translation) 박스**가 있습니다.\n\n#### 방화벽과 트래픽 필터링\n방화벽은 네트워크의 경계에서 동작하며, 네트워크를 통해 들어오거나 나가는 트래픽을 모니터링하는 역할을 합니다.\n보안 정책에 따라 정상적인 트래픽은 허용하고, 악의적인 트래픽은 차단합니다.\n\n이건 보안 측면에서 매우 중요하지만, **중간 네트워크 장치가 엔드 호스트 간의 통신을 차단할 수 있기 때문에** 종단 간 원칙을 위반하는 사례가 됩니다.\n방화벽이 특정 패킷을 차단하면 송신 호스트와 수신 호스트가 직접 통신하는 것이 불가능해질 수 있기 때문입니다.\n\n#### NAT (Network Address Translation) 박스\n인터넷 주소 공간이 부족해지면서 등장한 해결책 중 하나가 **NAT** 입니다. \nNAT은 **하나의 공인 IP 주소를 여러 개의 사설 IP 주소를 사용하는 내부 네트워크와 공유하도록 하는 기술**입니다.\n\n**NAT의 동작 방식**\n\n가정에서 여러 대의 기기를 인터넷에 연결한다고 가정해보면, 보통 Internet service provider(ISP)는 공유기에 **단 하나의 public IP 주소**를 할당합니다.\n하지만 가정 내의 **각 장치는 사설 네트워크에서 개별적인 private IP 주소**를 가질 수 있습니다.\n\n이 때, NAT이 동작하는 방식은 다음과 같습니다.\n1. 내부 네트워크의 장치가 public internet 상의 호스트로 데이터를 전송하려고 하면, 공유기는 **출발지 IP 주소를 자신의 public IP 주소로 변환**한 후 외부로 전송합니다.\n2. 외부에서 오는 응답 패킷의 목적지 IP는 공유기의 public IP 주소이므로, 공유기는 **NAT 변환 테이블을 참고하여 적절한 내부 IP로 변환한 후 전달**합니다.\n\nNAT 변환 테이블은 **public IP 주소 및 포트 번호**와 **내부 네트워크의 IP 주소 및 포트 번호**를 매핑하여 관리합니다.\n예를 들어, 내부 호스트 `10.0.0.4`가 포트 `3345`를 사용하여 public IP `120.70.39.4`의 포트 `5001`과 통신한다고 가정하면:\n- `출발지 IP 10.0.0.4, 출발지 포트 3345` → 변환 후 `IP: 120.70.39.4, 출발지 포트: 5001`\n- `목적지 IP 120.70.39.4, 목적지 포트 5001` → 변환 후 `IP: 10.0.0.4, 목적지 포트: 3345`\n\n이런 방식으로 NAT는 **단 하나의 public IP address를 이용해 다수의 내부 장치가 인터넷과 통신**할 수 있도록 해줍니다.\n\n#### NAT가 종단 간 원칙을 위반하는 이유\nNAT를 사용하는 네트워크 내부의 호스트는 public internet에서 직접 접근할 수 없습니다. 즉, 외부 호스트가 NAT 내부의 호스트로 직접 연결을 시도하는 것이 기본적으로 불가능합니다.\n\n종단 간 원칙의 핵심은 **인터넷의 엔드포인트(호스트)들이 직접 통신할수 있도록 하는 것**인데, NAT은 이 원칙을 깨고 중간에서 IP 주소를 변환하고 트래픽을 조정하는 역할을 합니다.\n\n따라서 NAT는 **네트워크 코어에서 특정한 기능을 수행하면서, 엔드 호스트 간 직접적인 통신을 방해하기 때문에** E2E 원칙을 위반하는 사례로 간주됩니다.\n\n#### NAT 문제를 해결하기 위한 우회 방법\nNAT로 인해 공인 인터넷의 호스트가 NAT 내부 호스트와 직접 통신할 수 없는 문제가 발생하지만, 이를 해결하기 위한 몇 가지 우회 기법이 존재합니다.\n- **STUN (Session Traversal Utilities for NAT)**\n  - NAT가 사용되는 환경에서 클라이언트가 **자신의 공인 IP 주소와 포트 번호를 발견할 수 있도록 도와주는 프로토콜**입니다.\n  - NAT 뒤에 있는 호스트가 외부 서버를 통해 자신이 사용하는 public IP/port를 확인하고, 이를 통해 통신을 설정할 수 있습니다.\n- **UDP Hole Punching**\n  - UDP 기반의 연결을 설정할 때, NAT를 통해 양쪽 호스트가 서로 직접 연결을 수립하는 기법입니다.\n  - 양쪽 호스트가 **동시에 NAT 바깥의 공용 서버에 패킷을 전송**함으로써, **각 공유기의 NAT 변환 테이블을 조작**하여 직접적인 UDP 연결을 가능하게 합니다.\n  - P2P network (Skype, 온라인 게임 등)에서 주로 사용됩니다.\n  \n  \n그럼, **종단 간 원칙을 위반하지 않는 사례**도 살펴보겠습니다.\n\nWiFi와 같은 일부 데이터 링크 계층 프로토콜은 기본적인 오류 수정 기능을 포함하고 있습니다. 이는 물리적 매체가 간섭이나 노이즈로 인해 쉽게 오류가 발생할 수 있기 때문입니다.\n\n그렇다면 **이러한 오류 수정 기능이 E2E principle을 위반하는 것일까요?**\n\n정답은 **위반이 아니다** 입니다.\n\n종단 간 원칙의 위반은 일반적으로 **특정 기능이 엔드 호스트에서만 완벽하게 구현될 수 있음에도 불구하고, 네트워크 내부에서 이를 처리하려고 할 때 발생**합니다. \n\n하지만 WiFi의 오류 수정 기능은 이와 다릅니다. **물리적 계층의 특성상 반드시 필요한 기능이기 때문**입니다.\n무선 네트워크는 유선 네트워크보다 더 많은 간섭과 신호 감쇠를 겪기 때문에, 기본적인 오류 검출 및 수정 기능이 없으면 안정적인 통신이 불가능해집니다.\n\n즉, 이러한 기능이 없으면 상위 계층(전송 계층, 애플리케이션 계층 등)에서 원활한 데이터 송수신이 어려워지므로, 네트워크의 전반적인 신뢰성이 떨어질 수 있습니다.\n데이터 링크 계층에서 이루어지는 오류 수정은 종단 간 원칙을 위반하는 것이 아니라, **네트워크의 안정성을 보장하기 위한 현실적인 조치**라고 볼 수 있습니다.\n'},{slug:"computer-networks/internet-protocol-stack",categorySlug:"computer-networks",title:{ko:"인터넷 프로토콜 스택 구조",en:"Hourglass Shape of Internet Protocol Stack"},date:"2025-02-23",category:{ko:"컴퓨터 네트워크",en:"Computer Networks"},description:{ko:"인터넷 프로토콜 스택과 모래시계 아키텍쳐에 대한 설명",en:"Internet protocol stack and its hourglass shape"},content:"\n인터넷 프로토콜 스택은 모래시계 형태의 계층 구조를 가지고 있습니다. 하지만 인터넷 아키텍쳐가 처음부터 이런 구조를 가지고 있었던 것은 아닙니다.\n\n1990년대 초반까지만 해도 인터넷의 네트워크 계층은 IPv4 하나로 통일된 것이 아니라, **여러 개의 경쟁 프로토콜이 존재했던 시기**였습니다.\n예를 들어, IPX(Internetwork Packet Exchange), X.25 Frame Relay Protocol 등이 IPv4와 경쟁하며 사용되었는데 시간이 지나면서 다른 프로토콜들은 점점 사라지게 되었습니다.\n\n인터넷 프로토콜 스택이 모래시계 모양을 갖게 된 이유는 **상위 계층(애플리케이션 계층)과 하위 계층(물리 계층)의 변화는 활발하게 이루어지는 반면, 중간 계층(네트워크/전송 계층)은 오랜 기간 유지되었기 때문**입니다.\n\n#### 상위 계층에서의 혁신\n애플리케이션 계층에서는 새로운 서비스와 프로토콜이 지속적으로 등장하고 사라지는 것이 일반적입니다. \n웹 브라우징을 위한 **HTTP/HTTPS**, 파일 전송을 위한 **FTP**, 이메일을 위한 **SMTP, IMAP, POP3** 등 수많은 프로토콜이 등장했고, 최근에는 **RESTful API, gRPC** 등 새로운 애플리케이션 계층 기술도 발전하고 있습니다.\n애플리케이션 계층은 새로운 사용자 요구사항과 기술 발전에 맞춰 빠르게 변화하기 때문에 지속적인 혁신이 이루어집니다.\n\n#### 하위 계층에서의 변화\n물리 계층도 새로운 전송 매체가 등장하면서 지속적으로 변화하고 있습니다.\n데이터 전송 속도를 높이고, 더 안정적인 네트워크를 구축하는 것이 주요 목표이기 때문에 하드웨어 기술이 발전함에 따라 새로운 프로토콜과 기술이 빠르게 도입됩니다.\n\n### 중간 계층의 안정성: IPv4, UDP, TCP가 쉽게 바뀌지 않는 이유\n네트워크 및 전송 계층은 인터넷의 핵심 기능을 담당하며, **모든 상위 및 하위 계층이 이 계층에 의존**하기 때문에 쉽게 대체되기 어렵습니다.\n\n1. **호환성과 네트워크 효과**\n    - 네트워크 계층에서 하나의 프로토콜이 표준으로 자리 잡으면, 모든 네트워크 장비(라우터, 스위치, 서버 등)가 이를 지원해야 합니다.\n    - IPv4는 초기에 널리 채택되었고, 이후 네트워크 인프라 대부분이 IPv4를 기반으로 구축되었기 때문에 다른 네트워크 계층 프로토콜이 경쟁에서 도태되었습니다.\n    - 전송 계층에서도 TCP/UDP가 거의 모든 인터넷 애플리케이션에서 사용되었기 때문에, 새로운 전송 계층 프로토콜이 등장하더라도 기존의 네트워크와 호환성을 유지하는 것이 어렵습니다.\n2. **대체 비용이 높음**\n    - 새로운 네트워크 계층 프로토콜이 등장했더라도, 기존의 인프라와 완전히 호환되지 않으면 적용하기 어렵습니다.\n    - IPv6은 1990년대부터 개발되었지만, 여전히 IPv4가 널리 이용되는 이유도 기존 인프라와의 호환성 문제와 전환 비용 때문입니다.\n3. **핵심 기능의 단순성**\n    - 네트워크 계층의 역할은 **데이터를 최적의 경로를 통해 전달**하는 것입니다.\n    - 전송 계층의 TCP와 UDP는 각각 **신뢰성이 필요한 통신**과 **빠른 데이터 전송이 필요한 통신** 이라는 단순하고 강력한 역할을 수행합니다.\n    - 이러한 기본적인 기능이 잘 동작하기 때문에 새로운 프로토콜을 도입할 유인이 적습니다.\n"},{slug:"computer-networks/hosts-and-networks",categorySlug:"computer-networks",title:{ko:"계층별 장치와 스패닝 트리 알고리즘",en:"Layer Devices and Spanning Tree Algorithm"},date:"2025-02-23",category:{ko:"컴퓨터 네트워크",en:"Computer Networks"},description:{ko:"물리, 데이터링크, 네트워크 계층의 장치들과 네트워크 간 연결 방법",en:"L1, L2, L3 devices and interconnecting hosts"},content:"\n컴퓨터 네트워크에는 호스트 간 연결을 제공하거나 서로 다른 네트워크를 연결하는 다양한 장치들이 존재합니다.\n이러한 장치들은 서로 다른 계층에서 동작하며, 각각 고유한 기능과 한계를 가지고 있습니다.\n\n## 계층별 장치\n### 물리 계층 (L1) 장치: 리피터(Repeater)와 허브(Hub)\n리피터와 허브는 **물리 계층**에서 동작하는 장치로, **디지털 신호를 수신하고 그대로 재전송하여 ethernet 세그먼트 간 연결을 제공**합니다.\n\n**리피터**는 신호가 약해지는 것을 방지하기 위해 신호를 증폭하여 전달하는 역할을 합니다.\n\n**허브**는 여러 호스트를 물리적으로 연결하는 장치로, 수신된 데이터를 네트워크에 연결된 모든 장치로 전달합니다.\n\n이런 장치들은 대부분 **단순하고 저렴하며, 계층적으로 구성할 수 있다는 장점**이 있습니다. \n하지만, **연결된 모든 호스트가 동일한 충돌 도메인(Collision domain)에 족하게 되어 하나의 링크를 공유하는 방식으로 데이터 충돌이 발생할 가능성이 높습니다.**\n\n### 데이터 링크 계층 (L2) 장치: 브릿지(Bridge)와 L2 스위치(L2 Switch)\n브릿지와 스위치는 **데이터링크 계층**에서 동작하며, **MAC 주소를 기반으로 패킷을 전달**하는 역할을 합니다.\n\n**브릿지**는 두 개의 네트워크 세그먼트를 연결하며 수신한 패킷의 MAC 주소를 확인하여 적절한 포트로 전달합니다.\n\n**L2 스위치**는 여러 개의 포트를 가지고 있으며, 각 포트마다 MAC 주소를 학습하여 목적지 MAC 주소에 따라 패킷을 전송합니다.\n\n이 장치들은 **직접 연결되지 않은 호스트 간의 통신을 가능**하게 하며, 네트워크 충돌을 줄이는 역할을 합니다.\n하지만 출력 포트의 대역폭이 제한되어 있어 **트래픽 도착 속도가 출력 용량을 초과하면 버퍼링이 필요**하며, **버퍼가 가득 차면 패킷 손실이 발생**할 수 있습니다.\n\n#### 학습 브릿지 (Learning Bridge)\n브릿지는 여러 개의 입출력을 가지고 있는데, 모든 프레임을 무조건 전송하는 것이 아니라 학습 과정을 통해 목적지에 따라 프레임을 선택적으로 전달할 수 있습니다.\n\n이를 위해 **포워딩 테이블**을 유지하며 프레임이 불필요한 포트로 전달되는 것을 방지합니다.\n\n\n**브릿지의 프레임 전달 방식**\n1. 브릿지는 처음에 모든 포트를 통해 프레임을 전달합니다. (Unknown unicast)\n2. 수신된 프레임의 출발지 주소를 확인해서 **해당 호스트가 어느 포트에 위치하는지 학습**합니다.\n3. 포워딩 테이블을 구축해서 이후엔 필요한 포트로만 프레임을 전달합니다.\n4. 동일한 포트에 있는 호스트 간의 통신은 해당 포트 내에서만 처리하여 네트워크 트래픽을 최적화합니다.\n\n#### 스패닝 트리 알고리즘과 루프 방지\n브릿지를 사용하여 LAN을 확장하는 경우 **네트워크 내에 루프가 발생하면 패킷이 무한히 순환하는 문제가 발생**할 수 있습니다.\n이는 브릿지가 들어오는 프레임을 여러 개의 포트로 중복 전송하면서 발생하는 현상입니다.\n\n이 문제를 해결하기 위해 **스패닝 트리 알고리즘**을 사용할 수 있습니다. \n이 알고리즘은 **네트워크 토폴로지를 트리 형태로 변환**하여 루프를 제거하는 역할을 합니다.\n\n스패닝 트리 알고리즘은 아래와 같이 동작합니다.\n1. 모든 브릿지가 초기에는 자신을 루트로 간주하고 메시지를 보냅니다.\n2. 네트워크 내에서 가장 작은 ID를 가진 브릿지가 루트 브릿지로 선택됩니다.\n3. 각 브릿지는 루트까지의 최단 경로를 찾고, 그 정보를 업데이트하여 공유합니다.\n4. 루프를 방지하기 위해 일부 링크(포트)가 비활성화 됩니다.\n5. 결과적으로 트리 구조가 형성되며 패킷 루프 문제가 해결됩니다.\n\n### 네트워크 계층 (L3) 장치: 라우터(Router)와 L3 스위치 (L3 Switch)\n라우터와 L3 스위치는 **IP 주소를 기반으로 서로 다른 네트워크 간의 데이터 전달을 수행**합니다.\n이 장치들은 네트워크를 여러 개의 서브넷으로 분할하여 트래픽을 효율적으로 관리할 수 있도록 도와주고, **라우팅 프로토콜을 사용하여 패킷을 최적의 경로로 전달**합니다.\n\n**라우터**는 IP 주소를 확인하여 최적의 경로를 선택하고, 패킷을 전달하는 기능을 수행합니다.\n\n**L3 스위치**는 라우팅 기능이 포함된 스위치로, 일반적인 L2 스위치보다 더 빠른 속도로 IP 패킷을 전달할 수 있습니다.\n\n"},{slug:"computer-networks/multiplexing-demultiplexing",categorySlug:"computer-networks",title:{ko:"전송 계층의 멀티플렉싱과 디멀티플렉싱",en:"Transport layer's Multiplexing and Demultiplexing"},date:"2025-02-23",category:{ko:"컴퓨터 네트워크",en:"Computer Networks"},description:{ko:"전송 계층의 멀티플렉싱/디멀티플렉싱에 대해 알아봅시다",en:"How multiplexing/demultiplexing work in transport layer"},content:"\n## 멀티플렉싱/디멀티플렉싱\n전송 계층의 주요 기능 중 하나는 **한 호스트에서 여러 애플리케이션이 동시에 네트워크를 사용할 수 있도록 하는 멀티플렉싱** 기능입니다.\n\n멀티플렉싱은 **송신 호스트**가 여러 **애플리케이션의 데이터를 수집하고, 이를 전송 계층 세그먼트로 변환**하는 과정입니다. \n\n반대로, 디멀티플렉싱은 **수신 호스트**가 네트워크 계층에서 전달받은 **세그먼트를 확인하고, 올바른 애플리케이션으로 데이터를 전달**하는 과정입니다.\n\n### 멀티플렉싱이 필요한 이유\n컴퓨터에서 여러 애플리케이션이 동시에 네트워크를 사용할 때, **각 애플리케이션이 올바른 데이터 패킷을 받도록 보장**하는 것이 중요합니다.\n\n예를 들어 한 사용자가 인스타그램을 사용하면서 동시에 spotify에서 음악을 듣고 있다면 두 개의 애플리케이션이 각각 다른 서버와 데이터를 송수신해야 합니다.\n\n하지만 네트워크 계층에서는 오직 IP 주소만 사용하기 때문에, **패킷이 어떤 애플리케이션으로 전달되어야 하는지**를 구분할 수 없습니다.\n\n#### 멀티플렉싱 동작 원리\n\n전송 계층에서는 각 애플리케이션을 구분하기 위해 **포트 번호**를 사용합니다.\n1. 각 애플리케이션은 고유한 포트 번호를 할당받고, 이를 통해 통신을 진행합니다.\n2. 애플리케이션이 네트워크를 사용할 때, 소켓을 열어서 특정 포트에서 데이터를 수신하도록 설정합니다.\n3. 따라서 패킷이 도착하면 **전송 계층은 포트 번호를 확인하고 해당 포트와 연결된 애플리케이션으로 데이터를 전달**합니다.\n\n\n만약 위 예제 사용자의 상황이라면 전송 계층은 **각 애플리케이션이 사용하는 포트 번호**를 기반으로 데이터를 분류해서 처리해야 합니다.\n- 인스타그램 -> 포트 443 (HTTP) 사용\n- spotify -> 포트 4070 사용\n\n전송 계층은 이 정보를 기반으로 **멀티플렉싱하여 패킷을 송신**하고, **수신 측에서는 디멀티플렉싱**하여 해당 애플리케이션으로 데이터를 전달합니다.\n### 멀티플렉싱 종류\n멀티플렉싱 방식은 **연결을 설정하는지 여부**에 따라 두 가지로 나뉩니다.\n\n1. **비연결형 (Connectionless) 멀티플렉싱**\n    - **UDP 기반** 멀티플렉싱\n    - 송신자가 수신자와 연결을 설정하지 않고 바로 데이터를 전송\n    - **패킷 손실 가능성이 있지만 빠르고 간단**한 방식\n    - DNS, VoIP, 온라인 게임 등에서 사용\n2. **연결형 (Connection-Oriented) 멀티플렉싱**\n    - **TCP 기반** 멀티플렉싱\n    - 송신자와 수신자가 먼저 연결을 설정한 후 데이터를 전송 **(3-way handshake)**\n    - **데이터의 신뢰성과 순서** 보장\n    - 웹 브라우징, 이메일, 파일 전송 등에서 사용\n    \n## 전송 계층의 소켓 식별 방법\n전송 계층은 소켓을 식별하기 위해 세그먼트의 특정 필드를 활용합니다. \n\n### UDP의 소켓 식별 방법\nUDP는 `Two-Tuple`을 사용하여 소켓을 식별합니다. \n\nUDP 소켓은 **목적지 IP 주소**와 **목적지 포트 번호**로 구분되는데, 송신 호스트가 **어떤 출발지 포트를 사용하든 상관없이** 동일한 목적지 포트로 전송된 데이터는 같은 소켓으로 전달됩니다. \n\n따라서 **여러 호스트가 동일한 서버의 같은 포트**로 데이터를 보낼 수도 있습니다.\n\n### TCP의 소켓 식별 방법\nTCP는 `Four-Tuple`을 사용하여 소켓을 식별합니다.\n\nTCP 소켓은 **출발지 IP 주소, 출발지 포트, 목적지 IP, 목적지 포트**로 구분됩니다.\n\n즉, 같은 서버의 동일한 포트로 여러 클라이언트가 접속하더라도, **각 클라이언트의 출발지 IP 및 포트가 다르므로 개별적인 연결을 유지**할 수 있습니다.\n\n### 웹 서버에서의 멀티플렉싱\n웹 서버는 하나의 포트에서 다수의 클라이언트 요청을 처리해야 합니다. 이를 위해 웹 서버는 다수의 클라이언트의 동시 접속을 각기 다른 세션으로 구분하여 처리할 수 있습니다.\n\n"},{slug:"computer-networks/tcp",categorySlug:"computer-networks",title:{ko:"TCP 프로토콜",en:"TCP Protocol"},date:"2025-02-23",category:{ko:"컴퓨터 네트워크",en:"Computer Networks"},description:{ko:"TCP 프로토콜에 대해 자세히 알아봅시다",en:"Deep dive into TCP Protocol"},content:"\n\n## 3-Way Handshake\nTCP는 신뢰성을 보장하는 연결 지향형 프로토콜로, 데이터를 전송하기 전에 **반드시 연결을 설정**하는 과정을 거쳐야 합니다.\n\n이때 사용하는 방식이 **3-way handshake** 입니다. \n이 과정에서는 클라이언트와 서버가 서로 통신이 가능한 상태인지 확인하고, 데이터 전송을 위한 준비를 완료합니다.\n\n1. 먼저 클라이언트는 서버에 **연결 요청(SYN 패킷)** 을 보냅니다. \n이때 **SYN 플래그를 1**로 설정하고, **초기 순서 번호(ISN, Initial Sequence Number)** 를 포함하여 서버로 전송합니다.\n\n2. 서버는 이 요청을 수락한 후, **SYN-ACK 패킷**을 응답합니다.\n이 패킷에는 클라이언트의 **ISN에 1을 더한 값**과 **서버의 ISN**이 포함됩니다.\n\n3. 마지막으로, 클라이언트는 서버의 응답을 확인한 후 **ACK 패킷**을 다시 서버로 전송합니다.\n\n이렇게 TCP 3-way handshake가 완료되면, 클라이언트와 서버는 신뢰할 수 있는 데이터 전송을 시작할 준비가 완료됩니다.\n\n### 4-Way Handshake\nTCP 연결이 설정되었다면 **연결 종료 시에도 신뢰성을 보장**하기 위해 4단계 과정을 거치게 됩니다. 이를 **4-way Handshake**라고 합니다.\n\n1. 먼저, 클라이언트가 더 보낼 데이터가 없을 경우 **FIN 패킷**을 서버로 전송합니다.\n\n2. 서버는 이 요청을 수락한 후, **ACK 패킷**으로 응답합니다.\n이 단계에서 서버는 클라이언트의 연결 종료 요청을 수락했지만 아직 데이터를 보낼 수 있는 상태입니다.\n\n3. 서버도 더 이상 보낼 데이터가 없을 경우, **FIN 패킷**을 클라이언트로 전송합니다.\n\n4. 클라이언트는 서버의 FIN 패킷을 수신한 후, **ACK 패킷**을 서버로 전송하며 연결 종료를 완료합니다.\n이 과정에서 TCP는 신뢰성을 보장하기 위해 **일정 시간 동안 대기**한 후 최종적으로 연결을 종료합니다.\n\n## TCP의 신뢰성 보장\n**네트워크 계층은 기본적으로 신뢰성이 보장되지 않기** 때문에 패킷이 손실되거나 순서가 뒤바뀌어 도착할 가능성이 있습니다.\n이러한 문제는 일부 패킷이 유실되면 파일이 손실될 수 있기 때문에 파일 다운로드와 같은 애플리케이션에서 심각한 영향을 줄 수 있습니다.\n\n이 문제를 해결하는 방법 중 하나는 UDP처럼 애플리케이션 개발자가 직접 네트워크 손실을 감지하고 복구하도록 하는 것입니다.\n하지만 신뢰성이 중요한 서비스에서는 TCP를 사용하는 것이 훨씬 더 효율적입니다. \nTCP는 **데이터가 손실되지 않고, 순서대로 도착하고, 오류 없이 전달**되는 것을 보장합니다.\n\nTCP에서 신뢰성을 보장하려면 송신 측에서 수신 측이 어떤 데이터를 정상적으로 받았는지, 어떤 데이터가 손실되었는지를 알아야 합니다.\n이를 위해 **ACK**을 사용합니다.\n\n수신 측은 받은 데이터를 확인하는 메시지를 송신 측에 보내고, 만약 송신 측이 일정 시간 내에 ACK을 받지 못하면 해당 패킷이 손실된 것으로 간주하고 재전송합니다.\n이를 **자동 재전송 요청 (ARQ, Automatic Repeat reQuest)** 이라고 합니다.\n\n### 신뢰성 보장 기법\n1. **Stop-and-Wait ARQ (정지 대기 ARQ)**: 가장 단순한 방식으로, **송신 측이 하나의 패킷을 보낸 후 수신 측의 ACK을 기다렸다가 다시 다음 패킷을 보내는 방식**입니다.\n하지만 이 방법은 대기 시간이 길어질 경우 전송 속도가 매우 느려진다는 단점이 있습니다.\n2. **Sliding window** 방식: stop-and-wait의 단점을 개선하기 위해 **한 번에 여러 개의 패킷을 전송**할 수 있도록 한 방법입니다.\n송신 측이 미리 **정해진 윈도우 크기(Window size) 만큼의 패킷**을 연속으로 보내고, 수신 측으로부터 ACK을 받으면 추가적인 패킷을 전송할 수 있습니다.\n\n### 데이터 손실 복구 방식\n1. **Go-Back-N** 방식: 수신 측이 **받은 패킷의 순서가 맞지 않으면 그 이후의 모든 패킷을 폐기**하고, 송신 측은 **폐기된 패킷 이후의 모든 데이터를 다시 전송**하는 방식입니다.\n이 방식은 간단하지만 하나의 패킷이 손실될 경우 많은 데이터를 다시 전송해야 하는 비효율적인 점이 있습니다.\n2. **Selective Acknowledgement (SACK, 선택적 확인 응답)**: Go-Back-N의 단점을 개선한 방식으로, 수신 측이 받은 패킷에 대한 정보를 개별적으로 송신 측에 알리고, 송신 측은 **손실된 패킷만 다시 보내는 방법**입니다.\n\n### 패킷 손실 감지 방법\n1. **Timeout 기반 재전송**: 일정 시간동안 ACK이 도착하지 않으면 해당 패킷이 손실된 것으로 판단하고 다시 전송합니다.\n2. **빠른 재전송 (Fast Retransmit)**: TCP는 **중복된 ACK**을 활용하여 패킷 손실을 보다 빠르게 감지합니다.\n동일한 데이터에 대해 **3번 이상의 중복된 ACK을 수신**하면 해당 패킷이 손실되었다고 판단하고 즉시 재전송합니다.\n예를 들어 패킷 7이 손실되었을 때, 수신 측은 계속해서 패킷 7에 대한 ACK을 보냅니다. \n송신 측이 같은 ACK을 3번 받으면 바로 패킷 7을 다시 전송하는 방식입니다.\n\n## 전송 속도 제어 메커니즘\n네트워크에서 데이터를 전송할 때 전송 속도를 적절히 조절하는 것이 매우 중요합니다.\n\n예를 들어 사용자가 1GB 파일을 원격 호스트로 전송하려고 할 때, **전송 속도를 얼마로 설정**해야 할까요?\n\n이상적으로는 100Mbps 네트워크를 사용한다면 100Mbps로 전송하는 것이 최적일 것처럼 보이지만, 현실적으로는 그렇지 않습니다.\n\n첫 번째 문제는 **송신자가 링크의 정확한 용량을 알지 못한다**는 점입니다. 네트워크 환경은 항상 변동되며, 현재 사용 가능한 대역폭이 얼마인지 미리 알 수 없습니다.\n\n두 번째로, 네트워크에는 여러 사용자가 존재하며 **같은 링크를 여러 명이 공유할 경우 공정한 분배가 필요**합니다.\n만약 한 사용자가 과도한 속도로 데이터를 전송한다면 다른 사용자의 네트워크 품질이 저하될 수 있습니다.\n또한, 수신자가 여러 개의 파일을 동시에 받고 있다면 송신자는 이를 고려해야 합니다.\n\n그럼 전송 속도를 조절하는 기능을 **네트워크 스택의 어느 계층에서** 구현해야 할까요?\n\n한 가지 방법은 애플리케이션 개발자가 **직접 속도 제어 메커니즘을 구현**하는 것입니다. \nUDP가 이러한 방식을 사용하며 데이터 전송 속도를 애플리케이션이 직접 관리하도록 합니다.\n하지만 대부분의 애플리케이션에서 전송 속도 제어는 필수적인 기능이므로 이를 **전송 계층에서 제공**하는 것이 훨씬 효율적입니다.\n\n### 흐름 제어 메커니즘 (Flow Control)\nTCP에서 전송 속도를 제어하는 첫 번째 이유는 **수신 버퍼가 넘치는 것을 방지하기 위해서**입니다.\nTCP는 **수신 측에서 데이터를 버퍼에 저장한 후 애플리케이션이 이를 읽어가도록** 합니다.\n하지만 수신 측이 여러 프로세스를 동시에 처리하고 있거나 데이터를 즉시 읽지 못하는 경우 버퍼에 데이터가 쌓일 수 있습니다.\n\n이러한 문제를 해결하지 위해 TCP는 **송신 속도를 수신 속도에 맞추는** Flow control 메커니즘을 제공합니다.\n\n이 메커니즘의 핵심은 송신자가 현재 수신자가 처리할 수 있는 데이터 양을 파악하는 것입니다.\n이를 위해 TCP는 **수신 윈도우(receive window, `rwnd`)** 라는 변수를 유지하며 이는 수신자가 처리할 수 있는 여유 공간을 나타냅니다.\n\n#### 동작 방식\nTCP 연결을 통해 두 호스트 A와 B가 통신하는 상황을 가정해 보겠습니다.\nA가 B로 파일을 전송하려고 할 때 B는 이 연결을 위해 **수신 버퍼(`RcvBuffer`)** 를 할당합니다.\n\n수신 측에서는 다음 두 개의 변수를 유지합니다:\n- **`LastByteRead`**: 애플리케이션이 버퍼에서 읽은 마지막 바이트의 번호\n- **`LastByteRcvd`**: 네트워크에서 수신하여 버퍼에 저장된 마지막 바이트의 번호\n\nBuffer overflow를 방지하려면 다음 조건이 항상 유지되어야 합니다.\n\n**`LastByteRcvd - LastByteRead <= RcvBuffer`**\n\n여유 공간을 계산할 때는 `rwnd`를 사용합니다.\n\n**`rwnd = RcvBuffer - (LastByteRcvd - LastByteRead)`**\n\n수신자는 매번 송신자에게 ACK을 보낼 때 `rwnd`값을 포함하여 현재 수신할 수 있는 공간을 알립니다.\n송신자는 다음 두 변수를 유지하며 수신자의 여유 공간을 고려합니다:\n\n- **`LastByteSent`**: 송신자가 전송한 마지막 바이트의 번호\n- **`LastByteAcked`**: 송신자가 전송한 데이터 중 수신자로부터 ACK을 받은 마지막 바이트의 번호\n\n송신자는 unacked data sent를 계산하여 `rwnd`를 초과하지 않도록 보장해야 합니다.\n\n**`LastByteSent - LastByteAcked <= rwnd`**\n\n#### Flow control에서 발생할 수 있는 문제와 해결책\n위와 같은 방식에서는 한 가지 문제가 발생할 수 있습니다.\n\n예를 들어, 수신자가 송신자에게 `rwnd = 0`이라고 알리면 송신자는 데이터 전송을 중단합니다. \n그리고 수신측에서는 애플리케이션이 데이터를 읽어가면서 버퍼에 남는 공간이 생길 수도 있습니다. 하지만 **송신자는 이를 알 방법이 없기 때문에 새로운 데이터를 전송하지 못하는 문제**가 발생합니다.\n\n이 문제를 해결하기 위해 TCP는 `rwnd = 0` 상태에서도 송신자가 **1 byte 크기의 세그먼트를 주기적으로 전송**하도록 합니다.\n\n이를 통해 송신자는 수신자로부터 **ACK을 받을 때마다 최신 `rwnd`값을 확인**할 수 있으며, 수신 버퍼에 여유 공간이 생기면 즉시 데이터를 전송할 수 있습니다.\n\n### 혼잡 제어 메커니즘 (Congestion Control)\n전송 속도를 제어해야 하는 또 다른 중요한 이유는 네트워크에서 **혼잡(congestion)** 을 방지하기 위해서입니다.\n네트워크가 혼잡해지면 패킷 손실이 증가하고 지연 시간이 길어지는 문제가 생길 수 있습니다.\n\n네트워크는 동적인 환경이므로 **사용자들이 네트워크에 접속하고 연결을 종료하는 일이 지속적으로 발생**합니다. 따라서 네트워크의 혼잡 상태도 끊임없이 변하게 됩니다.\n\n이러한 변동성 때문에 혼잡 제어 메커니즘은 단순히 정적인 속도 제한을 설정하는 것이 아니라 **네트워크의 상태를 지속적으로 감지하고 이에 따라 전송 속도를 조정**할 수 있어야 합니다.\n\n#### Congestion Control 특징\n1. **효율성**: 네트워크 자원을 최대한 활용하면서 불필요한 혼잡을 방지하는 균형점을 찾아야합니다.\n2. **공정성**: 네트워크를 사용하는 모든 사용자들이 **동일한 병목 링크(Bottleneck link)** 를 공유할 때, 각 사용자가 공정한 대역폭을 가져야합니다.\n(네트워크 정책에 따라 달라지지만) 일반적으로 같은 조건의 Flow들은 **동일한 네트워크 자원을 균등하게 할당**받아야 합니다.\n3. **낮은 지연**: 지연을 최소화 하면서 높은 성능을 유지하는 방법으로 설계되어야 합니다.\n4. **빠른 수렴**: 네트워크에서 flow가 공정한 대역폭을 배분받기까지 걸리는 시간이 짧아야 합니다.\n\n#### 구현 방법\n1. **네트워크 기반(Network-assisted) congestion control**\n\n    이 방식에서는 네트워크 자체가 혼잡 상태를 감지하고 송신자에게 **Explicit feedback**을 제공하여 혼잡을 해결하도록 돕습니다.\n    \n    예를 들어 라우터가 **ICMP 소스 퀀치** 메시지를 보내 송신자에게 혼잡이 발생했음을 알릴 수 있습니다. 송신자는 이를 받아들이고 전송 속도를 줄일 수 있습니다.\n    \n    하지만 이 방법에는 몇 가지 한계가 있습니다. 네트워크가 심각하게 혼잡해지면 **ICMP 패킷조차 손실될 가능성**이 있어 피드백이 효과적으로 전달되지 않을 수 있습니다.\n    또한, 네트워크 장비가 혼잡 제어를 지원하려면 추가적인 프로토콜과 기능이 필요하므로 **구현이 복잡해지고 비용이 증가**할 수 있습니다.\n    \n2. **종단 간(End-to-End) congestion control**\n\n    이 방식에서는 네트워크가 혼잡 상태를 직접 알리지 않고 **송신자가 네트워크의 상태를 스스로 추론**하여 전송 속도를 조절합니다.\n    즉, 네트워크에서 발생하는 패킷 손실, 지연 증가 등을 기반으로 **송신자가 혼잡을 감지하고 대응**하는 방식입니다.\n    \n    TCP는 바로 이 **e2e congestion control**을 사용합니다. 이건 종단 간 원칙과도 잘 맞아떨어지는 개념인데, 네트워크 계층에서는 패킷 전달을 담당하고 혼잡 제어는 전송 계층에서 처리하는 것이 이상적이라는 설계 철학이 반영된 것입니다.\n    \n    그러나 현대 네트워크에서는 일부 라우터가 **Explicit Congestion Notification (ECN)** 이나 **Quantized Congestion Notification (QCN)** 과 같은 프로토콜을 사용하여 송신자에게 혼잡 상태를 알릴 수 있습니다.\n    이렇게 종단 간 방식을 고수하기 보다는 네트워크의 피드백을 활용하는 하이브리드 방식도 점점 활용되고 있습니다.\n\n#### TCP의 혼잡 감지 방법\nTCP는 혼잡을 감지하기 위해 **두 가지 주요 신호**를 사용합니다.\n\n1. **패킷 지연 (Packet delay)**\n\n    네트워크가 혼잡해지면 라우터의 버퍼에 패킷이 대기하면서 **큐가 쌓이고 전송 지연이 증가**하게 됩니다.\n    이로 인해 왕복 시간(RTT, Rount Trip Time)이 증가하는데 송신자는 ACK 패킷을 기반으로 RTT를 측정하여 혼잡을 감지할 수 있습니다.\n    \n    하지만 delay-based congestion inference는 구현이 쉽지 않습니다.\n    네트워크의 지연 시간은 혼잡 외에도 다양한 요인에 의해 변동될 수 있기 때문입니다. 따라서 **TCP는 기본적으로 패킷 지연을 직접적인 혼잡 신호로 사용하지 않습니다.**\n    \n2. **패킷 손실 (Packet loss)**\n\n    네트워크가 심하게 혼잡해지면 라우터의 버퍼가 가득 차서 패킷을 드롭하게 됩니다. \n    패킷 손실의 원인엔 여러 가지가 있지만 (TTL 만료, 네트워크 혼잡, 하드웨어 오류 등등) 대부분의 손실은 네트워크 혼잡으로 인해 발생합니다.\n    \n초기 TCP 구현에서는 **패킷 손실이 감지되면 이를 혼잡의 신호로 해석하고 전송 속도를 줄이는 방식**을 사용했습니다.\n\n#### 동작 방식\nTCP는 혼잡 제어를 위해 `cwnd` 개념을 사용합니다.\n이는 **송신자가 한 번에 보낼 수 있는 데이터의 최대 크기**를 의미합니다.\n\n`cwnd`는 `rwnd`와 유사하지만, 수신 측이 아닌 **네트워크의 혼잡 상태를 기반으로 조절**된다는 차이가 있습니다.\n\nTCP는 **probe-and-adapt** 방식을 통해 `cwnd` 크기를 조절합니다.\n네트워크가 안정적인 경우, `cwnd`를 점진적으로 증가시켜 더 많은 데이터를 전송하도록 시도합니다.\n패킷 손실이 감지되면 혼잡이 발생한 것으로 판단하고 창 크기를 줄여 혼잡을 완화합니다.\n\n송신자는 **네트워크의 상태(`cwnd`) 또는 수신자의 처리 능력(`rwnd`) 중 더 작은 값**에 맞춰 전송 속도를 조절해야합니다.\n\n#### AIMD\nTCP가 혼잡에 따라 송신 윈도우 크기를 조절하는 방식은 **AIMD (Additive Increase / Multiplicative Decrease)** 라고 불립니다.\n\n1. **Additive Increase(가산 증가)** 방식\n\n    TCP 연결은 초기 송신 윈도우 크기를 일정하게 설정한 후, 점진적으로 증가시킵니다.\n    일반적으로 초기 윈도우 크기는 2로 설정되며 매 RTT(Rount Trip Time)마다 선형적으로 증가하는 방식입니다.\n    \n    즉, **송신자가 `cwnd` 개수만큼의 패킷을 성공적으로 전송하면 `cwnd`의 크기가 증가**합니다. \n    \n    또한 TCP는 모든 패킷의 ACK을 기다린 후 증가시키는 것이 아니라, **개별적인 ACK을 수신할 때마다 즉시 증가**시키는 방식을 사용합니다.\n\n    증가량은 MSS(Maximum Segment Size)에 기반하며 아래의 수식을 따릅니다.\n    \n    **`Increment = MSS * (MSS/cwnd)`**\n    \n2. **Multiplicative Decrease(배수 감소)** 방식\n    \n    TCP는 패킷 손실이 발생하면 `cwnd` 값을 **기존 값의 절반**으로 줄입니다. `cwnd` 값은 **최소 1**까지 줄어들 수 있고 그 이하로는 내려가지 않습니다.\n    \n이러한 과정이 반복되면서 `cwnd`는 지속적으로 증가했다가 감소하는 패턴을 보이는데, 이를 **톱니형 패턴**이라고 합니다.\n\nTCP의 여러 구현 방식 중에서 TCP Reno는 두 가지 종류의 패킷 손실을 기반으로 혼잡을 감지합니다. \n1. **세 번의 중복 ACK을 수신하는 경우**: 네트워크가 경미한 혼잡 상태에 있다는 신호이며, `cwnd` 값을 절반으로 줄입니다.\n2. **특정 시간 동안 ACK을 받지 못하는 타임아웃 이벤트**: 타임아웃은 심각한 혼잡 상태로 간주되며, `cwnd` 값을 초기 윈도우 상태로 재설정합니다.\n\n#### Slow Start\nSlow start는 송신 호스트가 네트워크의 용량을 모를 때, 즉 **새로운 연결이 시작될 때 적용**됩니다. \n초기에는 송신 윈도우 크기를 1로 설정하고, **각 ACK을 받을 때마다 윈도우 크기를 두 배씩 증가**시킵니다.\n\n즉, 처음 1개의 패킷을 보내고, 다음에는 2개, 그 다음에는 4개, 8개 식으로 증가합니다. \n\n이를 통해 네트워크가 허용하는 최적의 전송 속도를 신속하게 찾을 수 있습니다.\n\n하지만 Slow start가 계속되면 송신 윈도우가 과도하게 증가하여 네트워크 혼잡이 발생할 수 있습니다.\n이를 방지하기 위해 **congestion threshold를 넘어서면 AIMD 방식으로 전환**됩니다. \n\n#### TCP 공정성이 보장되지 않는 경우\n1. **RTT의 차이**\n\n    TCP Reno는 ACK을 기반으로 `cwnd` 크기를 조정하는데, **RTT가 짧은 연결일수록 ACK을 빨리** 받을 수 있어 `cwnd`를 더 빨리 증가시킬 수 있습니다.\n    \n    반면, RTT가 긴 연결은 같은 속도로 증가하지 못하고 상대적으로 낮은 전송 속도를 유지해야 합니다.\n        \n2. **여러 개의 병렬 TCP 연결을 사용하는 경우**\n\n    다수의 연결을 가진 애플리케이션이 불공정하게 더 많은 네트워크 자원을 가져갈 수 있습니다.\n\n위와 같은 문제로 인해 일부 네트워크 환경에서는 다양한 조정 기법이 도입되기도 합니다.\n\n예를 들어 TCP의 경쟁적인 특성을 완화하고자 **RTT를 고려한 대역폭 할당 방식**을 적용하거나, **다중 연결 사용을 제한하는 정책을 활용**하는 방법이 있습니다.\n\n#### TCP Cubic\n기존의 TCP Reno는 네트워크 대역폭이 높거나 지연 시간이 큰 경우 네트워크 활용도가 낮다는 문제가 있었습니다.\n이를 해결하기 위해 TCP의 여러 개선 버전이 등장했고, 그 중 하나가 TCP CUBIC 입니다. \n\nTCP CUBIC은 **CUBIC 다항식 항수를 사용하여 `cwnd` 크기를 조절**합니다.\n\n**핵심 아이디어**\n\nTCP가 세 개의 중복 ACK을 받았을 때, `cwnd` 크기를 절반으로 감소시킵니다. \n\n윈도우 크기가 `W_max`일 때 패킷 손실이 발생하여 혼잡이 감지되었다고 가정하면, 다시 윈도우 크기를 증가시킬 때 **처음에는 빠르게 증가시키지만 `W_max`에 가까워질수록 증가 속도를 점진적으로 줄이는 방식**을 사용합니다.\n\n만약 `W_max`에 도달했는데도 패킷 손실이 발생하지 않는다면 이전 손실이 transient congestion이나 기타 원인으로 발생한 것일 수 있습니다.\n\n이 경우, **이후에는 윈도우 크기를 더 적극적으로 증가**시키는 방식으로 아래와 같이 동작합니다:\n\n        W(t) = C(t-K)^3 + W_max\n\n        W_max: 마지막 패킷 손실이 발생했을 때 윈도우 크기\n        C: 스케일링 상수 (네트워크 환경에 따라 조정)\n        K: cwnd가 W_max로 도달하는데 걸리는 시간\n\n특히 TCP CUBIC의 중요한 특징은 **시간을 기준으로 윈도우 크기를 조절**한다는 점입니다.\n이를 통해 TCP CUBIC은 RTT가 다른 연결 간에도 보다 공정하게 네트워크 자원을 공유하는 **RTT-fair** 한 특성을 가질 수 있습니다.\n"},{slug:"cs/event-broker-vs-message-broker",categorySlug:"cs",title:{ko:"이벤트 브로커와 메시지 브로커",en:"Event Broker and Message Broker"},date:"2025-02-24",category:{ko:"컴퓨터 공학",en:"Computer Science"},description:{ko:"이벤트 브로커와 메시지 브로커의 차이, RabbitMQ와 Kafka의 동작 원리",en:"Difference between event broker and message broker, how RabbitMQ and Kafka work"},content:'\n오늘은 이벤트 브로커와 메시지 브로커, 그리고 각각의 대표적인 예시인 Apache Kafka와 RabbitMQ에 대해 알아보겠습니다.\n\n## 이벤트 브로커 (Event Broker)\n이벤트 브로커는 **시스템 내에서 일어나는 다양한 사건이나 상태 변화를 다른 컴포넌트에 전달**하는 중개자 역할을 합니다.\n\n예를 들어, 온라인 쇼핑몰에서는 사용자가 상품을 장바구니에 담거나 결제하는 등의 행동이 이벤트로 발생할 수 있습니다.\n이러한 이벤트들은 직접적으로 다른 컴포넌트에 전달되는 것이 아니라 이벤트 브로커를 통해 전달되어 **여러 시스템이나 서비스가 동시에 반응**할 수 있도록 할 수 있습니다.\n\n시스템의 각 부분은 이벤트 브로커를 통해 **서로 분리되어 동작**하게 되는데, 이를 통해 한 부분에서 발생한 변화가 다른 부분에 영향을 주더라도 서로 강하게 의존하지 않게 됩니다.\n\n만일 결제 시스템에 문제가 생겨도 주문 처리나 재고 관리 시스템은 이미 발생한 이벤트를 기반으로 자신의 업무를 계속 진행할 수 있습니다.\n\n이런 구조 덕분에 장애가 발생했을 때 **문제를 국소적으로 격리**할 수 있고 **시스템 전체의 안정성을 높일 수 있는 효과**가 있습니다. (Loose coupling)\n\n또한, 이벤트 브로커는 발생한 이벤트 데이터를 기록하고 저장하는 기능도 제공합니다. \n예를 들어 사용자가 웹사이트에서 발생시킨 모든 행동 기록을 이벤트 브로커가 수집해 저장해 놓으면 나중에 이 데이터를 분석해 **사용자 행동 패턴을 파악**하거나 **문제 발생 시 재처리할 수 있는 기반**을 마련할 수 있습니다.\n\n이러한 기능은 **실시간 모니터링**이나 **로그 수집**, **감사**와 같은 다양한 활용 사례에 유용하게 쓰입니다.\n\n### Pub/Sub 모델\n이벤트 브로커는 pub/sub 모델을 채택하고 있는데, 이 모델에서 이벤트를 생성하는 쪽은 **publisher**, 이벤트를 받아 처리하는 쪽은 **consumer**라고 부릅니다.\n\nPublisher는 자신이 **생성한 이벤트를 이벤트 브로커에 전달**하고, 이벤트 브로커는 이 **이벤트를 구독하고 있는 여러 consumer들에게 동시에 전달**합니다.\n\n예를 들어, 온라인 쇼핑몰에서 상품이 구매되면 결제 시스템, 주문 관리 시스템, 재고 관리 시스템, 심지어는 고객에게 알림을 보내는 시스템 등이 모두 이 이벤트를 받아 각각의 역할을 수행할 수 있습니다.\n\n다른 예시를 생각해보면 이벤트 브로커는 마치 **도서관의 사서**와 같다고 볼 수 있습니다.\n\n도서관에서 책을 요청하면 사서가 책을 찾아 여러 독자에게 전달해 주는 것처럼, 이벤트 브로커도 각 시스템의 요청이나 상태 변화를 받아 필요한 모든 곳에 전달합니다.\n이 과정에서 각 시스템은 직접 서로를 호출할 필요 없이 **간접적으로 소통**할 수 있게 됩니다.\n\n### Apache Kafka\nKafka는 이벤트 브로커의 대표적인 예시로 주로 **대용량의 실시간 데이터 스트림**을 처리하는 데 최적화되어 있습니다.\n\nKafka에서는 **모든 이벤트가 로그 형태로 기록**되며, 이 로그는 분산 시스템 내 여러 노드에 걸쳐 저장됩니다.\n\n예를 들어 대규모 웹 애플리케이션에서 사용자 행동 데이터나 서버 로그 같은 이벤트가 발생하면\n이 데이터를 Kafka에 기록해 여러 consumer가 동시에 실시간 분석, 모니터링, 경고 등의 작업을 수행할 수 있습니다.\n\nEvent broker의 특성처럼 Kafka의 pub/sub 모델은 publisher가 데이터를 보내면 여러 소비자가 그 로그를 구독하여 각자의 필요에 따라 데이터를 처리할 수 있습니다.\n이 과정에서 이벤트가 지속적으로 기록되기 때문에 **나중에 필요할 때 과거의 데이터를 재분석하거나 시스템 에러 발생 시 재처리**를 쉽게 할 수 있습니다.\n\n#### 동작 원리\nKafka의 기본 단위는 **토픽**입니다. \n토픽은 메시지들의 카테고리를 의미하고, 각 토픽은 하나 이상의 **파티션**으로 나뉩니다.\n파티션은 실제 메시지들이 저장되는 단위로, 각 파티션 내에서는 메시지가 **순차적으로 저장**되고, 각 메시지는 고유한 **offset** 값을 갖게 됩니다.\n\n이러한 구조 덕분에 Kafka는 **메시지의 순서를 보장**할 수 있고 파티션을 여러 서버에 **분산 저장**함으로써 확장성과 병렬 처리를 지원합니다.\n\nKafka 클러스터는 여러 **브로커**로 구성되어 있고, 각 브로커는 하나 이상의 파티션을 관리합니다.\n\n데이터 안정성과 내결함성을 확보하기 위해 Kafka는 **파티션의 복제본을 여러 브로커에 분산 저장**합니다.\n이 방식으로 하나의 브로커에 장애가 발생하더라도 다른 복제본에서 데이터를 제공할 수 있습니다.\n\n데이터를 기록하는 역할은 **producer**가 담당하는데, producer는 특정 토픽에 메시지를 전송하며 **전송 시 메시지를 어느 파티션에 저장할지를 결정**할 수 있습니다.\n\n이때 파티션 선택은 **라운드 로빈 방식**이나 **특정 키 값을 기반**으로 할 수 있는데, 키를 기반으로 할 경우 동일한 키를 가진 메시지들은 항상 같은 파티션에 저장되어 순서가 보장됩니다.\n\nKafka에서 데이터를 소비하는 역할은 **consumer**가 맡습니다. \nconsumer는 **특정 토픽의 파티션에서 메시지를 읽어들이고** 각 consumer는 **읽은 메시지의 offset을 관리**합니다.\n\nKafka는 **consumer group** 이라는 개념을 통해 다수의 consumer가 같은 그룹으로 묶여 토픽의 각 파티션을 분산 처리할 수 있도록 지원합니다.\n동일한 consumer group 내에서는 **하나의 파티션이 하나의 consumer에게만 할당**되어 메시지가 중복 처리되지 않도록 보장합니다.\n\n#### 특징\nKafka의 중요한 특징은 **retention**과 **reprocessing** 입니다.\n\nKafka는 기본적으로 일정 기간 동안 혹은 특정 용량에 도달할 때까지 메시지를 보관합니다.\n이 덕분에 소비자가 메시지를 읽은 후에도 필요에 따라 과거 데이터를 다시 읽어들일 수 있어, 실시간 분석 뿐만 아니라 이벤트 소싱이나 로그 분석 같은 다양한 용도로 활용될 수 있습니다.\n\n\n## 메시지 브로커 (Message Broker)\n메시지 브로커의 주요 목적은 **메시지를 안정적으로 전송하고 각 시스템이 독립적으로 작동**할 수 있도록 하는 것입니다.\n\n메시지 브로커는 메시지를 **Queue나 Topic과 같은 구조에 저장**하고, consumer가 준비되면 해당 메시지를 전달하여 순차적 또는 병렬적으로 처리할 수 있게 합니다.\n\n예를 들어, 사용자가 주문을 완료하면 메시지 브로커는 이 주문 데이터를 결제 처리 시스템에 전달하고, 결제가 완료된 후 다시 주문 처리 시스템에 결과를 전달하는 과정을 중개합니다.\n\n이벤트 브로커가 도서관의 사서와 같았다면 메시지 브로커는 **우편 배달 시스템**과 비슷하다고 볼 수 있습니다.\n\n편지를 보내는 사람이 직접 수취인에게 전달하는 대신 우체국에 맡기는 것처럼 메시지 브로커는 발신자로부터 메시지를 받아 중간에서 필요한 곳으로 전달합니다.\n\n### RabbitMQ\nRabbitMQ는 전통적인 메시지 브로커의 대표적인 예입니다.\n\nRabbitMQ에서는 **메시지가 큐에 저장되고, consumer가 해당 큐에서 하나씩 메시지를 가져와 처리하는 방식**으로 동작합니다.\n\n예를 들어 전자상거래 시스템에서 주문이 들어오면 주문 처리 요청 메시지가 RabbitMQ 큐에 저장되고, 주문 처리 서비스가 이 큐에서 메시지를 하나씩 꺼내 처리합니다.\n\nRabbitMQ의 **라우팅 기능**을 이용하면 특정 조건이나 주제에 따라 메시지를 다양한 큐로 분배할 수 있어 시스템 간의 통신을 보다 세밀하게 조절할 수 있습니다.\n\n#### 동작 원리\nRabbitMQ의 기본 구성 요소는 크게 **producer, consumer, exchange, queue, binding**으로 구분할 수 있습니다.\n\n**Producer**는 애플리케이션에서 **메시지를 생성하고 RabbitMQ에 전달**하는 역할을 합니다.\n이때 메시지를 직접 queue에 넣는 것이 아니라, 먼저 **exchange로 메시지를 전송**합니다.\n\n**Exchang**e는 들어오는 **메시지를 어떻게 queue로 라우팅할 것인지 결정**하는 중추적인 역할을 합니다.\nExchange엔 여러 종류가 있는데, 대표적으로 **direct, topic, fanout, headers** exchange가 있습니다.\n각 exchange는 routing key나 바인딩 조건에 따라 메시지를 적절한 queue로 분배합니다.\n\n**Queue**는 **실제로 메시지가 저장되는 공간**입니다.\n메시지는 저장된 후, 준비된 consumer에게 전달되어 처리됩니다.\n\nRabbitMQ는 메세지의 신뢰성과 안정성 보장을 위해 큐에 저장된 메시지에 대해 **persistence 옵션을 제공**하며, \nconsumer가 메시지를 받아 처리한 후에는 메시지에 대한 **ACK을 받아야 메시지를 삭제**합니다.\n이 과정은 메시지 유실이나 중복 처리 방지에 중요한 역할을 합니다.\n\n**Binding**은 exchange와 queue 사이의 **연결 규칙을 정의**합니다.\nBinding을 통해 특정 routing key나 패턴에 맞는 메시지가 어떤 queue로 전달될지 결정되므로, 메시지 흐름을 세밀하게 정의할 수 있습니다.\n\n**Consumer**는 큐에 저장된 **메시지를 받아 처리**하는 역할을 합니다.\n여러 consumer가 하나의 큐를 구독할 경우, RabbitMQ는 메시지를 **라운드 로빈 방식** 등으로 분배하여 각 consumer가 메시지를 균등하게 처리할 수 있도록 지원합니다.\n\nConsumer가 메시지를 처리하고 난 후 ACK을 보내야하는데, 만약 메시지 처리에 실패하면 RabbitMQ는 해당 메시지를 **재전달하거나 DLX 또는 다른 큐로 라우팅** 할 수 있습니다.\n\n\n\n\n## 차이점\n이벤트 브로커는 **"어떤 일이 발생했다"는 사실 자체를 전파**하는 데 중점을 둡니다. 예를 들어 온라인 쇼핑몰에서 사용자가 결제를 완료했을 때 그 사건을 기록하고 여러 시스템에 동시에 알리는 역할을 할 수 있습니다.\n\n반면, 메시지 브로커는 **특정 작업이나 요청을 안전하게 전달**하는 데 집중합니다.\n예를 들어, 주문 처리를 위해 결제 요청을 보내거나 작업 큐에 저장된 작업을 하나씩 처리하는 시스템에서 메시지 브로커는 메시지를 큐잉하여 전달하고, 재시도나 배달 보증 등의 기능을 통해 데이터의 신뢰성을 보장합니다.\n\n또한 이벤트 브로커는 이벤트 자체를 **지속적으로 기록하고 저장**하여 나중에 재처리나 분석에 활용할 수 있는 반면, 메시지 브로커는 일반적으로 메시지를 즉시 처리하는 **단기적인 데이터 전달**에 집중합니다.\n\n이처럼 이벤트 브로커는 주로 **시스템의 상태 변화나 사건 발생의 "기록"** 을 다루고, 메시지 브로커는 **특정 작업의 "수행"** 과 관련된 데이터를 다루는 데 초점을 맞춥니다.\n\nKafka와 RabbitMQ 사용 사례를 비교하자면 Kafka는 **높은 처리량, 내구성, 재처리 기능** 등이 중요한 이벤트 스트리밍 환경에, RabbitMQ는 **복잡한 라우팅, 메세지 우선 순위, 큐 기반의 작업 분산 처리**와 같은 요구 사항이 있을 때 효과적인 선택이 됩니다.\n\n\n\n\n\n\n\n'}],r=[{number:1,date:"2025-02-19",name:"Two Sum",tags:["Array","Hash Table"],approach:"Use hash map to store complement values",difficulty:"Easy",url:"https://leetcode.com/problems/two-sum/",solutions:[{id:"brute-force",approach:"Brute Force",code:"def twoSum(self, nums: List[int], target: int) -> List[int]:\n    for i in range(len(nums)):\n        for j in range(i + 1, len(nums)):\n            if nums[i] + nums[j] == target:\n                return [i, j]\n    return []",timeComplexity:"O(n\xb2)",spaceComplexity:"O(1)",explanation:"모든 가능한 쌍을 확인하는 방식으로, 이중 반복문을 사용합니다. 첫 번째 숫자와 두 번째 숫자의 합이 target과 같으면 해당 인덱스들을 반환합니다."},{id:"hash-map",approach:"Hash Map",code:"def twoSum(self, nums: List[int], target: int) -> List[int]:\n    seen = {}\n    for i, num in enumerate(nums):\n        complement = target - num\n        if complement in seen:\n            return [seen[complement], i]\n        seen[num] = i\n    return []",timeComplexity:"O(n)",spaceComplexity:"O(n)",explanation:"해시맵을 사용하여 각 숫자의 보수(target - 현재 숫자)를 저장합니다. 현재 숫자의 보수가 이미 해시맵에 있다면, 현재 인덱스와 해시맵에 저장된 인덱스를 반환합니다."}]},{number:2,date:"2025-02-19",name:"Task Scheduler",tags:["Heap","Queue"],approach:"Use a heap to manage task frequencies and a queue to track tasks in cooldown.",difficulty:"Medium",url:"https://leetcode.com/problems/task-scheduler/description/",solutions:[{id:"heap",approach:"Heap",code:"class Solution:\n    def leastInterval(self, tasks: List[str], n: int) -> int:\n        # 최대 힙을 사용하여 가장 빈도가 높은 작업을 먼저 처리\n        max_heap = []\n        task_counts = Counter(tasks)  # 각 작업의 빈도수 계산 (O(n))\n        \n        for count in task_counts.values():\n            max_heap.append(-count)  # 최대 힙을 만들기 위해 음수 값을 저장\n        \n        heapq.heapify(max_heap)  # O(n) 복잡도로 힙 변환\n        \n        time_elapsed = 0\n        cooldown_queue = deque()  # (남은 실행 횟수, 작업이 다시 실행 가능해지는 시간) 튜플 저장\n        \n        while max_heap or cooldown_queue:\n            time_elapsed += 1\n            \n            if max_heap:\n                remaining_executions = heapq.heappop(max_heap) + 1  # 작업 실행 (-1 증가)\n                \n                if remaining_executions < 0:  # 아직 실행해야 할 작업이 남아 있으면 큐에 추가\n                    cooldown_queue.append((remaining_executions, time_elapsed + n))\n            \n            # 가장 먼저 추가된 작업이 다시 실행 가능하면 max_heap으로 복귀\n            if cooldown_queue and cooldown_queue[0][1] == time_elapsed:\n                heapq.heappush(max_heap, cooldown_queue.popleft()[0])\n        \n        return time_elapsed\n",timeComplexity:"O(n): O(n log(26)) -> O(n), 각 작업은 최대 한 번만 heappop(), heappush() 실행 가능",spaceComplexity:"O(1): O(26) -> O(1)",explanation:"최대 힙을 사용하여 가장 빈도가 높은 작업을 먼저 실행합니다. 실행된 작업은 쿨다운 큐에 넣어 일정 시간이 지나야 다시 실행할 수 있도록 합니다. 쿨다운이 끝난 작업은 다시 힙에 추가하여 최소 시간으로 모든 작업을 처리합니다."}]},{number:3,date:"2025-02-19",name:"Design Twitter",tags:["Heap"],approach:"Use a min heap to get the 10 most recent tweets, adding previous tweets if available.",difficulty:"Medium",url:"https://leetcode.com/problems/design-twitter/",solutions:[{id:"heap",approach:"Heap",code:'class Twitter:\n    def __init__(self):\n        self.tweets = defaultdict(list)  # 사용자 ID별 트윗 리스트 저장\n        self.follows = defaultdict(set)  # 사용자 ID별 팔로우하는 사용자 목록 저장\n        self.counter = 0  # 트윗 정렬을 위한 시간 카운터 (최근 트윗이 가장 작은 값)\n\n    def postTweet(self, userId: int, tweetId: int) -> None:\n        """사용자가 새로운 트윗을 게시한다."""\n        self.counter -= 1  # 최신 트윗이 가장 먼저 나오도록 음수값 사용\n        self.tweets[userId].append((self.counter, tweetId))  # 트윗 저장\n\n    def getNewsFeed(self, userId: int) -> List[int]:\n        """사용자와 팔로우한 사람들의 최신 10개 트윗을 반환한다."""\n        followees = self.follows[userId]  # 사용자가 팔로우한 사람들 가져오기\n        followees.add(userId)  # 자신의 트윗도 포함\n\n        heap = []  # 최소 힙을 사용하여 최신 트윗 10개 유지\n\n        # 각 팔로우한 사용자의 가장 최신 트윗을 힙에 추가\n        for followee in followees:\n            if followee in self.tweets:\n                idx = len(self.tweets[followee]) - 1  # 최신 트윗의 인덱스\n                count, tweet_id = self.tweets[followee][idx]\n                heapq.heappush(heap, (count, tweet_id, followee, idx - 1))  # 최신 트윗 삽입\n\n        res = []\n        while heap and len(res) < 10:  # 최대 10개의 트윗을 가져옴\n            count, tweet_id, followee, idx = heapq.heappop(heap)  # 가장 최신 트윗 꺼내기\n            res.append(tweet_id)\n\n            if idx >= 0:  # 해당 사용자의 이전 트윗이 존재하면 힙에 추가\n                count, tweet_id = self.tweets[followee][idx]\n                heapq.heappush(heap, (count, tweet_id, followee, idx - 1))\n\n        return res\n\n    def follow(self, followerId: int, followeeId: int) -> None:\n        """followerId 사용자가 followeeId 사용자를 팔로우한다."""\n        self.follows[followerId].add(followeeId)\n\n    def unfollow(self, followerId: int, followeeId: int) -> None:\n        """followerId 사용자가 followeeId 사용자를 언팔로우한다."""\n        if followeeId in self.follows[followerId]:\n            self.follows[followerId].remove(followeeId)\n',timeComplexity:"O(n log n) (for getNewsFeed), O(1) (for other methods)",spaceComplexity:"O(N * m + N * M + n): O(N * m)(모든 사용자의 트윗 저장, N: 전체 사용자 수, m: 사용자당 최대 트윗 수), O(N * M)(팔로우 관계 저장, M: 사용자당 최대 팔로우 수), O(n)(getNewsFeed() 실행 시 힙 사용, n: userId에 연결된 총 팔로우 수)",explanation:"최대 힙을 사용하여 가장 최신 트윗을 가져옵니다. 각 사용자의 최신 트윗을 힙에 넣고, 가장 최신 트윗을 가져온 후 해당 사용자의 이전 트윗을 추가하여 최신순으로 유지합니다. 최대 10개의 트윗만 유지하여 뉴스 피드를 반환합니다. 팔로우 관계는 별도의 해시맵에 저장하여 관리합니다."}]},{number:4,date:"2025-02-20",name:"Design Add and Search Word Data Structure",tags:["Trie","DFS"],approach:"Use a Trie to store and search words, and utilize DFS with backtracking to handle wildcard '.' searches.",difficulty:"Medium",url:"https://leetcode.com/problems/design-add-and-search-words-data-structure",solutions:[{id:"trie",approach:"Trie, DFS",code:"class TrieNode:\n    def __init__(self):\n        self.children: = dict()  # 문자 -> TrieNode 매핑\n        self.word = False  # 현재 노드가 단어의 끝인지 여부\n\nclass WordDictionary:\n    def __init__(self):\n        self.root = TrieNode()\n\n    def addWord(self, word: str) -> None:\n        curr = self.root\n        \n        for c in word:\n            if c not in curr.children:  # 해당 문자가 Trie에 없으면 새 노드 추가\n                curr.children[c] = TrieNode()\n            curr = curr.children[c]  # 다음 노드로 이동\n        \n        curr.word = True  # 단어 끝을 표시\n        \n    def search(self, word: str) -> bool:        \n        def dfs(j, root):\n            curr = root\n            for i in range(j, len(word)):\n                c = word[i]\n                \n                if c == \".\":  # '.'은 어떤 문자와도 매칭 가능\n                    for child in cur.children.values():  # 현재 노드의 모든 자식 노드를 탐색\n                        if dfs(i + 1, child):  # 다음 문자를 재귀적으로 탐색\n                            return True\n                            \n                    return False  # 매칭되는 단어가 없음\n                else:\n                    if c not in curr.children:\n                        return False\n                        \n                    curr = curr.children[c]\n                    \n            return cur.word  # 단어 끝 여부 반환\n        \n        return dfs(0, self.root)\n",timeComplexity:"O(n) for addWord(), O(n) for search()",spaceComplexity:"O(t + n), where t is the total number of stored characters in Trie and n is the depth of recursive calls in search()",explanation:"Trie를 사용하여 단어를 추가하고 검색합니다. addWord()는 단어 길이 n에 비례하는 O(n) 시간에 수행됩니다. search() 또한 일반적인 경우 O(n)이지만, '.'이 포함되면 백트래킹이 발생할 수 있습니다. 공간 복잡도는 Trie에 저장된 총 문자 개수 t와 DFS 호출 깊이 n에 의해 결정됩니다."}]},{number:5,date:"2025-02-20",name:"Word Search II",tags:["Trie","DFS","Backtracking"],approach:"Store words in a Trie and use DFS with backtracking to find valid words on the board.",difficulty:"Hard",url:"https://leetcode.com/problems/word-search-ii/",solutions:[{id:"trie",approach:"Trie, DFS",code:'class TrieNode:\n    def __init__():\n        self.children = dict()\n        self.is_word = False\n    \n    def add_word(self, word):\n        curr = self\n        \n        for c in word:\n            if c not in curr.children:\n                curr.children[c] = TrieNode()\n            curr = curr.children[c]\n        \n        curr.is_word = True\n        \ndef findWords(self, board: List[List[str]], words: List[str]) -> List[str]:\n    # Trie를 생성하고 단어들을 추가\n    root = TrieNode()\n    for w in words:\n        root.add_word(w)\n    \n    num_rows, num_cols = len(board), len(board[0])\n    res = set()  # 중복 방지를 위해 set 사용\n    visit = set()  # 방문한 위치 추적\n    \n    def dfs(r, c, node, word):\n        # 보드를 벗어나거나 이미 방문한 위치이거나, 현재 문자가 Trie에 없는 경우 종료\n        if not 0 <= r < num_rows or not 0 <= c < num_cols or (r, c) in visit or board[r][c] not in node.children:\n            return\n        \n        visit.add((r, c))\n        \n        node = node.children[board[r][c]]  # Trie에서 현재 문자에 해당하는 노드로 이동\n        word += board[r][c]  # 단어에 문자 추가\n        \n        if node.is_word:  # Trie에 등록된 단어를 찾으면 결과에 추가\n            res.add(word)\n        \n        # 상, 하, 좌, 우 방향으로 DFS 탐색 수행\n        dfs(r - 1, c, node, word)\n        dfs(r + 1, c, node, word)\n        dfs(r, c - 1, node, word)\n        dfs(r, c + 1, node, word)\n        \n        visit.remove((r, c))  # 백트래킹(이전 상태로 복귀)\n        \n    # 보드의 모든 위치에서 DFS 시작\n    for r in range(num_rows):\n        for c in range(num_cols):\n            dfs(r, c, root, "")\n    \n    return list(res)\n',timeComplexity:"O(m * n * 4 * 3^(t-1) + s), where m is the number of rows, n is the number of columns, t is the maximum length of any word in words, and s is the sum of the lengths of all words.",spaceComplexity:"O(s), where s is the sum of the lengths of all words stored in the Trie.",explanation:"먼저 단어 목록을 Trie에 저장합니다. 그런 다음, board에서 가능한 모든 위치에서 DFS를 수행하여 단어를 찾습니다. DFS 중에는 백트래킹을 사용하여 이미 방문한 위치를 추적하고, 경로를 따라 Trie에 없는 문자가 나오면 탐색을 중단합니다. 검색된 단어는 set에 저장하여 중복을 방지하고, 최종적으로 리스트로 변환하여 반환합니다."}]},{number:6,date:"2025-02-21",name:"Subsets",tags:["DFS","Backtracking"],approach:"Use DFS with backtracking to explore both including and excluding each element.",difficulty:"Medium",url:"https://leetcode.com/problems/subsets",solutions:[{id:"backtracking",approach:"Backtracking, DFS",code:"def subsets(self, nums: List[int]) -> List[List[int]]:\n    res = []  # 모든 부분집합을 저장할 리스트\n    subset = []  # 현재까지 선택된 원소들을 저장할 리스트\n    \n    def dfs(i):\n        # i가 nums의 길이와 같으면, 모든 원소에 대해 선택 여부를 결정한 것이므로 결과에 추가\n        if i == len(nums):\n            res.append(subset[:])  # 현재 subset의 복사본을 추가\n            return\n        \n        # 현재 원소를 부분 집합에 포함시키는 경우\n        subset.append(nums[i])\n        dfs(i + 1)\n        \n        # 백트래킹: 이전 선택을 취소하고 원소를 포함시키지 않는 경우\n        subset.pop()\n        dfs(i + 1)\n    \n    dfs(0)\n    return res\n",timeComplexity:"최악의 경우 모든 원소에 대해 선택 또는 비선택의 두 가지 경우를 고려하므로, 시간 복잡도는 O(2ⁿ)입니다. 또한, 각 부분집합을 복사하는 데 O(n)의 시간이 소요되므로, 전체 시간 복잡도는 O(n * 2ⁿ)입니다.",spaceComplexity:"O(n)",explanation:"각 단계에서 현재 인덱스의 원소를 선택하거나 선택하지 않고 재귀 호출을 진행합니다. 인덱스가 리스트의 길이에 도달하면, 현재까지 구성된 부분집합의 복사본을 결과에 추가합니다. 이 과정에서 백트래킹을 통해 이전 선택을 취소하여 다른 경우의 수도 탐색할 수 있습니다."}]},{number:7,date:"2025-02-21",name:"Combination Sum",tags:["DFS","Backtracking"],approach:"Use DFS with backtracking to build candidate combinations that sum to the target.",difficulty:"Medium",url:"https://leetcode.com/problems/combination-sum/",solutions:[{id:"backtracking",approach:"Backtracking, DFS",code:"def combinationSum(self, candidates: List[int], target: int) -> List[List[int]]:\n    res = []  # 결과로 반환할 조합\n    subset = []  # 현재까지 선택된 숫자 조합\n    \n    def dfs(i, curr_sum):\n        # 현재 합이 target과 같으면, 현재 조합의 복사본을 추가\n        if curr_sum == target:\n            res.append(subset[:])\n            return\n        \n        # 인덱스가 끝에 도달했거나 현재 합이 target을 초과하면 종료        \n        if i == len(candidates) or curr_sum > target:\n            return\n        \n        # 현재 후보 숫자를 조합에 포함시키고 재귀적으로 같은 인덱스에서 탐색 (같은 숫자 재사용이 가능하기 때문)\n        subset.append(candidates[i])\n        dfs(i, curr_sum + candidates[i])\n        \n        # 백트래킹: 마지막에 추가한 숫자를 제거하고 다음 후보로 넘어감\n        subset.pop()\n        dfs(i + 1, curr_sum)\n    \n    dfs(0, 0)\n    return res\n",timeComplexity:"O(2^(t/m)) 최악의 경우 모든 가능한 조합을 탐색해야 함",spaceComplexity:"O(n)",explanation:"DFS와 백트래킹을 활용하여 후보 숫자들의 조합을 탐색하며, 현재 인덱스의 숫자를 포함시켜 합계를 갱신하고 재귀적으로 탐색을 진행합니다. 만약 현재 합이 목표값(target)과 같다면 해당 조합을 결과 리스트에 추가하며, 인덱스가 배열의 끝에 도달하거나 합이 목표를 초과하면 탐색을 중단합니다. 포함한 후에는 백트래킹을 통해 마지막으로 추가한 숫자를 제거하고 다음 후보로 넘어가며 모든 가능한 조합을 탐색합니다."}]},{number:8,date:"2025-02-21",name:"Combination Sum II",tags:["DFS","Backtracking"],approach:"Use DFS with backtracking and skip duplicates with a while loop.",difficulty:"Medium",url:"https://leetcode.com/problems/combination-sum-ii/",solutions:[{id:"backtracking",approach:"Backtracking, DFS",code:"def combinationSum2(self, candidates: List[int], target: int) -> List[List[int]]:\n    res = []  # 결과 조합 저장\n    subset = []  # 현재 조합 저장\n    candidates.sort()  # 중복 제거를 위해 후보 숫자 정렬\n    \n    def dfs(i, curr_sum):\n        if curr_sum == target:\n            res.append(subset[:])\n            return\n        \n        # 합이 타겟을 초과하거나 인덱스가 범위를 벗어나면 종료\n        if curr_sum > target or i == len(candidates):\n            return\n        \n        # 현재 후보 숫자를 포함시키고 다음 인덱스로 진행\n        subset.append(candidates[i])\n        dfs(i + 1, curr_sum + candidates[i])\n        subset.pop()\n        \n        # 중복된 숫자는 한 번만 처리하기 위해 While loop를 통해 건너뜀\n        while i + 1 < len(candidates) and candidates[i] == candidates[i + 1]:\n            i += 1\n        \n        dfs(i + 1, curr_sum)\n    \n    dfs(0, 0)\n    return res\n",timeComplexity:"O(n*(2^n))",spaceComplexity:"O(n)",explanation:"후보 숫자들을 정렬하고 DFS와 백트래킹을 이용하여 목표 합을 만족하는 조합을 찾습니다. 중복된 숫자는 While loop을 통해 한 번만 처리하여 중복 결과를 방지하고, 재귀적으로 다음 인덱스로 이동하면서 가능한 모든 조합을 탐색합니다."}]},{number:9,date:"2025-02-21",name:"Permutations",tags:["DFS","Backtracking"],approach:"Use DFS with backtracking and skip already existing num in for loop.",difficulty:"Medium",url:"https://leetcode.com/problems/permutations/",solutions:[{id:"backtracking",approach:"Backtracking, DFS",code:"def permute(self, nums: List[int]) -> List[List[int]]:\n    sol = []\n    res = []\n\n    def dfs():\n        if len(sol) == len(nums):\n            res.append(sol[:])\n            return\n\n        # 입력 리스트 nums의 모든 숫자에 대해 반복합니다.\n        # 이미 현재 순열(sol)에 포함된 숫자는 건너뛰어 중복 사용을 방지합니다.\n        for num in nums:\n            if num not in sol:\n                sol.append(num)\n                dfs()\n                sol.pop()\n\n    dfs()\n    return res\n",timeComplexity:"O(n * n!)",spaceComplexity:"O(n)",explanation:"DFS와 백트래킹을 이용하여 주어진 리스트의 모든 순열을 생성합니다. 현재 순열(sol)에 포함되지 않은 숫자만 선택하여 순열을 확장하며, 입력 리스트의 길이만큼 숫자가 모두 포함되면 완성된 순열의 복사본을 결과 리스트에 추가합니다. 재귀 호출 후에는 백트래킹을 통해 마지막에 추가한 숫자를 제거함으로써 다른 조합도 탐색할 수 있도록 합니다."}]}]},4508:function(n,e,t){t.d(e,{cn:function(){return i}});var o=t(1994),r=t(3335);function i(){for(var n=arguments.length,e=Array(n),t=0;t<n;t++)e[t]=arguments[t];return(0,r.m6)((0,o.W)(e))}}}]);