"use strict";(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[729],{4491:function(n,e,t){t.d(e,{LanguageProvider:function(){return a},Z:function(){return d}});var o=t(7437),r=t(2265);let i={ko:{name:"이은지",role:"소프트웨어 엔지니어",sections:{skills:"기술 스택",experience:"경력",education:"학력",projects:"프로젝트",blog:"블로그"},buttons:{viewAll:"모든 글 보기",viewProject:"프로젝트 보기",source:"소스 코드",downloadResume:"이력서 다운로드"},theme:{light:"라이트 모드",dark:"다크 모드",system:"시스템 설정"},gpa:"학점",period:"기간",current:"현재"},en:{name:"Julie Lee",role:"Software Engineer",sections:{skills:"Skills",experience:"Experience",education:"Education",projects:"Projects",blog:"Blog"},buttons:{viewAll:"View All",viewProject:"View Project",source:"Source Code",downloadResume:"Download Resume"},theme:{light:"Light Mode",dark:"Dark Mode",system:"System"},gpa:"GPA",period:"Period",current:"Present"}},s=r.createContext(void 0);function a(n){let{children:e}=n,[t,a]=r.useState("ko");r.useEffect(()=>{let n=localStorage.getItem("preferredLanguage");("ko"===n||"en"===n)&&a(n)},[]);let d=r.useCallback(n=>{a(n),localStorage.setItem("preferredLanguage",n)},[]),l=r.useCallback(n=>{let e=function(n,e){let t=n;for(let n of e){if(!t||"string"==typeof t)return;t=t[n]}return t}(i[t],n.split("."));return"string"==typeof e?e:n},[t]);return(0,o.jsx)(s.Provider,{value:{language:t,setLanguage:d,t:l},children:e})}function d(){let n=r.useContext(s);if(!n)throw Error("useLanguage must be used within a LanguageProvider");return n}},5974:function(n,e,t){t.d(e,{C:function(){return a}});var o=t(7437);t(2265);var r=t(535),i=t(4508);let s=(0,r.j)("inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2",{variants:{variant:{default:"border-transparent bg-primary text-primary-foreground hover:bg-primary/80",secondary:"border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80",destructive:"border-transparent bg-destructive text-destructive-foreground hover:bg-destructive/80",outline:"text-foreground"}},defaultVariants:{variant:"default"}});function a(n){let{className:e,variant:t,...r}=n;return(0,o.jsx)("div",{className:(0,i.cn)(s({variant:t}),e),...r})}},2289:function(n,e,t){t.d(e,{n:function(){return o},o:function(){return r}});let o=[{slug:"cs/multiprocessing-and-multithreading-in-python",categorySlug:"cs",title:{ko:"파이썬에서의 멀티 프로세싱과 멀티 스레딩",en:"Multiprocessing and Multithreading in Python"},date:"2025-02-21",category:{ko:"컴퓨터 공학",en:"Computer Science"},description:{ko:"멀티 프로세싱과 멀티 스레딩의 파이썬에서의 동작 원리",en:"How Multiprocessing and Multithreading Work in Python"},content:'\n## 개요\n대규모 데이터 파이프라인을 운영하다보면 **병목 현상**을 자주 목격하게 됩니다. 이 때, 마이크로서비스가 실행 중인 컨테이너들을 수평적으로 확장하는 것도 중요하지만, 때로는 컨테이너 확장만으로는 해결되지 않는 문제들도 있습니다.\n\n예를 들어, 특정 서비스에서 복잡한 연산 때문에 한 개의 메시지를 처리하는 데 시간이 너무 오래 걸린다면, 멀티 프로세싱 기법을 도입하여 문제를 해결할 수 있습니다. 또한, 한 서비스가 다른 서비스의 네트워크 응답을 기다려야 하는 상황에서는, 멀티 스레딩을 활용하여 대기 시간 동안 다른 작업을 병행할 수 있습니다.\n\n이 글에서는 멀티 프로세싱과 멀티 스레딩의 차이가 무엇인지, 그리고 이 방법들을 파이썬에서 어떻게 사용할 수 있을지 알아보도록 하겠습니다.\n\n## 멀티 프로세싱\n먼저, 프로세스의 개념에 대해서 알아보겠습니다.\n\n**프로세스**: **컴퓨터에서 실행 중인 하나의 프로그램**이라고 생각하면 됩니다. 예를 들어, 웹 브라우저, 미디어 플레이어 등이 각각 하나의 프로세스입니다.\n\n각 프로세스는 운영체제로부터 독립된 메모리 공간(힙, 스택 등)과 자원을 할당 받고, 한 프로세스에 문제가 발생해도 다른 프로세스에는 영향을 주지 않습니다.\n\nCPU 코어를 활용해 위와 같은 여러 개의 프로세스들을 병렬로 실행할 수 있으며, 프로세스 간 통신은 **IPC**(Inter-Process Communication)을 사용합니다.\n예를 들어, 한 컴퓨터에서 웹 브라우저와 미디어 플레이어를 동시에 실행하는 경우, 두 개의 독립된 프로세스가 작동합니다.  \n\n아래는 Python에서 multiprocessing을 구현할 수 있는 간단한 예제입니다.\n```python\nfrom multiprocessing import Process\nimport time\n\ndef process_file(file_name):\n    print(f"[프로세스] {file_name} 처리 시작")\n    # 실제 파일 처리는 생략하고, 2초간 대기합니다.\n    time.sleep(2)\n    print(f"[프로세스] {file_name} 처리 완료")\n\ndef main():\n    files = [\'file1.csv\', \'file2.csv\']\n    processes = []\n\n    # 각 파일에 대해 별도의 프로세스를 생성합니다.\n    for file in files:\n        p = Process(target=process_file, args=(file,))\n        processes.append(p)\n        p.start()  # 각 프로세스 시작\n\n    # 모든 프로세스가 끝날 때까지 대기합니다.\n    for p in processes:\n        p.join()\n\n    print("모든 프로세스 작업 완료")\n\nif __name__ == "__main__":\n    main()\n```\n#### 동시에 실행할 수 있는 프로세스의 수\n그럼, **동시에 실행되는 프로세스의 수**는 어떻게 결정하는 것이 좋을까요?\n\n\n보통 **CPU bound** 작업일 경우, 일반적으로 **실행할 프로세스의 수를 CPU 코어 수와 동일**하게 맞추는 것이 좋습니다. 예를 들어, 8코어 시스템에서는 8개의 프로세스를 동시에 실행하면 각 프로세스가 별도의 코어에서 동작하며 최적의 성능을 낼 수 있습니다.\n\n만약 작업이 **I/O bound**일 경우, CPU 사용률이 낮으므로 **CPU 코어 수보다 더 많은 프로세스**를 실행해도 문제가 없을 수 있습니다. 하지만 동시에 실행되는 프로세스가 많아지면, 각 프로세스가 사용하는 메모리와 자원에 대한 부담이 커지기 때문에 시스템의 **메모리 용량**과 **자원 사용량**을 고려하여 정해야 합니다.\n\n#### IPC (Inter-Process Communication)\nIPC, 프로세스 간 통신은 서로 독립적으로 실행되는 여러 프로세스들이 데이터를 주고받을 수 있도록 해주는 메커니즘입니다.\n\n**IPC 방법들**\n1. **Pipe와 FIFO (Named Pipe)**  \n    **파이프**: 두 프로세스 간에 데이터를 일방향으로 전달하는 통신 채널입니다. 보통 부모/자식 프로세스 사이에서 사용됩니다.  \n    **FIFO (Named Pipe)**: 이름이 있는 파이프로, 관련 없는 독립적인 프로세스들 간에도 통신할 수 있습니다.\n2. **메시지 큐**  \n  여러 프로세스가 데이터를 메시지 단위로 보내고 받을 수 있는 큐입니다.\n  메시지는 순서대로 저장되고, 한 프로세스가 메시지를 보내면 다른 프로세스가 이를 꺼내어 처리합니다.\n3. **공유 메모리**  \n  여러 프로세스가 같은 메모리 영역에 접근할 수 있게 하는 방법입니다.\n  접근 속도가 매우 빠르지만, race condition(동기화 문제)를 해결하기 위한 추가 메커니즘이 필요합니다.\n4. **소켓**  \n  네트워크를 통해 프로세스 간 통신을 할 수 있고, 동일 컴퓨터 내의 프로세스 뿐만 아니라 다른 컴퓨터의 프로세스와도 통신할 수 있습니다.\n\n파이썬에서는 사용의 편의성과 안정성 면에서 메시지 큐(`multiprocessing.Queue`)가 가장 널리 사용됩니다. \n\n#### 멀티 프로세싱 풀 (Pool)\n멀티 프로세싱 풀은 미리 정해진 수의 프로세스(작업자)를 생성해두고, 이를 통해 작업을 분산하여 실행하는 방식입니다. 이렇게 하면 매번 새로운 프로세스를 생성하는 오버헤드를 줄일 수 있어, 다수의 작업을 효율적으로 처리할 수 있습니다.\n\n**작동 원리**\n1. 풀은 시작할 때 **지정한 수의 프로세스를 미리 생성**합니다. 예를 들어, **CPU 코어 수나 작업량**에 맞게 4개, 8개 등의 프로세스를 만들어 둡니다.\n2. 여러 작업을 풀에 제출하면, 풀에 있는 프로세스들이 작업을 나눠서 실행합니다. **작업이 끝난 프로세스는 다시 대기** 상태로 돌아가 다음 작업을 처리할 준비를 합니다.\n3. 한 번 생성된 프로세스는 여러 작업에 대해 **재사용**됩니다.\n\n## 멀티 스레딩\n**스레드**: 스레드는 하나의 프로세스 내에서 **실제로 작업을 수행하는 작은 실행 단위**입니다. 즉, 하나의 프로세스 안에서 여러 가지 일을 동시에 진행할 수 있도록 도와주는 역할을 합니다. 예를 들면, 크롬(프로세스)에서 여러 개의 탭마다 웹사이트를 불러오는 작업은 멀티 스레딩으로 이루어집니다.\n\n같은 프로세스 내의 스레드들은 **모두 동일한 메모리(데이터, 변수 등)를 공유**하며, 스레드들끼리 데이터를 쉽게 주고받을 수 있습니다. 하지만, 동시에 **같은 데이터에 접근하다 보면 서로 충돌**할 수도 있어 주의해야 합니다.\n\n#### Python에서 멀티 스레딩과 GIL (Global Interpreter Lock)\nPython의 가장 널리 쓰이는 interpreter인 CPython에는 **GIL**이라는 메커니즘이 있습니다. GIL은 한 번에 **오직 하나의 스레드**만 Python 코드를 실행하도록 하는 잠금장치입니다.\n\n\nPython은 **Garbage collection**을 사용해 메모리를 자동으로 관리합니다. GIL은 **여러 스레드가 동시에 메모리를 변경하는 일을 방지**하고, 프로그램이 복잡해져도 메모리 관리가 안전하게 이루어지도록 도와줍니다.\n\n하지만, GIL으로 인해 여러 스레드를 사용해도 한 시점에 오직 하나의 스레드만이 실제로 코드를 실행합니다. 따라서, 복잡한 계산이나 **CPU를 많이 사용하는 작업(CPU bound)은 여러 스레드로 병렬 처리했을 때 기대만큼의 성능 향상을 얻기 어렵습니다**.\n\n반면에, 파일 입출력, 네트워크 통신 등과 같이 **기다리는 시간이 상대적으로 많은 작업**(I/O bound)들에서는 **스레드가 대기 상태로 있을 때 다른 스레드가 실행**될 수 있으므로 GIL의 영향이 덜합니다. 이 경우, CPU는 한 스레드에만 국한되지 않고 다른 스레드로 전환되어 작업을 진행합니다.\n\n예를 들면, 파일을 읽거나 쓸 때, CPU는 집중적으로 계산하는 것이 아니라, 외부 장치(디스크 등)와 데이터를 주고받느라 기다리는 시간이 발생합니다. 이 때 스레드가 **대기 상태**로 들어가면서 GIL을 해제하게 됩니다. 이로 인해 다른 스레드들이 CPU를 사용할 수 있게 되어, 여러 파일을 동시에 읽거나 쓸 수 있습니다.\n  \n엄밀히 말하면 CPU가 여러 작업을 번갈아 실행하기 때문에, 동시에 실행되는 것처럼 보이지만 실제로는 **컨텍스트 스위칭**이 계속 발생하며 작업을 처리합니다.\n\nCPython에서는 GIL이 interpreter의 핵심 설계 요소이기 때문에 Python 자체에서 **GIL을 완전히 해제하거나 제거하는 것은 불가능**합니다.\n\n#### 동시에 실행할 수 있는 스레드의 수\n멀티 스레딩에서 **동시에 실행할 수 있는 스레드의 수**는 작업의 종류에 따라 달라집니다.\n\n**CPU 집약적인 작업**의 경우, CPython의 GIL 때문에 한 번에 한 스레드만 Python 바이트코드를 실행합니다. 따라서, CPU 코어 수에 맞춰 스레드를 구성하는 것이 좋습니다. 이렇게 하면 불필요한 스레드 전환(컨텍스트 스위칭) 오버헤드를 줄일 수 있습니다.\n\n반면, **I/O 바운드 작업**처럼 파일 입출력이나 네트워크 요청과 같이 대기 시간이 긴 작업에서는, CPU 사용이 크게 발생하지 않으므로 CPU 코어 수보다 훨씬 많은 스레드를 사용할 수 있습니다. 예를 들어, 네트워크 요청이 많은 애플리케이션에서는 수십 개 이상의 스레드를 사용해도 오히려 성능 향상을 기대할 수 있습니다.\n\n#### 멀티 스레딩에서의 풀\n멀티 프로세싱에서 풀을 사용하는 것과 같이, 스레딩에서도 풀 개념을 적용할 수 있습니다. Python에서는 주로 `cuncurrent.futures.ThreadPoolExecutor`를 사용하여 풀을 구성합니다. 이를 통해 **미리 정해진 수의 스레드를 생성하고, 작업을 해당 스레드들에 분산**시켜 실행할 수 있습니다.\n'},{slug:"cs/garbage-collection-in-python",categorySlug:"cs",title:{ko:"파이썬에서의 가비지 컬렉션",en:"Garbage Collection in Python"},date:"2025-02-21",category:{ko:"컴퓨터 공학",en:"Computer Science"},description:{ko:"가비지 컬렉션의 파이썬에서의 동작 원리",en:"How Garbage Collection Works in Python"},content:"\n## 가비지 컬렉션 (Garbage Collection)\nPython의 가비지 컬렉션은 메모리 관리를 자동으로 수행하는 메커니즘입니다. 이 메커니즘은 크게 두 가지 방법을 사용합니다.\n### 1. 참조 카운팅 (Reference Counting)\n어떤 물건을 여러 사람이 공유하고 있을 때, 몇 명이 그 물건을 사용 중인지 숫자로 세어보는 것과 비슷합니다.\n\n**작동 원리**\n1. Python에서 어떤 데이터를 저장하는 객체(list, dictionary, etc)가 만들어지면, 이 객체를 사용하고 있는 변수가 몇 개인지 기록합니다.\n2. 만약 변수가 그 객체를 사용하면 숫자가 1 증가하고, 더 이상 사용하지 않게 되면 숫자가 1 감소합니다.\n3. 이 **참조 카운트가 0**이 되면, 그 객체는 아무도 사용하지 않는 것으로 판단되어 청소부가 그 객체를 메모리에서 제거합니다.\n```python\na = [1, 2, 3]    # 리스트 객체 생성 (참조 카운트 증가)\n\nb = a            # b가 a를 참조 (참조 카운트 증가)\n\ndel b            # b 삭제 (참조 카운트 감소)\n```\n### 2. 순환 가비지 컬렉터 (Cyclic Garbage Collector)\n때로는 두 개 이상의 객체가 서로를 참조하면서 **서로를 잡아먹는** 상황이 생깁니다. 예를 들어, A가 B를, B가 A를 참조하고 있으면 외부에서는 둘 다 사용하지 않더라도 참조 카운트가 0이 되지 않습니다.\n\n```python\nclass A:\n    def __init__(self):\n        self.other = None\n\n# 두 객체 생성 후 서로를 참조하게 만듭니다.\na = A()\nb = A()\na.other = b  # a는 b를 참조\nb.other = a  # b는 a를 참조\n\n# 외부 참조 제거\na = None\nb = None\n\n# 이제 두 객체는 외부에서 접근할 수 없지만, 서로를 참조하므로 참조 카운트는 0이 되지 않습니다.\n```\nPython은 이러한 순환 참조 문제를 해결하기 위해 정기적으로 청소를 하는 **순환 가비지 컬렉터** 시스템을 사용합니다. 이 시스템은 주기적으로 객체 그래프를 탐색하여, **외부에서는 접근할 수 없지만 내부적으로 서로 참조하는 객체들**을 찾아냅니다.\n#### 세대 개념\n객체는 **얼마나 오래 살아남았느냐**에 따라 몇 개의 세대로 분류됩니다. 최근에 생성된 객체는 0세대, 조금 오래된 객체는 1세대, 가장 오래된 객체는 2세대로 분류됩니다.\n\n이렇게 세대를 구분하는 이유는 대부분의 객체가 짧은 수명을 가지고 있고, 오래 살아남은 객체는 변경 가능성이 낮다고 판단하여, 더 자주 검사하지 않음으로써 가비지 컬렉션 오버헤드를 줄이기 위함입니다.\n\n### 고려 사항\n한 객체를 참조하는 수가 많을 경우, **참조 카운트를 업데이트하는 오버헤드**가 발생할 수 있습니다. 객체에 대한 참조를 추가하거나 제거할 때마다 메모리 내에서 해당 값을 읽고, 수정하고, 다시 저장하는 작업이 필요합니다. \n이런 연산이 반복되면, 단순히 그 객체를 사용하거나 해제하는 비용 외에도 참조 카운트 업데이트에 따른 부가적인 CPU 연산 비용이 누적될 수 있습니다.\n\n예를 들어, 수천 개의 복잡한 데이터 구조에서 한 객체가 여러 부분에서 참조될 경우, 참조 카운트 관리에 드는 시간이 전체 성능에 영향을 줄 수 있습니다.\n\nOS는 새로운 메모리 블록을 할당하거나, 사용이 끝난 메모리 블록을 해제할 때 **시스템 호출**을 사용합니다. 이러한 호출은 사용자 코드에서 직접 호출하는 연산보다 훨씬 느리고, 오버헤드가 큽니다.\n\n\n또한, 메모리 할당/해제를 반복하면, 메모리 내부에 작고 산발적인 빈 공간들이 생기는데, 이를 **메모리 단편화**(Fragmentation)라고 합니다. 단편화가 심해지면 **메모리 사용 효율이 떨어지고, 큰 연속된 메모리 공간을 할당받기 어려워집니다**.\n\n\n이와 같이 메모리 할당 및 해제는 비용이 크므로, Python은 **메모리 풀**과 같은 기법을 통해 메모리를 재활용합니다. 메모리 풀은 **미리 일정 크기의 메모리 블록들을 할당해 놓고, 필요할 때마다 이 블록들을 재활용**하는 방식입니다.\n\n예를 들어, CPython은 짧은 문자열이나 작은 리스트와 같은 소형 객체를 위한 전용 메모리 할당기를 사용합니다. 이 풀은 **한 번에 시스템으로부터 큰 메모리 블록**을 받아, 내부에서 작고 고정된 크기의 블록들로 나눈 후, 객체 생성 시 이 블록들을 할당합니다.\n\n이 방식을 사용하면, 새로운 객체를 만들 때마다 OS에 매번 메모리 할당 요청을 보내지 않아도 되므로, **매우 빠르게 메모리를 할당**할 수 있습니다. 객체가 해제되면, 해당 메모리 블록은 즉시 운영체제에 반환되지 않고 **메모리 풀에 다시 저장**되어, 다음에 **재사용**됩니다.\n\n\n만약 현재 **할당된 메모리 풀이 모두 사용중**이라면:\n1. Python의 메모리 할당기는 OS에 추가 메모리를 요청합니다.\n2. 운영체제에서 추가 메모리를 제공하면, 메모리 풀은 확장되어 이후에 새로운 객체 할당에 사용됩니다.\n3. 만약 운영체제에서 더 이상 메모리를 제공할 수 없다면, Python은 더 이상 객체를 위한 메모리를 할당할 수 없게 됩니다. (`MemoryError` Exception 발생)\n\n메모리 풀 확장 시 여러 프로세스가 동시에 메모리를 요구할 수 있고, 이런 상황에서는 경쟁이 발생할 수도 있습니다.\n\n## 마무리\n오늘은 파이썬에서 가비지 컬렉션이 어떻게 동작하는지 알아보았습니다. 다음엔 네트워크 관련 게시글을 올려보도록 하겠습니다. 감사합니다 :)\n"},{slug:"system-design/messaging-service",categorySlug:"system-design",title:{ko:"메시징 서비스 시스템 디자인",en:"Design Messaging Service"},date:"2025-02-20",category:{ko:"시스템 디자인",en:"System Design"},description:{ko:"대규모 메시징 서비스 설계",en:"Let's design messaging service"},content:'\n`Togather` 프로젝트 (북미 대학생을 위한 익명 커뮤니티 앱) 를 만들면서, 자연스럽게 커뮤니티 플랫폼과 채팅 서비스의 시스템 디자인에 대해 관심을 갖게 되었습니다.\n\n이번 글에서는 대규모 사용자를 대상으로 한 채팅 서비스의 시스템 디자인에 대해 살펴보겠습니다.\n\n## 기능적 요구사항\n1. **그룹 채팅 지원** – 여러 명이 함께 대화할 수 있는 그룹 메시지 기능이 필요함.\n2. **메시지 송수신 기능** – 사용자가 메시지를 보내고 받을 수 있어야 함.\n3. **오프라인 수신 가능** – 사용자가 오프라인 상태일 때도 메시지를 받을 수 있어야 하며, 다시 온라인이 되면 확인할 수 있어야 함.\n4. **사진 및 미디어 전송 지원** – 텍스트뿐만 아니라 사진, 동영상 등 미디어 파일도 주고받을 수 있어야 함.\n\n## 비기능적 요구사항\n1. **빠른 메시지 전달 속도** – 온라인 상태인 사용자는 500ms(0.5초) 이내에 메시지를 받아야 함.\n2. **메시지 전달 보장** – 메시지가 유실되지 않고 반드시 수신자에게 전달되어야 함.\n3. **확장성** – 수십억 명의 사용자가 이용해도 원활하게 동작해야 함.\n4. **필요한 메시지만 저장** – 메시지는 필요한 만큼만 보관하고, 불필요한 데이터는 자동으로 삭제되도록 관리해야 함.\n5. **안정성 보장** – 특정 서버나 기능이 고장 나더라도 전체 서비스가 중단되지 않도록 시스템이 복구 및 대응할 수 있어야 함.\n## Core entities\n- Users\n- Chats\n- Messages\n- Clients (devices)\n## API 디자인\n메시지가 매우 자주 주고받아지는 환경에서는, 매번 요청을 보내고 응답을 받는 REST API 방식은 비효율적입니다. REST API는 요청이 올 때마다 새로운 연결을 만들고, 응답을 받은 후 연결을 종료하기 때문에 실시간성이 중요한 서비스에서는 지연이 발생할 수 있습니다.\n\n반면, 양방향 소켓 연결 (bi-directional socket connection) 은 한 번 연결을 설정하면 계속 유지되므로, 서버와 클라이언트가 실시간으로 데이터를 주고받을 수 있습니다. \n예를 들어, 채팅 서비스에서는 사용자가 메시지를 보내면 서버가 즉시 상대방에게 전달해야 하는데, 소켓 연결을 사용하면 별도의 요청 없이도 빠르게 메시지를 받을 수 있습니다.\n\n\n즉, 자주 변하는 데이터를 실시간으로 주고받아야 하는 서비스에서는 REST API보다 소켓 연결이 훨씬 효율적입니다.\n\n### 전송되는 명령\n#### Create Chat: 대화방 생성\n**Request**\n```json\n{\n    "participants": ["user1", "user2"],\n    "name": "Study Group"\n}\n```\n\n#### Send Message: 메시지 전송\n**Request**\n```json\n{\n    "chatId": 1,\n    "message": "hi",\n    "attachments": ["sampleFile"]\n}\n```\n\n#### Create Attachment: 첨부파일 생성\n**Request**\n```json\n{\n    "body": ...,\n    "hash": ""\n}\n```\n\n#### Modify Chat Participants, 대화방 인원 수정\n**Request**\n```json\n{\n    "chatId": 1,\n    "userId": 1,\n    "operation": "ADD" | "REMOVE"\n}\n```\n위에 나열한 각 요청은 다른 클라이언트들에게도 동시에 전송됩니다. 클라이언트가 요청을 받으면, 서버에 `"명령을 정상적으로 받았다"`는 ACK (확인 응답) 메시지를 보냅니다.\n\n이렇게 하면 서버는 `"이제 이 메시지를 다시 보낼 필요가 없겠구나"` 하고 확인합니다. (만약 ACK을 받지 못하면, 서버는 메시지가 제대로 전달되지 않았다고 판단하고 다시 보낼 수도 있습니다.)\n\n\n### 수신되는 명령\n#### New Message, 새로운 메시지 수신\n**Request**\n```json\n{\n    "chatId": 1,\n    "userId": 1\n    "message": "hi",\n    "attachments": []\n}\n```\n\n#### Chat Update, 대화방 업데이트\n**Request**\n```json\n{\n    "chatId": 1,\n    "participants": ["user1"],\n}\n```\n\n## High-Level Design\n### 1. 그룹 채팅 지원: 최대 100명\n```plaintext\n+-----------+   (WebSocket Conn)    +---------+      +-------------+      +--------------------+\n|  Client   | --------------------> |  L4 LB  | ---> | Chat Server | ---> | Database (DynamoDB) |\n+-----------+                       +---------+      +-------------+      +--------------------+\n```\n\n#### 플로우\n1. 사용자가 서비스에 연결한 후 createChat 요청을 보냅니다.\n2. 서버는 한 트랜잭션 내에서 새로운 채팅방(Chat) 데이터를 생성하고, 해당 채팅방의 참여자(ChatParticipant) 정보도 함께 저장합니다.\n3. 채팅방이 성공적으로 생성되면, 서버는 생성된 chatId를 사용자에게 반환합니다.\n\n#### 사용 기술\n- **L4(4계층) 로드밸런서**: 웹소켓 연결을 지원하며, 실시간 통신이 필요한 메시징 서비스에 적합합니다.\n- **AWS DynamoDB**: 채팅방 생성 시 관련 데이터(참여자 정보, 생성 시간 등)를 저장하기 위해 사용됩니다. 빠른 Key-Value 성능과 뛰어난 확장성(Scalability) 을 제공하여 대규모 사용자 환경에서도 안정적으로 동작합니다.\n\n여기서 다른 데이터베이스가 아닌 `AWS DynamoDB`를 사용하는 이유는 다음과 같습니다.\n- **확장성**: 자동으로 수평 확장 되므로, 사용자가 많이 늘어나는 상황에서도 안정적으로 동작합니다. RDBMS는 일정 규모가 넘어가면 샤딩을 직접 관리해야 하는데, DynamoDB는 이를 자동으로 처리해줍니다. 같은 NoSQL 데이터베이스인 MongoDB와 같은 경우에도, 수평 확장이 가능하지만, 샤딩과 클러스터 관리를 직접 해야합니다.\n- **Low latency**: key-value 기반이라 초당 수백만건의 요청을 빠르게 처리할 수 있습니다. 지연 시간을 최소화 하기 좋습니다. 쿼리 기능은 제한적이지만, Composite key와 GSI를 이용해 특정 조회 패턴을 빠르게 지원합니다.\n- **비용 효율성**: 온디맨드 모델을 사용하면, 실제 사용한 만큼만 비용을 지불합니다. 고성능 환경에서 RDBMS를 유지하려면 서버 증설 등에 비용이 크게 늘어날 수 있습니다.\n\n#### DB Index 설계: `ChatParticipant` 테이블\n`ChatParticipant` 테이블은 다음과 같은 두 가지 기능을 지원해야 합니다.\n1. 특정 채팅방에 참여한 모든 사용자 조회\n2. 특정 사용자가 참여 중인 모든 채팅방 조회\n\n이를 위해, DynamoDB의 `Composite primary key`와 `GSI(Global Secondary Indexes)`를 활용해야 합니다.\nDynamoDB는 테이블을 만들 때 기본 키로 설정되는 두 가지 유형의 Primary key를 지원하는데, 단일 partition key (우리가 아는 기본 primary key), composite key (partition key + sort key) 로 나누어져 있습니다.\n\nDynamoDB의 composite key는 partition key + sort key 조합으로 테이블을 구성하는 방식인데, 같은 Partition key 값을 가진 여러 개의 데이터를 저장할 수 있습니다. Partition key로 데이터를 그룹화하고, Sort key로 정렬하는 방식입니다.\n\n\n우리가 `chatId`를 **Partition Key**, `participantId`를 **Sort Key**로 설정하면 특정 채팅방(`chatId`)에 속한 모든 사용자를 손쉽게 조회할 수 있습니다. 하지만, **"특정 사용자가 속한 모든 채팅방을 알고 싶다"** 라는 쿼리를 실행하려면 `participantId`를 기준으로 검색해야 합니다. 이를 가능하게 하기 위해 **GSI(Global Secondary Index)** 를 추가해야 합니다.\n**GSI**는 DynamoDB에서 테이블 생성 후 추가 가능한 추가적인 조회 패턴을 지원하기 위해 사용되는 인덱스입니다. 여기서 Partition key를 `participantId`로, sort key를 `chatId`로 설정하면 특정 유저가 참여한 모든 채팅방을 효율적으로 조회할 수 있습니다.\n\nGSI가 **"Global"한 이유**는, **기본 테이블의 Partition Key와 상관없이 전역적으로 데이터를 검색할 수 있기 때문**입니다. 반면, **LSI(Local Secondary Index)** 는 특정 Partition 내부에서만 작동하므로, 예를 들어 특정 채팅방 내에서 가장 최근 메시지를 검색할 때(`chatId -> timestamp`) LSI를 활용할 수 있습니다.\n\n**요약**\n1. Composite Primary Key(`chatId` + `participantId`)를 사용하면, 특정 `chatId`에 속한 모든 사용자를 빠르게 조회할 수 있습니다.\n2. GSI(`participantId` + `chatId`)를 추가하면, 특정 사용자가 속한 모든 채팅방을 효율적으로 검색할 수 있습니다.\n\n### 2. 메시지 송수신 기능\n우선 문제를 단순화하기 위해, **서버가 하나만 존재한다고 가정**해보겠습니다. 또한, 앞서 언급한 것처럼 **웹소켓(WebSocket) 연결을 사용하여 실시간 메시지를 주고받도록 설계**합니다.\n\n\n유저가 채팅 서버에 웹소켓을 통해 연결하면, **서버는 해당 유저의 연결 정보를 해시맵(HashMap)에 저장**합니다. 이렇게 하면 **현재 어떤 유저가 서버에 연결되어 있는지 파악할 수 있으며, 연결된 유저에게 메시지를 직접 전달**할 수 있습니다.\n\n#### 메시지 송신 플로우 (1차 버전)\n1. 유저가 `sendMessage` 요청을 서버에 보냅니다.  \n2. 서버는 데이터베이스의 `ChatParticipant` 테이블을 조회하여, **해당 채팅방에 속한 모든 참여자 목록을 가져옵니다.**  \n3. 서버는 **내부 해시맵을 확인하여 현재 웹소켓 연결이 활성화된 유저들에게만 메시지를 전송합니다.**  \n\n이 방식에서는 다음과 같은 **제약 사항**이 존재합니다.  \n- 모든 유저가 웹소켓 연결 상태여야만 메시지를 받을 수 있음\n- 유저가 반드시 같은 서버에 연결되어 있어야 함\n- 각 유저마다 웹소켓을 유지하고 관리해야 함\n\n위에서 언급한 제약 사항들은 이후 섹션에서 해결 방법을 다룰 예정입니다.  \n### 3. 오프라인 수신 기능 (최대 30일)\n오프라인 수신 기능을 만들기 위해, 앞에서 가정했던 일부 조건들을 다시 생각해보겠습니다. 오프라인 상태인 유저에게 메시지를 전달하려면, 메시지를 데이터베이스에 저장해야 할 필요가 생깁니다.\n\n각 유저별로 **메시지 수신함**을 만들고, 여기에 **아직 전달되지 않은 메시지들을 저장**하는 방식으로 설계해보겠습니다.\n메시지가 전송되면, **수신자의 수신함에 메시지를 저장**하고, 만약 수신자가 온라인 상태라면 메시지 즉시 전달을 시도합니다. 만일 유저가 오프라인 상태라면, 메시지를 저장한 후 나중에 다시 접속했을 때 전달하도록 하겠습니다.\n#### 메시지 송신 플로우 (2차 버전)\n1. 유저가 `sendMessage` 요청을 서버에 보냅니다.  \n2. 서버는 데이터베이스의 `ChatParticipant` 테이블을 조회하여, **해당 채팅방에 속한 모든 참여자 목록을 가져옵니다.**  \n3. 서버는 한 트랜잭션 내에서 (1) `Message` 테이블에 메시지를 저장하고, (2) 채팅방의 각 참여자의 `Inbox`에 해당 메시지 정보를 저장합니다.\n4. 서버는 클라이언트에게 **성공/실패 응답 + `messageId`** 를 반환합니다.  \n5. 서버는 **웹소켓 연결 정보 해시맵**을 확인하여, 현재 온라인 상태인 수신자에게 `newMessage` 명령을 통해 메시지를 즉시 전달합니다.  \n6. **연결된 수신자**는 메시지를 받은 후, **`ack` 메시지를 서버에 반환**합니다. 서버는 `Inbox` 테이블에서 해당 유저에게 전달된 메시지를 삭제하여, 중복 전송을 방지합니다.\n\n#### 연결되지 않은 수신자 플로우\n오프라인 상태였던 유저가 다시 서버에 연결되었을 때, 이전까지 전달되지 않았던 메시지를 정상적으로 받을 수 있도록 처리해야 합니다.\n1. 수신자가 서버에 연결되면, **서버는 해당 유저의 `Inbox` 테이블을 조회하여 아직 남아있는 메시지 ID 목록을 가져옵니다.**  \n2. 각 `messageId` 에 해당하는 메시지를 `Message` 테이블에서 조회합니다.  \n3. 온라인 상태인 수신자에게 `newMessage` 명령을 통해 메시지들을 전달합니다.\n4. **연결된 수신자**는 메시지를 받은 후, **`ack` 메시지를 서버에 반환**합니다. 서버는 `Inbox` 테이블에서 해당 유저에게 전달된 메시지를 삭제하여, 중복 전송을 방지합니다.\n\n마지막으로, **간단한 Cron Job을 활용하여 30일 이상 전달되지 않은 `Inbox` 메시지를 정리(cleanup)** 할 수 있습니다. \n### 4. 사진 및 미디어 전송 기능\n이상적인 접근 방식은 **사용자가 직접 Blob Storage(예: AWS S3, GCS)에 업로드할 수 있도록 권한을 부여하는 것**입니다.  \n이를 위해 **Pre-Signed URL**을 활용하면, 채팅 서버를 거치지 않고도 사용자가 직접 파일을 업로드할 수 있습니다. 이 방식은 제가 `Togather` 프로젝트에서 사용자가 게시글을 올릴 때 미디어를 첨부하는 과정에서도 적용했던 방식입니다.\n\n#### 파일 업로드 플로우\n1. 사용자가 `getAttachmentTarget` 요청을 **Chat Server**에 보냅니다.  \n2. **Chat Server**는 **Pre-Signed URL**을 생성하여 사용자에게 반환합니다.  \n3. 사용자는 이 **Pre-Signed URL**을 이용해 **Blob Storage에 직접 파일을 업로드**합니다.  \n4. 업로드가 완료되면, 사용자는 **업로드된 파일의 URL을 Chat Server에 전달**하여 메시지와 함께 저장합니다.  \n\n#### 파일 다운로드 플로우\n1. 사용자가 특정 첨부 파일을 다운로드하려고 하면, 서버에 Pre-Signed URL을 요청합니다.  \n2. **Chat Server**는 Blob Storage에서 해당 파일에 접근할 수 있는 **Pre-Signed URL을 반환**합니다.  \n3. 사용자는 **해당 URL을 통해 직접 Blob Storage에서 파일을 다운로드**합니다.  \n\n이상적으로는 모든 수신자가 파일을 다운로드한 후 자동 삭제하는 것이 가장 효율적이므로, 메시지 전송 후 수신자가 다운로드 했는지 확인하는 로직이 필요합니다. 또한 파일을 일정 기간 이후 자동 삭제하는 정책을 적용시킬 수도 있습니다.\n## 상세 설계\n### 1. 수십억 명의 유저가 동시 접속할 경우 어떻게 처리할 것인가?\n위에서는 단일 서버를 가정했지만, **단일 서버로 수십억 명의 유저를 처리하는 것은 현실적으로 불가능**합니다.  \n가장 직관적인 해결 방법은 **서버를 늘려서 트래픽을 분산하는 것(수평 확장, Horizontal Scaling)** 입니다.  \n\n예를 들어, **전 세계적으로 10억 명의 유저가 있다면, 2억 명이 동시 접속하는 것도 충분히 가능한 시나리오**입니다.  \n그러나 단순히 서버를 늘리는 것만으로는 해결되지 않는 문제들도 존재합니다.  \n\n먼저, **유저가 서로 다른 서버에 연결될 경우 메시지 전송이 불가능**해집니다. 예를 들어, A 유저가 서버 1에 연결되어 있고, B 유저가 서버 2에 연결되어 있다면 두 유저 간 메시지를 주고받기 위해서는 서버 간의 데이터 동기화가 필요해집니다.\n\n이 문제를 해결하기 위해 **Redis Pub/Sub과 같은 메시지 브로커 시스템을 활용**할 수 있습니다.  \nRedis는 **가벼운 해시맵(HashMap) 기반의 소켓 연결 관리 기능을 제공하여, 메시지를 빠르게 라우팅**할 수 있습니다. \n \n#### Redis Pub/Sub 기반 메시지 전달 플로우\n**메시지를 받을 때**\n1. 사용자가 서버에 웹소켓을 연결합니다.\n2. 서버는 Redis Pub/Sub에서 해당 유저 ID를 구독 (subscribe) 합니다.\n3. 이후, 해당 유저에게 전달되는 메시지는 **구독된 Pub/Sub 채널을 통해 서버로 전달**됩니다.\n4. 서버는 받은 메시지를 웹소켓을 통해 유저에게 전달합니다.\n\n**메시지를 보낼 때**\n1. 송신자가 메시지를 보내면, **서버는 수신자의 Pub/Sub 채널에 메시지를 Publish**합니다.  \n2. 해당 메시지는 **수신자를 구독(Subscribe) 중인 모든 서버에서 수신**됩니다.  \n3. 각 서버는 **수신자가 현재 연결된 상태인지 확인하고, 연결된 경우 웹소켓을 통해 메시지를 전달**합니다.  \n\n여기서 Redis Pub/Sub의 한계도 존재합니다. Redis Pub/Sub은 **"At most once"** 전송 방식을 가지고 있는데, **구독자가 없을 경우 메시지는 손실**될 수 있습니다.\n\n하지만, 우리는 이미 `Inbox` 테이블을 통해 메시지 내구성을 보장하고 있기 때문에 문제가 되지 않습니다.\n\n그러나, 수십억 명의 유저를 감당하려면 Redis Pub/Sub 자체도 확장 가능하게 설계해야 합니다.\nRedis는 클러스터 모드(Redis Cluster)를 지원하지만, Pub/Sub 자체는 기본적으로 클러스터 샤딩을 지원하지 않습니다. 즉, 단순히 Redis Cluster를 활성화한다고 해서 Pub/Sub 메시지가 자동으로 여러 노드에 분산되지 않습니다.\n\n따라서, **수동으로 유저 ID를 기준으로 특정 Redis 노드에 Pub/Sub 메시지를 라우팅하는 방식**을 적용해야 합니다.\n\n#### Redis Cluster 기반 샤딩 적용 플로우\nRedis Cluster는 데이터를 **키(Key) 값에 따라 여러 노드(Shard)로 분산 저장**하는 기능을 제공합니다.  \n이러한 방식은 **Consistent Hashing**을 활용하여, **유저 ID를 기준으로 항상 동일한 노드에서 Pub/Sub 메시지를 처리할 수 있도록 보장**합니다.  \n\n1. **유저 ID를 기반으로 특정 Redis 노드(Shard)를 할당**합니다. (Consistent Hashing 사용)  \n2. 각 서버는 **특정 Redis 노드에서만 Pub/Sub 메시지를 Publish & Subscribe** 합니다.  \n3. **메시지를 보내는 서버가 수신자의 Redis 노드를 찾아 Publish** 합니다.  \n4. 수신자가 연결된 서버는 해당 Redis 노드에서 구독(Subscribe)한 후, 메시지를 전달합니다.  \n\n### 2. 다중 기기 지원 문제\n지금까지는 유저가 하나의 기기만 사용한다고 가정했습니다. 그러나 현실적으로 대부분의 유저는 여러 기기를 사용합니다.\n\n예를 들어, 내 휴대폰에서는 메시지를 받았지만 노트북이 꺼져있었다면 노트북을 켰을 때, **누락된 메시지를 받아서 최신 상태로 동기화** 할 수 있어야 합니다. \n하지만, 기존 **유저 단위로 메시지 전달을 추적**하는 `Inbox` 테이블 만으로는 이를 해결할 수 없습니다.\n\n다중 기기 지원 시, 고려해야할 사항은 다음과 같습니다.\n- 유저가 사용하는 모든 기기를 추적해야 합니다. 또한, 유저가 로그인하면 현재 활성화된 모든 기기를 관리할 방법이 필요합니다.\n- 더 이상 사용되지 않는 기기를 자동으로 비활성화 해야합니다.\n- 기기별로 메시지 전송을 관리해야합니다.\n\n이를 해결하기 위해, 기존 설계를 변경하지 않고 방법을 찾아보겠습니다.\n#### 1. `Clients` 테이블 추가 (유저별 활성화된 기기 추적)\n| **userId** | **clientId (device identifier)** | **lastActive** |\n|-----------|-----------------------------------|----------------|\n| user123   | phone_abc                         | 2025-02-20     |\n| user123   | laptop_xyz                        | 2025-02-19     |\n| user456   | tablet_def                        | 2025-02-18     |\n\n#### 2. `Inbox` 테이블을 유저 단위가 아닌 "기기 단위"로 변경\n각 기기가 개별적으로 메시지를 관리할 수 있으므로, 기기 간 메시지 동기화 문제를 해결할 수 있고, 기기가 오프라인 상태였다가 다시 연결되었을 때 `Inbox` 테이블을 조회하여 전과 같은 방식으로 최신 메시지들을 받을 수 있습니다.\n\n**변경 전 (유저 단위 Inbox)**\n| **userId** | **messageId** | **status**  |\n|-----------|-------------|----------|\n| user123   | msg_001     | pending  |\n| user123   | msg_002     | pending  |\n\n**변경 후 (기기 단위 Inbox)**\n| **clientId** | **messageId** | **status**  |\n|--------------|---------------|-------------|\n| phone_abc    | msg_001       | pending     |\n| laptop_xyz   | msg_001       | pending     |\n| phone_abc    | msg_002       | pending     |\n| laptop_xyz   | msg_002       | pending     |\n\n#### 3. Pub/Sub 구독 방식 변경\n기존에는 유저 ID 기준으로 서버가 Pub/Sub을 구독했지만, 이제는 기기 ID 기준으로 구독하도록 변경합니다.\n또한, 기존에는 **유저 ID**를 기준으로 메시지를 보냈지만, 이제는 **유저의 활성화된 모든 기기(Client)를 조회하여 각각 메시지를 전송**해야 합니다.\n\n**메시지를 보낼 때**  \n1. 송신자가 메시지를 보냅니다.\n2. 서버는 **수신자의 `Clients` 테이블을 조회하여 활성화된 기기 목록**을 가져옵니다. \n3. **각 기기의 Pub/Sub 채널에 메시지를 Publish** 합니다.  \n4. 해당 기기에 연결된 Chat Server가 메시지를 받아 웹소켓을 통해 전달합니다.  \n5. **각 기기가 메시지를 받은 후 `ack`를 반환하면, 해당 기기의 `Inbox`에서 메시지를 삭제**합니다.  \n\n## 마무리\n오늘은 위와 같이 대규모 사용자를 대상으로 한 채팅 서비스를 디자인 해보았습니다. 다음 번엔 대규모 사용자를 위한 게시판 서비스를 디자인 해보겠습니다. 감사합니다.\n\n### Reference\n- https://redis.io/docs/latest/develop/interact/pubsub/\n- https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-indexes-general.html\n- https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GSI.html\n- https://youtu.be/cr6p0n0N-VA\n'}],r=[{number:1,date:"2025-02-19",name:"Two Sum",tags:["Array","Hash Table"],approach:"Use hash map to store complement values",difficulty:"Easy",url:"https://leetcode.com/problems/two-sum/",solutions:[{id:"brute-force",approach:"Brute Force",code:"def twoSum(self, nums: List[int], target: int) -> List[int]:\n    for i in range(len(nums)):\n        for j in range(i + 1, len(nums)):\n            if nums[i] + nums[j] == target:\n                return [i, j]\n    return []",timeComplexity:"O(n\xb2)",spaceComplexity:"O(1)",explanation:"모든 가능한 쌍을 확인하는 방식으로, 이중 반복문을 사용합니다. 첫 번째 숫자와 두 번째 숫자의 합이 target과 같으면 해당 인덱스들을 반환합니다."},{id:"hash-map",approach:"Hash Map",code:"def twoSum(self, nums: List[int], target: int) -> List[int]:\n    seen = {}\n    for i, num in enumerate(nums):\n        complement = target - num\n        if complement in seen:\n            return [seen[complement], i]\n        seen[num] = i\n    return []",timeComplexity:"O(n)",spaceComplexity:"O(n)",explanation:"해시맵을 사용하여 각 숫자의 보수(target - 현재 숫자)를 저장합니다. 현재 숫자의 보수가 이미 해시맵에 있다면, 현재 인덱스와 해시맵에 저장된 인덱스를 반환합니다."}]},{number:2,date:"2025-02-19",name:"Task Scheduler",tags:["Heap","Queue"],approach:"Use a heap to manage task frequencies and a queue to track tasks in cooldown.",difficulty:"Medium",url:"https://leetcode.com/problems/task-scheduler/description/",solutions:[{id:"heap",approach:"Heap",code:"class Solution:\n    def leastInterval(self, tasks: List[str], n: int) -> int:\n        # 최대 힙을 사용하여 가장 빈도가 높은 작업을 먼저 처리\n        max_heap = []\n        task_counts = Counter(tasks)  # 각 작업의 빈도수 계산 (O(n))\n        \n        for count in task_counts.values():\n            max_heap.append(-count)  # 최대 힙을 만들기 위해 음수 값을 저장\n        \n        heapq.heapify(max_heap)  # O(n) 복잡도로 힙 변환\n        \n        time_elapsed = 0\n        cooldown_queue = deque()  # (남은 실행 횟수, 작업이 다시 실행 가능해지는 시간) 튜플 저장\n        \n        while max_heap or cooldown_queue:\n            time_elapsed += 1\n            \n            if max_heap:\n                remaining_executions = heapq.heappop(max_heap) + 1  # 작업 실행 (-1 증가)\n                \n                if remaining_executions < 0:  # 아직 실행해야 할 작업이 남아 있으면 큐에 추가\n                    cooldown_queue.append((remaining_executions, time_elapsed + n))\n            \n            # 가장 먼저 추가된 작업이 다시 실행 가능하면 max_heap으로 복귀\n            if cooldown_queue and cooldown_queue[0][1] == time_elapsed:\n                heapq.heappush(max_heap, cooldown_queue.popleft()[0])\n        \n        return time_elapsed\n",timeComplexity:"O(n): O(n log(26)) -> O(n), 각 작업은 최대 한 번만 heappop(), heappush() 실행 가능",spaceComplexity:"O(1): O(26) -> O(1)",explanation:"최대 힙을 사용하여 가장 빈도가 높은 작업을 먼저 실행합니다. 실행된 작업은 쿨다운 큐에 넣어 일정 시간이 지나야 다시 실행할 수 있도록 합니다. 쿨다운이 끝난 작업은 다시 힙에 추가하여 최소 시간으로 모든 작업을 처리합니다."}]},{number:3,date:"2025-02-19",name:"Design Twitter",tags:["Heap"],approach:"Use a min heap to get the 10 most recent tweets, adding previous tweets if available.",difficulty:"Medium",url:"https://leetcode.com/problems/design-twitter/",solutions:[{id:"heap",approach:"Heap",code:'class Twitter:\n    def __init__(self):\n        self.tweets = defaultdict(list)  # 사용자 ID별 트윗 리스트 저장\n        self.follows = defaultdict(set)  # 사용자 ID별 팔로우하는 사용자 목록 저장\n        self.counter = 0  # 트윗 정렬을 위한 시간 카운터 (최근 트윗이 가장 작은 값)\n\n    def postTweet(self, userId: int, tweetId: int) -> None:\n        """사용자가 새로운 트윗을 게시한다."""\n        self.counter -= 1  # 최신 트윗이 가장 먼저 나오도록 음수값 사용\n        self.tweets[userId].append((self.counter, tweetId))  # 트윗 저장\n\n    def getNewsFeed(self, userId: int) -> List[int]:\n        """사용자와 팔로우한 사람들의 최신 10개 트윗을 반환한다."""\n        followees = self.follows[userId]  # 사용자가 팔로우한 사람들 가져오기\n        followees.add(userId)  # 자신의 트윗도 포함\n\n        heap = []  # 최소 힙을 사용하여 최신 트윗 10개 유지\n\n        # 각 팔로우한 사용자의 가장 최신 트윗을 힙에 추가\n        for followee in followees:\n            if followee in self.tweets:\n                idx = len(self.tweets[followee]) - 1  # 최신 트윗의 인덱스\n                count, tweet_id = self.tweets[followee][idx]\n                heapq.heappush(heap, (count, tweet_id, followee, idx - 1))  # 최신 트윗 삽입\n\n        res = []\n        while heap and len(res) < 10:  # 최대 10개의 트윗을 가져옴\n            count, tweet_id, followee, idx = heapq.heappop(heap)  # 가장 최신 트윗 꺼내기\n            res.append(tweet_id)\n\n            if idx >= 0:  # 해당 사용자의 이전 트윗이 존재하면 힙에 추가\n                count, tweet_id = self.tweets[followee][idx]\n                heapq.heappush(heap, (count, tweet_id, followee, idx - 1))\n\n        return res\n\n    def follow(self, followerId: int, followeeId: int) -> None:\n        """followerId 사용자가 followeeId 사용자를 팔로우한다."""\n        self.follows[followerId].add(followeeId)\n\n    def unfollow(self, followerId: int, followeeId: int) -> None:\n        """followerId 사용자가 followeeId 사용자를 언팔로우한다."""\n        if followeeId in self.follows[followerId]:\n            self.follows[followerId].remove(followeeId)\n',timeComplexity:"O(n log n) (for getNewsFeed), O(1) (for other methods)",spaceComplexity:"O(N * m + N * M + n): O(N * m)(모든 사용자의 트윗 저장, N: 전체 사용자 수, m: 사용자당 최대 트윗 수), O(N * M)(팔로우 관계 저장, M: 사용자당 최대 팔로우 수), O(n)(getNewsFeed() 실행 시 힙 사용, n: userId에 연결된 총 팔로우 수)",explanation:"최대 힙을 사용하여 가장 최신 트윗을 가져옵니다. 각 사용자의 최신 트윗을 힙에 넣고, 가장 최신 트윗을 가져온 후 해당 사용자의 이전 트윗을 추가하여 최신순으로 유지합니다. 최대 10개의 트윗만 유지하여 뉴스 피드를 반환합니다. 팔로우 관계는 별도의 해시맵에 저장하여 관리합니다."}]},{number:4,date:"2025-02-20",name:"Design Add and Search Word Data Structure",tags:["Trie","DFS"],approach:"Use a Trie to store and search words, and utilize DFS with backtracking to handle wildcard '.' searches.",difficulty:"Medium",url:"https://leetcode.com/problems/design-add-and-search-words-data-structure",solutions:[{id:"trie",approach:"Trie, DFS",code:"class TrieNode:\n    def __init__(self):\n        self.children: = dict()  # 문자 -> TrieNode 매핑\n        self.word = False  # 현재 노드가 단어의 끝인지 여부\n\nclass WordDictionary:\n    def __init__(self):\n        self.root = TrieNode()\n\n    def addWord(self, word: str) -> None:\n        curr = self.root\n        \n        for c in word:\n            if c not in curr.children:  # 해당 문자가 Trie에 없으면 새 노드 추가\n                curr.children[c] = TrieNode()\n            curr = curr.children[c]  # 다음 노드로 이동\n        \n        curr.word = True  # 단어 끝을 표시\n        \n    def search(self, word: str) -> bool:        \n        def dfs(j, root):\n            curr = root\n            for i in range(j, len(word)):\n                c = word[i]\n                \n                if c == \".\":  # '.'은 어떤 문자와도 매칭 가능\n                    for child in cur.children.values():  # 현재 노드의 모든 자식 노드를 탐색\n                        if dfs(i + 1, child):  # 다음 문자를 재귀적으로 탐색\n                            return True\n                            \n                    return False  # 매칭되는 단어가 없음\n                else:\n                    if c not in curr.children:\n                        return False\n                        \n                    curr = curr.children[c]\n                    \n            return cur.word  # 단어 끝 여부 반환\n        \n        return dfs(0, self.root)\n",timeComplexity:"O(n) for addWord(), O(n) for search()",spaceComplexity:"O(t + n), where t is the total number of stored characters in Trie and n is the depth of recursive calls in search()",explanation:"Trie를 사용하여 단어를 추가하고 검색합니다. addWord()는 단어 길이 n에 비례하는 O(n) 시간에 수행됩니다. search() 또한 일반적인 경우 O(n)이지만, '.'이 포함되면 백트래킹이 발생할 수 있습니다. 공간 복잡도는 Trie에 저장된 총 문자 개수 t와 DFS 호출 깊이 n에 의해 결정됩니다."}]},{number:5,date:"2025-02-20",name:"Word Search II",tags:["Trie","DFS","Backtracking"],approach:"Store words in a Trie and use DFS with backtracking to find valid words on the board.",difficulty:"Hard",url:"https://leetcode.com/problems/word-search-ii/",solutions:[{id:"trie",approach:"Trie, DFS",code:'class TrieNode:\n    def __init__():\n        self.children = dict()\n        self.is_word = False\n    \n    def add_word(self, word):\n        curr = self\n        \n        for c in word:\n            if c not in curr.children:\n                curr.children[c] = TrieNode()\n            curr = curr.children[c]\n        \n        curr.is_word = True\n        \ndef findWords(self, board: List[List[str]], words: List[str]) -> List[str]:\n    # Trie를 생성하고 단어들을 추가\n    root = TrieNode()\n    for w in words:\n        root.add_word(w)\n    \n    num_rows, num_cols = len(board), len(board[0])\n    res = set()  # 중복 방지를 위해 set 사용\n    visit = set()  # 방문한 위치 추적\n    \n    def dfs(r, c, node, word):\n        # 보드를 벗어나거나 이미 방문한 위치이거나, 현재 문자가 Trie에 없는 경우 종료\n        if not 0 <= r < num_rows or not 0 <= c < num_cols or (r, c) in visit or board[r][c] not in node.children:\n            return\n        \n        visit.add((r, c))\n        \n        node = node.children[board[r][c]]  # Trie에서 현재 문자에 해당하는 노드로 이동\n        word += board[r][c]  # 단어에 문자 추가\n        \n        if node.is_word:  # Trie에 등록된 단어를 찾으면 결과에 추가\n            res.add(word)\n        \n        # 상, 하, 좌, 우 방향으로 DFS 탐색 수행\n        dfs(r - 1, c, node, word)\n        dfs(r + 1, c, node, word)\n        dfs(r, c - 1, node, word)\n        dfs(r, c + 1, node, word)\n        \n        visit.remove((r, c))  # 백트래킹(이전 상태로 복귀)\n        \n    # 보드의 모든 위치에서 DFS 시작\n    for r in range(num_rows):\n        for c in range(num_cols):\n            dfs(r, c, root, "")\n    \n    return list(res)\n',timeComplexity:"O(m * n * 4 * 3^(t-1) + s), where m is the number of rows, n is the number of columns, t is the maximum length of any word in words, and s is the sum of the lengths of all words.",spaceComplexity:"O(s), where s is the sum of the lengths of all words stored in the Trie.",explanation:"먼저 단어 목록을 Trie에 저장합니다. 그런 다음, board에서 가능한 모든 위치에서 DFS를 수행하여 단어를 찾습니다. DFS 중에는 백트래킹을 사용하여 이미 방문한 위치를 추적하고, 경로를 따라 Trie에 없는 문자가 나오면 탐색을 중단합니다. 검색된 단어는 set에 저장하여 중복을 방지하고, 최종적으로 리스트로 변환하여 반환합니다."}]},{number:6,date:"2025-02-21",name:"Subsets",tags:["DFS","Backtracking"],approach:"Use DFS with backtracking to explore both including and excluding each element.",difficulty:"Medium",url:"https://leetcode.com/problems/subsets",solutions:[{id:"backtracking",approach:"Backtracking, DFS",code:"def subsets(self, nums: List[int]) -> List[List[int]]:\n    res = []  # 모든 부분집합을 저장할 리스트\n    subset = []  # 현재까지 선택된 원소들을 저장할 리스트\n    \n    def dfs(i):\n        # i가 nums의 길이와 같으면, 모든 원소에 대해 선택 여부를 결정한 것이므로 결과에 추가\n        if i == len(nums):\n            res.append(subset[:])  # 현재 subset의 복사본을 추가\n            return\n        \n        # 현재 원소를 부분 집합에 포함시키는 경우\n        subset.append(nums[i])\n        dfs(i + 1)\n        \n        # 백트래킹: 이전 선택을 취소하고 원소를 포함시키지 않는 경우\n        subset.pop()\n        dfs(i + 1)\n    \n    dfs(0)\n    return res\n",timeComplexity:"최악의 경우 모든 원소에 대해 선택 또는 비선택의 두 가지 경우를 고려하므로, 시간 복잡도는 O(2ⁿ)입니다. 또한, 각 부분집합을 복사하는 데 O(n)의 시간이 소요되므로, 전체 시간 복잡도는 O(n * 2ⁿ)입니다.",spaceComplexity:"O(n)",explanation:"각 단계에서 현재 인덱스의 원소를 선택하거나 선택하지 않고 재귀 호출을 진행합니다. 인덱스가 리스트의 길이에 도달하면, 현재까지 구성된 부분집합의 복사본을 결과에 추가합니다. 이 과정에서 백트래킹을 통해 이전 선택을 취소하여 다른 경우의 수도 탐색할 수 있습니다."}]},{number:7,date:"2025-02-21",name:"Combination Sum",tags:["DFS","Backtracking"],approach:"Use DFS with backtracking to build candidate combinations that sum to the target.",difficulty:"Medium",url:"https://leetcode.com/problems/combination-sum/",solutions:[{id:"backtracking",approach:"Backtracking, DFS",code:"def combinationSum(self, candidates: List[int], target: int) -> List[List[int]]:\n    res = []  # 결과로 반환할 조합\n    subset = []  # 현재까지 선택된 숫자 조합\n    \n    def dfs(i, curr_sum):\n        # 현재 합이 target과 같으면, 현재 조합의 복사본을 추가\n        if curr_sum == target:\n            res.append(subset[:])\n            return\n        \n        # 인덱스가 끝에 도달했거나 현재 합이 target을 초과하면 종료        \n        if i == len(candidates) or curr_sum > target:\n            return\n        \n        # 현재 후보 숫자를 조합에 포함시키고 재귀적으로 같은 인덱스에서 탐색 (같은 숫자 재사용이 가능하기 때문)\n        subset.append(candidates[i])\n        dfs(i, curr_sum + candidates[i])\n        \n        # 백트래킹: 마지막에 추가한 숫자를 제거하고 다음 후보로 넘어감\n        subset.pop()\n        dfs(i + 1, curr_sum)\n    \n    dfs(0, 0)\n    return res\n",timeComplexity:"O(2^(t/m)) 최악의 경우 모든 가능한 조합을 탐색해야 함",spaceComplexity:"O(n)",explanation:"DFS와 백트래킹을 활용하여 후보 숫자들의 조합을 탐색하며, 현재 인덱스의 숫자를 포함시켜 합계를 갱신하고 재귀적으로 탐색을 진행합니다. 만약 현재 합이 목표값(target)과 같다면 해당 조합을 결과 리스트에 추가하며, 인덱스가 배열의 끝에 도달하거나 합이 목표를 초과하면 탐색을 중단합니다. 포함한 후에는 백트래킹을 통해 마지막으로 추가한 숫자를 제거하고 다음 후보로 넘어가며 모든 가능한 조합을 탐색합니다."}]},{number:8,date:"2025-02-21",name:"Combination Sum II",tags:["DFS","Backtracking"],approach:"Use DFS with backtracking and skip duplicates with a while loop.",difficulty:"Medium",url:"https://leetcode.com/problems/combination-sum-ii/",solutions:[{id:"backtracking",approach:"Backtracking, DFS",code:"def combinationSum2(self, candidates: List[int], target: int) -> List[List[int]]:\n    res = []  # 결과 조합 저장\n    subset = []  # 현재 조합 저장\n    candidates.sort()  # 중복 제거를 위해 후보 숫자 정렬\n    \n    def dfs(i, curr_sum):\n        if curr_sum == target:\n            res.append(subset[:])\n            return\n        \n        # 합이 타겟을 초과하거나 인덱스가 범위를 벗어나면 종료\n        if curr_sum > target or i == len(candidates):\n            return\n        \n        # 현재 후보 숫자를 포함시키고 다음 인덱스로 진행\n        subset.append(candidates[i])\n        dfs(i + 1, curr_sum + candidates[i])\n        subset.pop()\n        \n        # 중복된 숫자는 한 번만 처리하기 위해 While loop를 통해 건너뜀\n        while i + 1 < len(candidates) and candidates[i] == candidates[i + 1]:\n            i += 1\n        \n        dfs(i + 1, curr_sum)\n    \n    dfs(0, 0)\n    return res\n",timeComplexity:"O(n*(2^n))",spaceComplexity:"O(n)",explanation:"후보 숫자들을 정렬하고 DFS와 백트래킹을 이용하여 목표 합을 만족하는 조합을 찾습니다. 중복된 숫자는 While loop을 통해 한 번만 처리하여 중복 결과를 방지하고, 재귀적으로 다음 인덱스로 이동하면서 가능한 모든 조합을 탐색합니다."}]},{number:9,date:"2025-02-21",name:"Permutations",tags:["DFS","Backtracking"],approach:"Use DFS with backtracking and skip already existing num in for loop.",difficulty:"Medium",url:"https://leetcode.com/problems/permutations/",solutions:[{id:"backtracking",approach:"Backtracking, DFS",code:"\n                def permute(self, nums: List[int]) -> List[List[int]]:\n    sol = []\n    res = []\n\n    def dfs():\n        if len(sol) == len(nums):\n            res.append(sol[:])\n            return\n\n        # 입력 리스트 nums의 모든 숫자에 대해 반복합니다.\n        # 이미 현재 순열(sol)에 포함된 숫자는 건너뛰어 중복 사용을 방지합니다.\n        for num in nums:\n            if num not in sol:\n                sol.append(num)\n                dfs()\n                sol.pop()\n\n    dfs()\n    return res\n",timeComplexity:"O(n * n!)",spaceComplexity:"O(n)",explanation:"DFS와 백트래킹을 이용하여 주어진 리스트의 모든 순열을 생성합니다. 현재 순열(sol)에 포함되지 않은 숫자만 선택하여 순열을 확장하며, 입력 리스트의 길이만큼 숫자가 모두 포함되면 완성된 순열의 복사본을 결과 리스트에 추가합니다. 재귀 호출 후에는 백트래킹을 통해 마지막에 추가한 숫자를 제거함으로써 다른 조합도 탐색할 수 있도록 합니다."}]}]},4508:function(n,e,t){t.d(e,{cn:function(){return i}});var o=t(1994),r=t(3335);function i(){for(var n=arguments.length,e=Array(n),t=0;t<n;t++)e[t]=arguments[t];return(0,r.m6)((0,o.W)(e))}}}]);