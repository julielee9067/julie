"use strict";(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[145],{4491:function(n,e,t){t.d(e,{LanguageProvider:function(){return s},Z:function(){return l}});var r=t(7437),o=t(2265);let a={ko:{name:"이은지",role:"소프트웨어 엔지니어",sections:{skills:"기술 스택",experience:"경력",education:"학력",projects:"프로젝트",blog:"블로그"},buttons:{viewAll:"모든 글 보기",viewProject:"프로젝트 보기",source:"소스 코드",downloadResume:"이력서 다운로드"},theme:{light:"라이트 모드",dark:"다크 모드",system:"시스템 설정"},gpa:"학점",period:"기간",current:"현재"},en:{name:"Julie Lee",role:"Software Engineer",sections:{skills:"Skills",experience:"Experience",education:"Education",projects:"Projects",blog:"Blog"},buttons:{viewAll:"View All",viewProject:"View Project",source:"Source Code",downloadResume:"Download Resume"},theme:{light:"Light Mode",dark:"Dark Mode",system:"System"},gpa:"GPA",period:"Period",current:"Present"}},i=o.createContext(void 0);function s(n){let{children:e}=n,[t,s]=o.useState("ko");o.useEffect(()=>{let n=localStorage.getItem("preferredLanguage");("ko"===n||"en"===n)&&s(n)},[]);let l=o.useCallback(n=>{s(n),localStorage.setItem("preferredLanguage",n)},[]),c=o.useCallback(n=>{let e=function(n,e){let t=n;for(let n of e){if(!t||"string"==typeof t)return;t=t[n]}return t}(a[t],n.split("."));return"string"==typeof e?e:n},[t]);return(0,r.jsx)(i.Provider,{value:{language:t,setLanguage:l,t:c},children:e})}function l(){let n=o.useContext(i);if(!n)throw Error("useLanguage must be used within a LanguageProvider");return n}},5974:function(n,e,t){t.d(e,{C:function(){return s}});var r=t(7437);t(2265);var o=t(535),a=t(4508);let i=(0,o.j)("inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2",{variants:{variant:{default:"border-transparent bg-primary text-primary-foreground hover:bg-primary/80",secondary:"border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80",destructive:"border-transparent bg-destructive text-destructive-foreground hover:bg-destructive/80",outline:"text-foreground"}},defaultVariants:{variant:"default"}});function s(n){let{className:e,variant:t,...o}=n;return(0,r.jsx)("div",{className:(0,a.cn)(i({variant:t}),e),...o})}},6070:function(n,e,t){t.d(e,{Ol:function(){return s},Zb:function(){return i},aY:function(){return c},eW:function(){return d},ll:function(){return l}});var r=t(7437),o=t(2265),a=t(4508);let i=o.forwardRef((n,e)=>{let{className:t,...o}=n;return(0,r.jsx)("div",{ref:e,className:(0,a.cn)("rounded-lg border bg-card text-card-foreground shadow-sm",t),...o})});i.displayName="Card";let s=o.forwardRef((n,e)=>{let{className:t,...o}=n;return(0,r.jsx)("div",{ref:e,className:(0,a.cn)("flex flex-col space-y-1.5 p-6",t),...o})});s.displayName="CardHeader";let l=o.forwardRef((n,e)=>{let{className:t,...o}=n;return(0,r.jsx)("div",{ref:e,className:(0,a.cn)("text-2xl font-semibold leading-none tracking-tight",t),...o})});l.displayName="CardTitle",o.forwardRef((n,e)=>{let{className:t,...o}=n;return(0,r.jsx)("div",{ref:e,className:(0,a.cn)("text-sm text-muted-foreground",t),...o})}).displayName="CardDescription";let c=o.forwardRef((n,e)=>{let{className:t,...o}=n;return(0,r.jsx)("div",{ref:e,className:(0,a.cn)("p-6 pt-0",t),...o})});c.displayName="CardContent";let d=o.forwardRef((n,e)=>{let{className:t,...o}=n;return(0,r.jsx)("div",{ref:e,className:(0,a.cn)("flex items-center p-6 pt-0",t),...o})});d.displayName="CardFooter"},3344:function(n,e,t){t.d(e,{n:function(){return r},o:function(){return o}});let r=[{slug:"cs/multiprocessing-and-multithreading-in-python",categorySlug:"cs",title:{ko:"파이썬에서의 멀티 프로세싱과 멀티 스레딩",en:"Multiprocessing and Multithreading in Python"},date:"2025-02-21",category:{ko:"컴퓨터 공학",en:"Computer Science"},description:{ko:"멀티 프로세싱과 멀티 스레딩의 파이썬에서의 동작 원리",en:"How Multiprocessing and Multithreading Work in Python"},content:'\n## 개요\n대규모 데이터 파이프라인을 운영하다보면 **병목 현상**을 자주 목격하게 됩니다. 이 때, 마이크로서비스가 실행 중인 컨테이너들을 수평적으로 확장하는 것도 중요하지만, 때로는 컨테이너 확장만으로는 해결되지 않는 문제들도 있습니다.\n\n예를 들어, 특정 서비스에서 복잡한 연산 때문에 한 개의 메시지를 처리하는 데 시간이 너무 오래 걸린다면, 멀티 프로세싱 기법을 도입하여 문제를 해결할 수 있습니다. 또한, 한 서비스가 다른 서비스의 네트워크 응답을 기다려야 하는 상황에서는, 멀티 스레딩을 활용하여 대기 시간 동안 다른 작업을 병행할 수 있습니다.\n\n이 글에서는 멀티 프로세싱과 멀티 스레딩의 차이가 무엇인지, 그리고 이 방법들을 파이썬에서 어떻게 사용할 수 있을지 알아보도록 하겠습니다.\n\n## 멀티 프로세싱\n먼저, 프로세스의 개념에 대해서 알아보겠습니다.\n\n**프로세스**: **컴퓨터에서 실행 중인 하나의 프로그램**이라고 생각하면 됩니다. 예를 들어, 웹 브라우저, 미디어 플레이어 등이 각각 하나의 프로세스입니다.\n\n각 프로세스는 운영체제로부터 독립된 메모리 공간(힙, 스택 등)과 자원을 할당 받고, 한 프로세스에 문제가 발생해도 다른 프로세스에는 영향을 주지 않습니다.\n\nCPU 코어를 활용해 위와 같은 여러 개의 프로세스들을 병렬로 실행할 수 있으며, 프로세스 간 통신은 **IPC**(Inter-Process Communication)을 사용합니다.\n예를 들어, 한 컴퓨터에서 웹 브라우저와 미디어 플레이어를 동시에 실행하는 경우, 두 개의 독립된 프로세스가 작동합니다.  \n\n아래는 Python에서 multiprocessing을 구현할 수 있는 간단한 예제입니다.\n```python\nfrom multiprocessing import Process\nimport time\n\ndef process_file(file_name):\n    print(f"[프로세스] {file_name} 처리 시작")\n    # 실제 파일 처리는 생략하고, 2초간 대기합니다.\n    time.sleep(2)\n    print(f"[프로세스] {file_name} 처리 완료")\n\ndef main():\n    files = [\'file1.csv\', \'file2.csv\']\n    processes = []\n\n    # 각 파일에 대해 별도의 프로세스를 생성합니다.\n    for file in files:\n        p = Process(target=process_file, args=(file,))\n        processes.append(p)\n        p.start()  # 각 프로세스 시작\n\n    # 모든 프로세스가 끝날 때까지 대기합니다.\n    for p in processes:\n        p.join()\n\n    print("모든 프로세스 작업 완료")\n\nif __name__ == "__main__":\n    main()\n```\n#### 동시에 실행할 수 있는 프로세스의 수\n그럼, **동시에 실행되는 프로세스의 수**는 어떻게 결정하는 것이 좋을까요?\n\n\n보통 **CPU bound** 작업일 경우, 일반적으로 **실행할 프로세스의 수를 CPU 코어 수와 동일**하게 맞추는 것이 좋습니다. 예를 들어, 8코어 시스템에서는 8개의 프로세스를 동시에 실행하면 각 프로세스가 별도의 코어에서 동작하며 최적의 성능을 낼 수 있습니다.\n\n만약 작업이 **I/O bound**일 경우, CPU 사용률이 낮으므로 **CPU 코어 수보다 더 많은 프로세스**를 실행해도 문제가 없을 수 있습니다. 하지만 동시에 실행되는 프로세스가 많아지면, 각 프로세스가 사용하는 메모리와 자원에 대한 부담이 커지기 때문에 시스템의 **메모리 용량**과 **자원 사용량**을 고려하여 정해야 합니다.\n\n#### IPC (Inter-Process Communication)\nIPC, 프로세스 간 통신은 서로 독립적으로 실행되는 여러 프로세스들이 데이터를 주고받을 수 있도록 해주는 메커니즘입니다.\n\n**IPC 방법들**\n1. **Pipe와 FIFO (Named Pipe)**  \n    **파이프**: 두 프로세스 간에 데이터를 일방향으로 전달하는 통신 채널입니다. 보통 부모/자식 프로세스 사이에서 사용됩니다.  \n    **FIFO (Named Pipe)**: 이름이 있는 파이프로, 관련 없는 독립적인 프로세스들 간에도 통신할 수 있습니다.\n2. **메시지 큐**  \n  여러 프로세스가 데이터를 메시지 단위로 보내고 받을 수 있는 큐입니다.\n  메시지는 순서대로 저장되고, 한 프로세스가 메시지를 보내면 다른 프로세스가 이를 꺼내어 처리합니다.\n3. **공유 메모리**  \n  여러 프로세스가 같은 메모리 영역에 접근할 수 있게 하는 방법입니다.\n  접근 속도가 매우 빠르지만, race condition(동기화 문제)를 해결하기 위한 추가 메커니즘이 필요합니다.\n4. **소켓**  \n  네트워크를 통해 프로세스 간 통신을 할 수 있고, 동일 컴퓨터 내의 프로세스 뿐만 아니라 다른 컴퓨터의 프로세스와도 통신할 수 있습니다.\n\n파이썬에서는 사용의 편의성과 안정성 면에서 메시지 큐(`multiprocessing.Queue`)가 가장 널리 사용됩니다. \n\n#### 멀티 프로세싱 풀 (Pool)\n멀티 프로세싱 풀은 미리 정해진 수의 프로세스(작업자)를 생성해두고, 이를 통해 작업을 분산하여 실행하는 방식입니다. 이렇게 하면 매번 새로운 프로세스를 생성하는 오버헤드를 줄일 수 있어, 다수의 작업을 효율적으로 처리할 수 있습니다.\n\n**작동 원리**\n1. 풀은 시작할 때 **지정한 수의 프로세스를 미리 생성**합니다. 예를 들어, **CPU 코어 수나 작업량**에 맞게 4개, 8개 등의 프로세스를 만들어 둡니다.\n2. 여러 작업을 풀에 제출하면, 풀에 있는 프로세스들이 작업을 나눠서 실행합니다. **작업이 끝난 프로세스는 다시 대기** 상태로 돌아가 다음 작업을 처리할 준비를 합니다.\n3. 한 번 생성된 프로세스는 여러 작업에 대해 **재사용**됩니다.\n\n## 멀티 스레딩\n**스레드**: 스레드는 하나의 프로세스 내에서 **실제로 작업을 수행하는 작은 실행 단위**입니다. 즉, 하나의 프로세스 안에서 여러 가지 일을 동시에 진행할 수 있도록 도와주는 역할을 합니다. 예를 들면, 크롬(프로세스)에서 여러 개의 탭마다 웹사이트를 불러오는 작업은 멀티 스레딩으로 이루어집니다.\n\n같은 프로세스 내의 스레드들은 **모두 동일한 메모리(데이터, 변수 등)를 공유**하며, 스레드들끼리 데이터를 쉽게 주고받을 수 있습니다. 하지만, 동시에 **같은 데이터에 접근하다 보면 서로 충돌**할 수도 있어 주의해야 합니다.\n\n#### Python에서 멀티 스레딩과 GIL (Global Interpreter Lock)\nPython의 가장 널리 쓰이는 interpreter인 CPython에는 **GIL**이라는 메커니즘이 있습니다. GIL은 한 번에 **오직 하나의 스레드**만 Python 코드를 실행하도록 하는 잠금장치입니다.\n\n\nPython은 **Garbage collection**을 사용해 메모리를 자동으로 관리합니다. GIL은 **여러 스레드가 동시에 메모리를 변경하는 일을 방지**하고, 프로그램이 복잡해져도 메모리 관리가 안전하게 이루어지도록 도와줍니다.\n\n하지만, GIL으로 인해 여러 스레드를 사용해도 한 시점에 오직 하나의 스레드만이 실제로 코드를 실행합니다. 따라서, 복잡한 계산이나 **CPU를 많이 사용하는 작업(CPU bound)은 여러 스레드로 병렬 처리했을 때 기대만큼의 성능 향상을 얻기 어렵습니다**.\n\n반면에, 파일 입출력, 네트워크 통신 등과 같이 **기다리는 시간이 상대적으로 많은 작업**(I/O bound)들에서는 **스레드가 대기 상태로 있을 때 다른 스레드가 실행**될 수 있으므로 GIL의 영향이 덜합니다. 이 경우, CPU는 한 스레드에만 국한되지 않고 다른 스레드로 전환되어 작업을 진행합니다.\n\n예를 들면, 파일을 읽거나 쓸 때, CPU는 집중적으로 계산하는 것이 아니라, 외부 장치(디스크 등)와 데이터를 주고받느라 기다리는 시간이 발생합니다. 이 때 스레드가 **대기 상태**로 들어가면서 GIL을 해제하게 됩니다. 이로 인해 다른 스레드들이 CPU를 사용할 수 있게 되어, 여러 파일을 동시에 읽거나 쓸 수 있습니다.\n  \n엄밀히 말하면 CPU가 여러 작업을 번갈아 실행하기 때문에, 동시에 실행되는 것처럼 보이지만 실제로는 **컨텍스트 스위칭**이 계속 발생하며 작업을 처리합니다.\n\nCPython에서는 GIL이 interpreter의 핵심 설계 요소이기 때문에 Python 자체에서 **GIL을 완전히 해제하거나 제거하는 것은 불가능**합니다.\n\n#### 동시에 실행할 수 있는 스레드의 수\n멀티 스레딩에서 **동시에 실행할 수 있는 스레드의 수**는 작업의 종류에 따라 달라집니다.\n\n**CPU 집약적인 작업**의 경우, CPython의 GIL 때문에 한 번에 한 스레드만 Python 바이트코드를 실행합니다. 따라서, CPU 코어 수에 맞춰 스레드를 구성하는 것이 좋습니다. 이렇게 하면 불필요한 스레드 전환(컨텍스트 스위칭) 오버헤드를 줄일 수 있습니다.\n\n반면, **I/O 바운드 작업**처럼 파일 입출력이나 네트워크 요청과 같이 대기 시간이 긴 작업에서는, CPU 사용이 크게 발생하지 않으므로 CPU 코어 수보다 훨씬 많은 스레드를 사용할 수 있습니다. 예를 들어, 네트워크 요청이 많은 애플리케이션에서는 수십 개 이상의 스레드를 사용해도 오히려 성능 향상을 기대할 수 있습니다.\n\n#### 멀티 스레딩에서의 풀\n멀티 프로세싱에서 풀을 사용하는 것과 같이, 스레딩에서도 풀 개념을 적용할 수 있습니다. Python에서는 주로 `cuncurrent.futures.ThreadPoolExecutor`를 사용하여 풀을 구성합니다. 이를 통해 **미리 정해진 수의 스레드를 생성하고, 작업을 해당 스레드들에 분산**시켜 실행할 수 있습니다.\n'},{slug:"cs/garbage-collection-in-python",categorySlug:"cs",title:{ko:"파이썬에서의 가비지 컬렉션",en:"Garbage Collection in Python"},date:"2025-02-21",category:{ko:"컴퓨터 공학",en:"Computer Science"},description:{ko:"가비지 컬렉션의 파이썬에서의 동작 원리",en:"How Garbage Collection Works in Python"},content:"\n## 가비지 컬렉션 (Garbage Collection)\nPython의 가비지 컬렉션은 메모리 관리를 자동으로 수행하는 메커니즘입니다. 이 메커니즘은 크게 두 가지 방법을 사용합니다.\n### 1. 참조 카운팅 (Reference Counting)\n어떤 물건을 여러 사람이 공유하고 있을 때 몇 명이 그 물건을 사용 중인지 숫자로 세어보는 것과 비슷합니다.\n\n**작동 원리**\n1. Python에서 어떤 데이터를 저장하는 객체(list, dictionary, etc)가 만들어지면 이 객체를 사용하고 있는 변수가 몇 개인지 기록합니다.\n2. 만약 변수가 그 객체를 사용하면 숫자가 1 증가하고, 더 이상 사용하지 않게 되면 숫자가 1 감소합니다.\n3. 이 **참조 카운트가 0**이 되면 그 객체는 아무도 사용하지 않는 것으로 판단되어 청소부가 그 객체를 메모리에서 제거합니다.\n```python\na = [1, 2, 3]    # 리스트 객체 생성 (참조 카운트 증가)\n\nb = a            # b가 a를 참조 (참조 카운트 증가)\n\ndel b            # b 삭제 (참조 카운트 감소)\n```\n### 2. 순환 가비지 컬렉터 (Cyclic Garbage Collector)\n때로는 두 개 이상의 객체가 서로를 참조하면서 **서로를 잡아먹는** 상황이 생깁니다. 예를 들어, A가 B를, B가 A를 참조하고 있으면 외부에서는 둘 다 사용하지 않더라도 참조 카운트가 0이 되지 않습니다.\n\n```python\nclass A:\n    def __init__(self):\n        self.other = None\n\n# 두 객체 생성 후 서로를 참조하게 만듭니다.\na = A()\nb = A()\na.other = b  # a는 b를 참조\nb.other = a  # b는 a를 참조\n\n# 외부 참조 제거\na = None\nb = None\n\n# 이제 두 객체는 외부에서 접근할 수 없지만 서로를 참조하므로 참조 카운트는 0이 되지 않습니다.\n```\nPython은 이러한 순환 참조 문제를 해결하기 위해 정기적으로 청소를 하는 **순환 가비지 컬렉터** 시스템을 사용합니다. 이 시스템은 주기적으로 객체 그래프를 탐색하여, **외부에서는 접근할 수 없지만 내부적으로 서로 참조하는 객체들**을 찾아냅니다.\n#### 세대 개념\n객체는 **얼마나 오래 살아남았느냐**에 따라 몇 개의 세대로 분류됩니다. 최근에 생성된 객체는 0세대, 조금 오래된 객체는 1세대, 가장 오래된 객체는 2세대로 분류됩니다.\n\n이렇게 세대를 구분하는 이유는 대부분의 객체가 짧은 수명을 가지고 있고, 오래 살아남은 객체는 변경 가능성이 낮다고 판단하여 더 자주 검사하지 않음으로써 가비지 컬렉션 오버헤드를 줄이기 위함입니다.\n\n### 고려 사항\n한 객체를 참조하는 수가 많을 경우 **참조 카운트를 업데이트하는 오버헤드**가 발생할 수 있습니다. 객체에 대한 참조를 추가하거나 제거할 때마다 메모리 내에서 해당 값을 읽고, 수정하고, 다시 저장하는 작업이 필요합니다. \n이런 연산이 반복되면 단순히 그 객체를 사용하거나 해제하는 비용 외에도 참조 카운트 업데이트에 따른 부가적인 CPU 연산 비용이 누적될 수 있습니다.\n\n예를 들어, 수천 개의 복잡한 데이터 구조에서 한 객체가 여러 부분에서 참조될 경우, 참조 카운트 관리에 드는 시간이 전체 성능에 영향을 줄 수 있습니다.\n\nOS는 새로운 메모리 블록을 할당하거나, 사용이 끝난 메모리 블록을 해제할 때 **시스템 호출**을 사용합니다. 이러한 호출은 사용자 코드에서 직접 호출하는 연산보다 훨씬 느리고 오버헤드가 큽니다.\n\n\n또한, 메모리 할당/해제를 반복하면 메모리 내부에 작고 산발적인 빈 공간들이 생기는데, 이를 **메모리 단편화**(Fragmentation)라고 합니다. 단편화가 심해지면 **메모리 사용 효율이 떨어지고 큰 연속된 메모리 공간을 할당받기 어려워집니다**.\n\n\n이와 같이 메모리 할당 및 해제는 비용이 크므로 Python은 **메모리 풀**과 같은 기법을 통해 메모리를 재활용합니다. 메모리 풀은 **미리 일정 크기의 메모리 블록들을 할당해 놓고 필요할 때마다 이 블록들을 재활용**하는 방식입니다.\n\n예를 들어, CPython은 짧은 문자열이나 작은 리스트와 같은 소형 객체를 위한 전용 메모리 할당기를 사용합니다. 이 풀은 **한 번에 시스템으로부터 큰 메모리 블록**을 받아 내부에서 작고 고정된 크기의 블록들로 나눈 후, 객체 생성 시 이 블록들을 할당합니다.\n\n이 방식을 사용하면 새로운 객체를 만들 때마다 OS에 매번 메모리 할당 요청을 보내지 않아도 되므로 **매우 빠르게 메모리를 할당**할 수 있습니다. 객체가 해제되면 해당 메모리 블록은 즉시 운영체제에 반환되지 않고 **메모리 풀에 다시 저장**되어 다음에 **재사용**됩니다.\n\n\n만약 현재 **할당된 메모리 풀이 모두 사용중**이라면:\n1. Python의 메모리 할당기는 OS에 추가 메모리를 요청합니다.\n2. 운영체제에서 추가 메모리를 제공하면 메모리 풀은 확장되어 이후에 새로운 객체 할당에 사용됩니다.\n3. 만약 운영체제에서 더 이상 메모리를 제공할 수 없다면 Python은 더 이상 객체를 위한 메모리를 할당할 수 없게 됩니다. (`MemoryError` Exception 발생)\n\n메모리 풀 확장 시 여러 프로세스가 동시에 메모리를 요구할 수 있고 이런 상황에서는 경쟁이 발생할 수도 있습니다.\n\n## 마무리\n오늘은 파이썬에서 가비지 컬렉션이 어떻게 동작하는지 알아보았습니다. 다음엔 네트워크 관련 게시글을 올려보도록 하겠습니다. 감사합니다 :)\n"},{slug:"system-design/messaging-service",categorySlug:"system-design",title:{ko:"메시징 서비스 시스템 디자인",en:"Design Messaging Service"},date:"2025-02-20",category:{ko:"시스템 디자인",en:"System Design"},description:{ko:"대규모 메시징 서비스 설계",en:"Let's design messaging service"},content:'\n`Togather` 프로젝트 (북미 대학생을 위한 익명 커뮤니티 앱) 를 만들면서 자연스럽게 커뮤니티 플랫폼과 채팅 서비스의 시스템 디자인에 대해 관심을 갖게 되었습니다.\n\n이번 글에서는 대규모 사용자를 대상으로 한 채팅 서비스의 시스템 디자인에 대해 살펴보겠습니다.\n\n## 기능적 요구사항\n1. **그룹 채팅 지원** – 여러 명이 함께 대화할 수 있는 그룹 메시지 기능이 필요함.\n2. **메시지 송수신 기능** – 사용자가 메시지를 보내고 받을 수 있어야 함.\n3. **오프라인 수신 가능** – 사용자가 오프라인 상태일 때도 메시지를 받을 수 있어야 하며, 다시 온라인이 되면 확인할 수 있어야 함.\n4. **사진 및 미디어 전송 지원** – 텍스트뿐만 아니라 사진, 동영상 등 미디어 파일도 주고받을 수 있어야 함.\n\n## 비기능적 요구사항\n1. **빠른 메시지 전달 속도** – 온라인 상태인 사용자는 500ms(0.5초) 이내에 메시지를 받아야 함.\n2. **메시지 전달 보장** – 메시지가 유실되지 않고 반드시 수신자에게 전달되어야 함.\n3. **확장성** – 수십억 명의 사용자가 이용해도 원활하게 동작해야 함.\n4. **필요한 메시지만 저장** – 메시지는 필요한 만큼만 보관하고, 불필요한 데이터는 자동으로 삭제되도록 관리해야 함.\n5. **안정성 보장** – 특정 서버나 기능이 고장 나더라도 전체 서비스가 중단되지 않도록 시스템이 복구 및 대응할 수 있어야 함.\n## Core entities\n- Users\n- Chats\n- Messages\n- Clients (devices)\n## API 디자인\n메시지가 매우 자주 주고받아지는 환경에서는 매번 요청을 보내고 응답을 받는 REST API 방식은 비효율적입니다. REST API는 요청이 올 때마다 새로운 연결을 만들고, 응답을 받은 후 연결을 종료하기 때문에 실시간성이 중요한 서비스에서는 지연이 발생할 수 있습니다.\n\n반면, 양방향 소켓 연결 (bi-directional socket connection) 은 한 번 연결을 설정하면 계속 유지되므로 서버와 클라이언트가 실시간으로 데이터를 주고받을 수 있습니다. \n예를 들어, 채팅 서비스에서는 사용자가 메시지를 보내면 서버가 즉시 상대방에게 전달해야 하는데 소켓 연결을 사용하면 별도의 요청 없이도 빠르게 메시지를 받을 수 있습니다.\n\n\n즉, 자주 변하는 데이터를 실시간으로 주고받아야 하는 서비스에서는 REST API보다 소켓 연결이 훨씬 효율적입니다.\n\n### 전송되는 명령\n#### Create Chat: 대화방 생성\n**Request**\n```json\n{\n    "participants": ["user1", "user2"],\n    "name": "Study Group"\n}\n```\n\n#### Send Message: 메시지 전송\n**Request**\n```json\n{\n    "chatId": 1,\n    "message": "hi",\n    "attachments": ["sampleFile"]\n}\n```\n\n#### Create Attachment: 첨부파일 생성\n**Request**\n```json\n{\n    "body": ...,\n    "hash": ""\n}\n```\n\n#### Modify Chat Participants, 대화방 인원 수정\n**Request**\n```json\n{\n    "chatId": 1,\n    "userId": 1,\n    "operation": "ADD" | "REMOVE"\n}\n```\n위에 나열한 각 요청은 다른 클라이언트들에게도 동시에 전송됩니다. 클라이언트가 요청을 받으면 서버에 `"명령을 정상적으로 받았다"`는 ACK (확인 응답) 메시지를 보냅니다.\n\n이렇게 하면 서버는 `"이제 이 메시지를 다시 보낼 필요가 없겠구나"` 하고 확인합니다. (만약 ACK을 받지 못하면 서버는 메시지가 제대로 전달되지 않았다고 판단하고 다시 보낼 수도 있습니다.)\n\n\n### 수신되는 명령\n#### New Message, 새로운 메시지 수신\n**Request**\n```json\n{\n    "chatId": 1,\n    "userId": 1\n    "message": "hi",\n    "attachments": []\n}\n```\n\n#### Chat Update, 대화방 업데이트\n**Request**\n```json\n{\n    "chatId": 1,\n    "participants": ["user1"],\n}\n```\n\n## High-Level Design\n### 1. 그룹 채팅 지원: 최대 100명\n```plaintext\n+-----------+   (WebSocket Conn)    +---------+      +-------------+      +--------------------+\n|  Client   | --------------------> |  L4 LB  | ---> | Chat Server | ---> | Database (DynamoDB) |\n+-----------+                       +---------+      +-------------+      +--------------------+\n```\n\n#### 플로우\n1. 사용자가 서비스에 연결한 후 createChat 요청을 보냅니다.\n2. 서버는 한 트랜잭션 내에서 새로운 채팅방(Chat) 데이터를 생성하고, 해당 채팅방의 참여자(ChatParticipant) 정보도 함께 저장합니다.\n3. 채팅방이 성공적으로 생성되면 서버는 생성된 chatId를 사용자에게 반환합니다.\n\n#### 사용 기술\n- **L4(4계층) 로드밸런서**: 웹소켓 연결을 지원하며 실시간 통신이 필요한 메시징 서비스에 적합합니다.\n- **AWS DynamoDB**: 채팅방 생성 시 관련 데이터(참여자 정보, 생성 시간 등)를 저장하기 위해 사용됩니다. 빠른 Key-Value 성능과 뛰어난 확장성(Scalability) 을 제공하여 대규모 사용자 환경에서도 안정적으로 동작합니다.\n\n여기서 다른 데이터베이스가 아닌 `AWS DynamoDB`를 사용하는 이유는 다음과 같습니다.\n- **확장성**: 자동으로 수평 확장 되므로 사용자가 많이 늘어나는 상황에서도 안정적으로 동작합니다. RDBMS는 일정 규모가 넘어가면 샤딩을 직접 관리해야 하는데, DynamoDB는 이를 자동으로 처리해줍니다. 같은 NoSQL 데이터베이스인 MongoDB와 같은 경우에도 수평 확장이 가능하지만, 샤딩과 클러스터 관리를 직접 해야합니다.\n- **Low latency**: key-value 기반이라 초당 수백만건의 요청을 빠르게 처리할 수 있습니다. 지연 시간을 최소화 하기 좋습니다. 쿼리 기능은 제한적이지만 Composite key와 GSI를 이용해 특정 조회 패턴을 빠르게 지원합니다.\n- **비용 효율성**: 온디맨드 모델을 사용하면 실제 사용한 만큼만 비용을 지불합니다. 고성능 환경에서 RDBMS를 유지하려면 서버 증설 등에 비용이 크게 늘어날 수 있습니다.\n\n#### DB Index 설계: `ChatParticipant` 테이블\n`ChatParticipant` 테이블은 다음과 같은 두 가지 기능을 지원해야 합니다.\n1. 특정 채팅방에 참여한 모든 사용자 조회\n2. 특정 사용자가 참여 중인 모든 채팅방 조회\n\n이를 위해, DynamoDB의 `Composite primary key`와 `GSI(Global Secondary Indexes)`를 활용해야 합니다.\nDynamoDB는 테이블을 만들 때 기본 키로 설정되는 두 가지 유형의 Primary key를 지원하는데, 단일 partition key (우리가 아는 기본 primary key), composite key (partition key + sort key) 로 나누어져 있습니다.\n\nDynamoDB의 composite key는 partition key + sort key 조합으로 테이블을 구성하는 방식인데, 같은 Partition key 값을 가진 여러 개의 데이터를 저장할 수 있습니다. Partition key로 데이터를 그룹화하고 Sort key로 정렬하는 방식입니다.\n\n\n우리가 `chatId`를 **Partition Key**, `participantId`를 **Sort Key**로 설정하면 특정 채팅방(`chatId`)에 속한 모든 사용자를 손쉽게 조회할 수 있습니다. 하지만 **"특정 사용자가 속한 모든 채팅방을 알고 싶다"** 라는 쿼리를 실행하려면 `participantId`를 기준으로 검색해야 합니다. 이를 가능하게 하기 위해 **GSI(Global Secondary Index)** 를 추가해야 합니다.\n**GSI**는 DynamoDB에서 테이블 생성 후 추가 가능한 추가적인 조회 패턴을 지원하기 위해 사용되는 인덱스입니다. 여기서 Partition key를 `participantId`로, sort key를 `chatId`로 설정하면 특정 유저가 참여한 모든 채팅방을 효율적으로 조회할 수 있습니다.\n\nGSI가 **"Global"한 이유**는 **기본 테이블의 Partition Key와 상관없이 전역적으로 데이터를 검색할 수 있기 때문**입니다. 반면, **LSI(Local Secondary Index)** 는 특정 Partition 내부에서만 작동하므로 예를 들어 특정 채팅방 내에서 가장 최근 메시지를 검색할 때(`chatId -> timestamp`) LSI를 활용할 수 있습니다.\n\n**요약**\n1. Composite Primary Key(`chatId` + `participantId`)를 사용하면 특정 `chatId`에 속한 모든 사용자를 빠르게 조회할 수 있습니다.\n2. GSI(`participantId` + `chatId`)를 추가하면 특정 사용자가 속한 모든 채팅방을 효율적으로 검색할 수 있습니다.\n\n### 2. 메시지 송수신 기능\n우선 문제를 단순화하기 위해 **서버가 하나만 존재한다고 가정**해보겠습니다. 또한, 앞서 언급한 것처럼 **웹소켓(WebSocket) 연결을 사용하여 실시간 메시지를 주고받도록 설계**합니다.\n\n\n유저가 채팅 서버에 웹소켓을 통해 연결하면 **서버는 해당 유저의 연결 정보를 해시맵(HashMap)에 저장**합니다. 이렇게 하면 **현재 어떤 유저가 서버에 연결되어 있는지 파악할 수 있으며, 연결된 유저에게 메시지를 직접 전달**할 수 있습니다.\n\n#### 메시지 송신 플로우 (1차 버전)\n1. 유저가 `sendMessage` 요청을 서버에 보냅니다.  \n2. 서버는 데이터베이스의 `ChatParticipant` 테이블을 조회하여 **해당 채팅방에 속한 모든 참여자 목록을 가져옵니다.**  \n3. 서버는 **내부 해시맵을 확인하여 현재 웹소켓 연결이 활성화된 유저들에게만 메시지를 전송합니다.**  \n\n이 방식에서는 다음과 같은 **제약 사항**이 존재합니다.  \n- 모든 유저가 웹소켓 연결 상태여야만 메시지를 받을 수 있음\n- 유저가 반드시 같은 서버에 연결되어 있어야 함\n- 각 유저마다 웹소켓을 유지하고 관리해야 함\n\n위에서 언급한 제약 사항들은 이후 섹션에서 해결 방법을 다룰 예정입니다.  \n### 3. 오프라인 수신 기능 (최대 30일)\n오프라인 수신 기능을 만들기 위해 앞에서 가정했던 일부 조건들을 다시 생각해보겠습니다. 오프라인 상태인 유저에게 메시지를 전달하려면 메시지를 데이터베이스에 저장해야 할 필요가 생깁니다.\n\n각 유저별로 **메시지 수신함**을 만들고 여기에 **아직 전달되지 않은 메시지들을 저장**하는 방식으로 설계해보겠습니다.\n메시지가 전송되면 **수신자의 수신함에 메시지를 저장**하고, 만약 수신자가 온라인 상태라면 메시지 즉시 전달을 시도합니다. 만일 유저가 오프라인 상태라면 메시지를 저장한 후 나중에 다시 접속했을 때 전달하도록 하겠습니다.\n#### 메시지 송신 플로우 (2차 버전)\n1. 유저가 `sendMessage` 요청을 서버에 보냅니다.  \n2. 서버는 데이터베이스의 `ChatParticipant` 테이블을 조회하여 **해당 채팅방에 속한 모든 참여자 목록을 가져옵니다.**  \n3. 서버는 한 트랜잭션 내에서 (1) `Message` 테이블에 메시지를 저장하고, (2) 채팅방의 각 참여자의 `Inbox`에 해당 메시지 정보를 저장합니다.\n4. 서버는 클라이언트에게 **성공/실패 응답 + `messageId`** 를 반환합니다.  \n5. 서버는 **웹소켓 연결 정보 해시맵**을 확인하여 현재 온라인 상태인 수신자에게 `newMessage` 명령을 통해 메시지를 즉시 전달합니다.  \n6. **연결된 수신자**는 메시지를 받은 후, **`ack` 메시지를 서버에 반환**합니다. 서버는 `Inbox` 테이블에서 해당 유저에게 전달된 메시지를 삭제하여 중복 전송을 방지합니다.\n\n#### 연결되지 않은 수신자 플로우\n오프라인 상태였던 유저가 다시 서버에 연결되었을 때, 이전까지 전달되지 않았던 메시지를 정상적으로 받을 수 있도록 처리해야 합니다.\n1. 수신자가 서버에 연결되면 **서버는 해당 유저의 `Inbox` 테이블을 조회하여 아직 남아있는 메시지 ID 목록을 가져옵니다.**  \n2. 각 `messageId` 에 해당하는 메시지를 `Message` 테이블에서 조회합니다.  \n3. 온라인 상태인 수신자에게 `newMessage` 명령을 통해 메시지들을 전달합니다.\n4. **연결된 수신자**는 메시지를 받은 후, **`ack` 메시지를 서버에 반환**합니다. 서버는 `Inbox` 테이블에서 해당 유저에게 전달된 메시지를 삭제하여 중복 전송을 방지합니다.\n\n마지막으로, **간단한 Cron Job을 활용하여 30일 이상 전달되지 않은 `Inbox` 메시지를 정리(cleanup)** 할 수 있습니다. \n### 4. 사진 및 미디어 전송 기능\n이상적인 접근 방식은 **사용자가 직접 Blob Storage(예: AWS S3, GCS)에 업로드할 수 있도록 권한을 부여하는 것**입니다.  \n이를 위해 **Pre-Signed URL**을 활용하면 채팅 서버를 거치지 않고도 사용자가 직접 파일을 업로드할 수 있습니다. 이 방식은 제가 `Togather` 프로젝트에서 사용자가 게시글을 올릴 때 미디어를 첨부하는 과정에서도 적용했던 방식입니다.\n\n#### 파일 업로드 플로우\n1. 사용자가 `getAttachmentTarget` 요청을 **Chat Server**에 보냅니다.  \n2. **Chat Server**는 **Pre-Signed URL**을 생성하여 사용자에게 반환합니다.  \n3. 사용자는 이 **Pre-Signed URL**을 이용해 **Blob Storage에 직접 파일을 업로드**합니다.  \n4. 업로드가 완료되면 사용자는 **업로드된 파일의 URL을 Chat Server에 전달**하여 메시지와 함께 저장합니다.  \n\n#### 파일 다운로드 플로우\n1. 사용자가 특정 첨부 파일을 다운로드하려고 하면 서버에 Pre-Signed URL을 요청합니다.  \n2. **Chat Server**는 Blob Storage에서 해당 파일에 접근할 수 있는 **Pre-Signed URL을 반환**합니다.  \n3. 사용자는 **해당 URL을 통해 직접 Blob Storage에서 파일을 다운로드**합니다.  \n\n이상적으로는 모든 수신자가 파일을 다운로드한 후 자동 삭제하는 것이 가장 효율적이므로, 메시지 전송 후 수신자가 다운로드 했는지 확인하는 로직이 필요합니다. 또한 파일을 일정 기간 이후 자동 삭제하는 정책을 적용시킬 수도 있습니다.\n## 상세 설계\n### 1. 수십억 명의 유저가 동시 접속할 경우 어떻게 처리할 것인가?\n위에서는 단일 서버를 가정했지만, **단일 서버로 수십억 명의 유저를 처리하는 것은 현실적으로 불가능**합니다.  \n가장 직관적인 해결 방법은 **서버를 늘려서 트래픽을 분산하는 것(수평 확장, Horizontal Scaling)** 입니다.  \n\n예를 들어, **전 세계적으로 10억 명의 유저가 있다면 2억 명이 동시 접속하는 것도 충분히 가능한 시나리오**입니다.  \n그러나 단순히 서버를 늘리는 것만으로는 해결되지 않는 문제들도 존재합니다.  \n\n먼저, **유저가 서로 다른 서버에 연결될 경우 메시지 전송이 불가능**해집니다. 예를 들어, A 유저가 서버 1에 연결되어 있고, B 유저가 서버 2에 연결되어 있다면 두 유저 간 메시지를 주고받기 위해서는 서버 간의 데이터 동기화가 필요해집니다.\n\n이 문제를 해결하기 위해 **Redis Pub/Sub과 같은 메시지 브로커 시스템을 활용**할 수 있습니다.  \nRedis는 **가벼운 해시맵(HashMap) 기반의 소켓 연결 관리 기능을 제공하여 메시지를 빠르게 라우팅**할 수 있습니다. \n \n#### Redis Pub/Sub 기반 메시지 전달 플로우\n**메시지를 받을 때**\n1. 사용자가 서버에 웹소켓을 연결합니다.\n2. 서버는 Redis Pub/Sub에서 해당 유저 ID를 구독 (subscribe) 합니다.\n3. 이후, 해당 유저에게 전달되는 메시지는 **구독된 Pub/Sub 채널을 통해 서버로 전달**됩니다.\n4. 서버는 받은 메시지를 웹소켓을 통해 유저에게 전달합니다.\n\n**메시지를 보낼 때**\n1. 송신자가 메시지를 보내면 **서버는 수신자의 Pub/Sub 채널에 메시지를 Publish**합니다.  \n2. 해당 메시지는 **수신자를 구독(Subscribe) 중인 모든 서버에서 수신**됩니다.  \n3. 각 서버는 **수신자가 현재 연결된 상태인지 확인하고, 연결된 경우 웹소켓을 통해 메시지를 전달**합니다.  \n\n여기서 Redis Pub/Sub의 한계도 존재합니다. Redis Pub/Sub은 **"At most once"** 전송 방식을 가지고 있는데, **구독자가 없을 경우 메시지는 손실**될 수 있습니다.\n\n하지만, 우리는 이미 `Inbox` 테이블을 통해 메시지 내구성을 보장하고 있기 때문에 문제가 되지 않습니다.\n\n그러나 수십억 명의 유저를 감당하려면 Redis Pub/Sub 자체도 확장 가능하게 설계해야 합니다.\nRedis는 클러스터 모드(Redis Cluster)를 지원하지만, Pub/Sub 자체는 기본적으로 클러스터 샤딩을 지원하지 않습니다. 즉, 단순히 Redis Cluster를 활성화한다고 해서 Pub/Sub 메시지가 자동으로 여러 노드에 분산되지 않습니다.\n\n따라서, **수동으로 유저 ID를 기준으로 특정 Redis 노드에 Pub/Sub 메시지를 라우팅하는 방식**을 적용해야 합니다.\n\n#### Redis Cluster 기반 샤딩 적용 플로우\nRedis Cluster는 데이터를 **키(Key) 값에 따라 여러 노드(Shard)로 분산 저장**하는 기능을 제공합니다.  \n이러한 방식은 **Consistent Hashing**을 활용하여 **유저 ID를 기준으로 항상 동일한 노드에서 Pub/Sub 메시지를 처리할 수 있도록 보장**합니다.  \n\n1. **유저 ID를 기반으로 특정 Redis 노드(Shard)를 할당**합니다. (Consistent Hashing 사용)  \n2. 각 서버는 **특정 Redis 노드에서만 Pub/Sub 메시지를 Publish & Subscribe** 합니다.  \n3. **메시지를 보내는 서버가 수신자의 Redis 노드를 찾아 Publish** 합니다.  \n4. 수신자가 연결된 서버는 해당 Redis 노드에서 구독(Subscribe)한 후, 메시지를 전달합니다.  \n\n### 2. 다중 기기 지원 문제\n지금까지는 유저가 하나의 기기만 사용한다고 가정했습니다. 그러나 현실적으로 대부분의 유저는 여러 기기를 사용합니다.\n\n예를 들어, 내 휴대폰에서는 메시지를 받았지만 노트북이 꺼져있었다면 노트북을 켰을 때 **누락된 메시지를 받아서 최신 상태로 동기화** 할 수 있어야 합니다. \n하지만 기존 **유저 단위로 메시지 전달을 추적**하는 `Inbox` 테이블 만으로는 이를 해결할 수 없습니다.\n\n다중 기기 지원 시, 고려해야할 사항은 다음과 같습니다.\n- 유저가 사용하는 모든 기기를 추적해야 합니다. 또한, 유저가 로그인하면 현재 활성화된 모든 기기를 관리할 방법이 필요합니다.\n- 더 이상 사용되지 않는 기기를 자동으로 비활성화 해야합니다.\n- 기기별로 메시지 전송을 관리해야합니다.\n\n이를 해결하기 위해 기존 설계를 최대한 변경하지 않고 방법을 찾아보겠습니다.\n#### 1. `Clients` 테이블 추가 (유저별 활성화된 기기 추적)\n| **userId** | **clientId (device identifier)** | **lastActive** |\n|-----------|-----------------------------------|----------------|\n| user123   | phone_abc                         | 2025-02-20     |\n| user123   | laptop_xyz                        | 2025-02-19     |\n| user456   | tablet_def                        | 2025-02-18     |\n\n#### 2. `Inbox` 테이블을 유저 단위가 아닌 "기기 단위"로 변경\n각 기기가 개별적으로 메시지를 관리할 수 있으므로 기기 간 메시지 동기화 문제를 해결할 수 있고, 기기가 오프라인 상태였다가 다시 연결되었을 때 `Inbox` 테이블을 조회하여 전과 같은 방식으로 최신 메시지들을 받을 수 있습니다.\n\n**변경 전 (유저 단위 Inbox)**\n| **userId** | **messageId** | **status**  |\n|-----------|-------------|----------|\n| user123   | msg_001     | pending  |\n| user123   | msg_002     | pending  |\n\n**변경 후 (기기 단위 Inbox)**\n| **clientId** | **messageId** | **status**  |\n|--------------|---------------|-------------|\n| phone_abc    | msg_001       | pending     |\n| laptop_xyz   | msg_001       | pending     |\n| phone_abc    | msg_002       | pending     |\n| laptop_xyz   | msg_002       | pending     |\n\n#### 3. Pub/Sub 구독 방식 변경\n기존에는 유저 ID 기준으로 서버가 Pub/Sub을 구독했지만 이제는 기기 ID 기준으로 구독하도록 변경합니다.\n또한, 기존에는 **유저 ID**를 기준으로 메시지를 보냈지만 이제는 **유저의 활성화된 모든 기기(Client)를 조회하여 각각 메시지를 전송**해야 합니다.\n\n**메시지를 보낼 때**  \n1. 송신자가 메시지를 보냅니다.\n2. 서버는 **수신자의 `Clients` 테이블을 조회하여 활성화된 기기 목록**을 가져옵니다. \n3. **각 기기의 Pub/Sub 채널에 메시지를 Publish** 합니다.  \n4. 해당 기기에 연결된 Chat Server가 메시지를 받아 웹소켓을 통해 전달합니다.  \n5. **각 기기가 메시지를 받은 후 `ack`를 반환하면, 해당 기기의 `Inbox`에서 메시지를 삭제**합니다.  \n\n## 마무리\n오늘은 위와 같이 대규모 사용자를 대상으로 한 채팅 서비스를 디자인 해보았습니다. 다음 번엔 대규모 사용자를 위한 게시판 서비스를 디자인 해보겠습니다. 감사합니다.\n\n### Reference\n- https://redis.io/docs/latest/develop/interact/pubsub/\n- https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-indexes-general.html\n- https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GSI.html\n- https://youtu.be/cr6p0n0N-VA\n'},{slug:"computer-networks/intro-to-internet-architecture",categorySlug:"computer-networks",title:{ko:"인터넷 아키텍쳐 개요",en:"Introduction to Internet Architecture"},date:"2025-02-22",category:{ko:"컴퓨터 네트워크",en:"Computer Networks"},description:{ko:"인터넷 아키텍쳐와 OSI 7계층에 대한 간단한 설명",en:"Intro to internet architecture and OSI 7 layers"},content:"\n## 개요\n인터넷 아키텍쳐는 **서로 다른 네트워크에 위치한 동일한 애플리케이션을 실행하는 호스트를 연결**할 수 있도록 해줍니다. \n컴퓨터 네트워크는 여러 구성 요소로 이루어진 복잡한 시스템이며 다양한 기술을 기반으로 합니다. \n즉, 서로 다른 유형의 네트워크로 구성될 수 있고, 다양한 애플리케이션을 호스팅할 수도 있습니다.\n\n예를 들어, 두 개의 이메일 클라이언트는 **서로 다른 네트워크(Wifi vs. ethernet 케이블)를 사용하면서도 정상적으로 통신**할 수 있습니다. \n그렇다면 이렇게 다양한 기술과 구성 요소들이 어떻게 하나로 연결되어 각 애플리케이션이 필요한 기능을 수행할 수 있을까요?\n\n네트워크 프로토콜을 설계하는 과정에서, 이런 복잡한 시스템을 보다 체계적으로 만들기 위해 **계층(layer)** 개념이 도입되었습니다.\n\n### 계층\n**네트워크 아키텍쳐에서는 기능을 여러 계층으로 나누어 구현**합니다. 각 계층은 특정 기능을 담당하며, 아래 계층에서 제공하는 서비스를 기반으로 동작합니다.\n또한, 상위 계층이 원활하게 동작할 수 있도록 필요한 서비스를 제공합니다.\n\n항공 시스템으로 비유를 해보겠습니다.\n1. 승객은 티켓을 구매하고, 수하물을 맡기고, 공항 게이트를 통과합니다.\n2. 비행기가 출발하면 탑승한 승객은 목적지까지 이동합니다.\n3. 도착지에서는 비행기에서 내려 게이트를 통과한 후, 수하물을 찾고 공항을 나갑니다.\n\n이 과정에서 각 단계는 특정한 역할을 수행하고, 이전 단계에서 제공한 서비스를 기반으로 운영됩니다. 즉, **한 단계가 끝나야 다음단계가 진행**될 수 있습니다.\n\n네트워크 아키텍쳐에서도 동일한 원리가 적용됩니다. 각 계층은 특정 기능을 수행하고, 모두 연결되어 네트워크가 정상적으로 동작하도록 합니다.\n\n#### 계층 구조의 장점\n1. 확장성: 새로운 기술이나 기능을 쉽게 추가할 수 있습니다.\n2. 모듈성: 각 기능이 독립적으로 설계되어 유지보수가 편리합니다.\n3. 유연성: 특정 계층을 수정하거나 교체하더라도 전체 시스템에 큰 영향을 미치지 않습니다.\n\n위와 같은 이유로 인터넷 아키텍쳐는 계층적인 구조를 기반으로 설계되었고, 효율적이고 비용친화적인 네트워크 구현이 가능합니다.\n\n이렇게 기능을 계층별로 분리하는 것은 분명 여러 장점을 제공하지만, 몇 가지 단점도 존재합니다.\n\n#### 계층 구조의 단점\n1. 계층 간 종속성: 일부 계층의 기능이 다른 계층의 정보를 필요로 하는 경우, 계층 구분의 원칙이 어긋날 수 있습니다.\n2. 중복된 기능: 오류 복구와 같은 특정 기능이 하위/상위 계층에서 중복으로 구현될 수 있습니다.\n3. 추가적인 오버헤드: 계층 간의 추상화로 인해 성능 저하 및 불필요한 데이터 처리가 발생할 수 있습니다.\n\n## OSI 7계층 모델\n국제 표준화 기구(ISO)는 네트워크 통신을 구조화하기 위해 아래와 같은 모델을 제안했습니다.\n| 계층 |\n|-----------|\n| 애플리케이션 계층 (Application Layer)   |\n| 프레젠테이션 계층 (Presentation Layer)  |\n| 세션 계층 (Session Layer)   |\n| 전송 계층 (Transport Layer)  |\n| 네트워크 계층 (Network Layer)  |\n| 데이터 링크 계층 (Data Link Layer)  |\n| 물리 계층 (Physical Layer)  |\n\n### 7계층: 애플리케이션 계층 (Application Layer)\n애플리케이션 계층은 다양한 **애플리케이션을 지원하는 여러 프로토콜을 포함**합니다. 대표적인 프로토콜은 다음과 같습니다.\n- HTTP (HyperText Transfer Protocol): 웹페이지 요청 및 전송\n- SMTP (Simple Mail Transfer Protocol): 이메일 송수신\n- FTP (File Transfer Protocol): 파일 전송\n- DNS (Domain Name System): 도메인 이름을 IP 주소로 변환\n\n애플리케이션 계층에서는 구현된 애플리케이션에 따라 다양한 서비스를 제공하고, 이 계층을 이용하는 인터페이스와 사용되는 프로토콜도 애플리케이션에 따라 달라집니다.\n\n**애플리케이션 계층에서는 데이터를 `메시지 (Message)`라고 부릅니다.**\n\n### 6계층: 프레젠테이션 계층 (Presentation Layer)\n프레젠테이션 계층은 **데이터 형식을 변환하는 역할**을 하며, 하위 계층에서 받은 정보를 애플리케이션 계층이 이해할 수 있도록 변환합니다.\n\n예를 들어, 비디오 스트림을 특정 형식으로 변환하거나 숫자 데이터를 big endian에서 little endian으로 변환하는 것 등이 있습니다.\n\n### 5계층: 세션 계층 (Session Layer)\n세션 계층은 애플리케이션 간의 세션을 관리하는 역할을 합니다. **동일한 애플리케이션 프로세스에서 여러 개의 전송 스트림이 존재할 경우, 이를 하나의 세션으로 묶어 관리**합니다.\n\n예를 들어, 화상 회의 애플리케이션에서 오디오 스트림과 비디오 스트림을 동기화하여 올바르게 전달하도록 합니다. 세션 계층이 있어야 오디오와 비디오가 일관되게 전달되고 하나의 통합된 세션으로 유지될 수 있습니다.\n\n### 4계층: 전송 계층 (Transport Layer)\n전송 계층은 **호스트 간(end-to-end) 통신**을 담당하는 계층으로, 두 가지 주요 프로토콜이 사용됩니다.\n\n#### 1. TCP (Transmission Control Protocol)\n- 연결 지향적 서비스 (Connection-oriented service)\n- 애플리케이션 계층 메시지의 신뢰성 보장 (**Guaranteed delivery**)\n- 흐름 제어 (**Flow control**): 송신자와 수신자의 속도 조정\n- 혼잡 제어 (**Congestion control**): 네트워크 혼잡이 감지되면 송신 속도 조절\n#### 2. UDP (User Datagram Protocol)\n- 연결 없는 **connectionless** 서비스\n- **Best-effort 전송**: 신뢰성, 흐름 제어, 혼잡 제어가 없음\n- 실시간 스트리밍, VoIP, 온라인 게임 등 **속도가 중요한 애플리케이션**에서 주로 사용\n\n즉, 이 계층은 데이터가 중간에 손실되거나 순서가 뒤바뀌지 않도록 관리하여 최종 사용자에게 올바른 정보를 전달합니다.\n**전송 계층에서는 데이터를 `세그먼트 (Segment)`라고 부릅니다.**\n\n### 3계층: 네트워크 계층 (Network Layer)\n네트워크 계층의 역할은 **호스트 간 데이터그램(Datagram) 전달**입니다. 라우팅 프로토콜을 통해 최적의 경로를 선택하고, 그 경로를 통해 데이터를 전달합니다.\n\n**데이터 전달 과정**\n1. **전송 계층 → 네트워크 계층 전달**: 먼저, 송신 호스트의 4계층인 전송 계층에서 생성된 데이터를 네트워크 계층으로 넘깁니다. 이 데이터는 아직 `세그먼트` 형태로 존재합니다.\n2. **데이터그램 변환 및 라우팅**: 네트워크 계층은 받은 세그먼트를 **데이터그램으로 변환**합니다. 이때, 각 데이터그램에는 데이터의 목적지 주소, 출발지 주소 등 필요한 정보가 포함됩니다. 이 정보들을 바탕으로 데이터그램이 목적지에 도착할 수 있도록 **최적의 경로를 찾아 여러 라우터를 거쳐 전송**합니다.\n3. **목적지 도착 및 재구성**: 최종적으로 데이터그램들은 목적지 호스트에 도착하면 다시 모여 **원래의 세그먼트 형태로 재구성**되고, 이후 4계층인 전송 계층으로 전달되어 최종 데이터로 사용됩니다.\n\n**핵심 프로토콜**\n- **IP (Internet Protocol)**\n  - 인터넷의 핵심 프로토콜, 모든 인터넷 호스트 및 네트워크 장치는 IP 프로토콜을 실행해야 함\n  - 데이터그램의 **헤더 구조 및 주소 지정 방식 정의**\n  - 출발지와 목적지 간 패킷 전송 지원\n- **라우팅 프로토콜 (Routing Protocol)**\n  - 데이터그램이 송신지에서 목적지까지 **어떤 경로를 따라 이동할지 결정**\n  - EX) OSPF, BGP, RIP\n\n**네트워크 계층에서는 데이터를 `데이터그램 (Datagram)`이라고 부릅니다.**\n\n### 2계층: 데이터 링크 계층 (Data Link Layer)\n데이터 링크 계층은 **인접한 네트워크 장비 간의 안정적인 데이터 전송**을 담당 합니다. 데이터를 프레임 단위로 묶어, 물리적 연결에서 오류 검출과 재전송 기능을 수행합니다.\n\n**주요 프로토콜 예시**: Ethernet, PPP (Point-to-Point Protocol), WiFi\n\n**데이터 전송 과정**\n1. **데이터 준비**: 네트워크 계층에서 생성된 데이터그램이 각 노드(호스트 또는 라우터)로 전달됩니다.\n2. **프레임 캡슐화**: 데이터 링크 계층은 이 데이터그램을 프레임으로 포장하면서, 오류 검출 및 수정에 필요한 정보를 추가합니다.\n3. **단일 링크 전송**: 프레임은 물리 계층을 통해 바로 인접한 다음 네트워크 장비로 전송됩니다.\n4. **프레임 해체**: 다음 노드는 도착한 프레임의 오류를 검사하고, 문제가 없으면 프레임을 열어 원래의 데이터그램을 추출해 네트워크 계층으로 전달합니다.\n\n데이터 링크 계층은 **신뢰성 있는 데이터 전송(Reliable delivery)** 을 기반으로 합니다. 단, 이것은 TCP의 신뢰성 보장과는 다릅니다. TCP는 송신지에서 수신지까지의 전체 경로를 보장하지만, 데이터 링크 계층은 단일 링크에서만 보장합니다.\n\n**데이터 링크 계층에서는 데이터를 `프레임 (Frame)`이라고 부릅니다.**\n\n### 1계층: 물리 계층 (Physical Layer)\n물리 계층은 **하드웨어와 직접 상호작용 하며, 물리적 링크를 통해 비트를 전송**하는 역할을 합니다.\n\n프레임 내의 비트들을 송수신하고, 네트워크의 물리적인 전송 매체(케이블, 무선 신호 등)에 따라 다른 방식으로 데이터를 전달합니다.\n\n물리 계층에서 사용 되는 주요 기술 및 매체에는 꼬임쌍선(Twisted-Pair copper wire), 동축 케이블(coaxial cable), 광섬유(single-mode fiber optics) 등이 있습니다.\n\n데이터 링크 계층의 대표적인 프로토콜인 이더넷(Ethernet)은 **물리 계층의 전송 매체에 따라 다른 물리적 프로토콜을 사용**합니다. 예를 들어, UTP(비차폐 꼬임쌍선) 케이블, 무선(Wifi) 등 다양한 매체에서 동작할 수 있도록 설계되었습니다.\n\n**물리 계층에서는 데이터를 `비트 (Bits)`단위로 다룹니다.**\n\n### OSI 7계층을 통한 end-to-end 데이터 이동 경로\n\n한 호스트에서 다른 호스트로 데이터가 이동하는 과정을 OSI 7계층 모델을 이용해 단계별로 살펴보겠습니다.\n```\n         송신 호스트                                               수신 호스트\n──────────────────────────────────────────────────────────────────────────────\n     [ 애플리케이션 계층 ]                                         [ 애플리케이션 계층 ]  \n      HTTP, FTP, SMTP                                          HTTP, FTP, SMTP \n              │                                                       ▲  \n              ▼                                                       │ \n      [ 프레젠테이션 계층 ]                                        [ 프레젠테이션 계층 ]  \n       데이터 압축/암호화                                          데이터 복호화/압축 해제  \n              │                                                       ▲  \n              ▼                                                       │ \n         [ 세션 계층 ]                                             [ 세션 계층 ]  \n        세션 설정 및 유지                                          세션 동기화 및 종료  \n              │                                                       ▲  \n              ▼                                                       │ \n         [ 전송 계층 ]                                             [ 전송 계층 ]  \n       TCP/UDP 포트 관리                                        TCP/UDP 데이터 재조립  \n              │                                                       ▲  \n              ▼                                                       │ \n       [ 네트워크 계층 ]                                           [ 네트워크 계층 ]  \n     IP 주소 지정 및 라우팅                                       목적지 IP 확인 및 전달  \n              │                                                       ▲  \n              ▼                                                       │ \n      [ 데이터 링크 계층 ]                                         [ 데이터 링크 계층 ]  \n    MAC 주소 지정 및 프레임화                                     프레임 해체 및 MAC 검증  \n              │                                                       ▲  \n              ▼                                                       │ \n         [ 물리 계층 ] ─────────────────────────────────────▶       [ 물리 계층 ]  \n 비트 스트림 전송 (WiFi, LAN)                                 신호를 비트로 변환하여 상위 전달  \n\n```\n\n## 마무리\n이번 포스트에서는 OSI 7 layer 에 대해 간단히 알아보았습니다. 다음 게시글에서는 계층 간의 캡슐화, end-to-end principle 등에 대해 알아보겠습니다.\n"},{slug:"computer-networks/encapsulation-de-encapsulation",categorySlug:"computer-networks",title:{ko:"계층 간 캡슐화와 디캡슐화, 종단 간 원칙",en:"Layer Encapsulation and De-encapsulation, E2E principle"},date:"2025-02-22",category:{ko:"컴퓨터 네트워크",en:"Computer Networks"},description:{ko:"계층 간 캡슐화, 디캡슐화에 대한 설명",en:"How layer encapsulation and de-encapsulation work"},content:'\n## 개요\n네트워크 계층과 각 계층에서 실행되는 프로토콜들이 서로 어떻게 소통하는지 이해하기 위해 캡슐화(encapsulation)과 디캡슐화(de-encapsulation) 개념을 살펴보겠습니다.\n\n## 캡슐화 과정 (Encapsulation)\n캡슐화는 송신 호스트에서 데이터를 보낼 때 각 계층이 자신의 헤더를 추가하면서 이루어집니다.\n \n가장 먼저, 애플리케이션 계층에서 생성된 메시지는 전송 계층으로 전달됩니다. \n전송 계층에서는 이 메시지에 **전송 계층 헤더(HT, Transport Layer Header)** 를 추가하여 **세그먼트**를 형성합니다. \n이 추가된 정보는 수신 호스트에서 올바른 애플리케이션으로 데이터를 전달할 수 있도록 돕고, 오류 감지 및 데이터 무결성을 확인하는 역할을 합니다.\n\n세그먼트는 네트워크 계층으로 전달되며, 네트워크 계층에서는 **네트워크 계층 헤더(HN, Network Layer Header)** 를 추가하여 **데이터그램**을 생성합니다.\n이 헤더에는 **송신지 및 목적지의 IP 주소**가 포함되어 있어, 데이터가 정확한 목적지로 전송될 수 있도록 합니다.\n\n다음으로, 데이터그램은 데이터 링크 계층으로 이동하며 **데이터 링크 계층 헤더(HL, Link Layer Header)** 를 추가하여 **프레임**을 생성합니다.\n프레임은 물리 계층을 통해 비트 단위로 변환되며, 실제 네트워크 매체를 통해 전송됩니다.\n\n## 디캡슐화 과정 (De-encapsulation)\n수신 호스트에서는 위 과정을 반대로 수행합니다. \n\n물리 계층에서 수신된 비트들은 데이터 링크 계층으로 전달되며, 여기서 **프레임의 헤더(HL)** 가 제거된 후 네트워크 계층으로 전달됩니다.\n\n네트워크 계층에서는 **데이터그램의 헤더(HN)** 를 확인하고 제거한 후, 전송 계층으로 데이터를 넘깁니다.\n\n마지막으로 전송 계층에서는 **세그먼트의 헤더(HT)** 를 분석하여 올바른 애플리케이션으로 데이터를 전달합니다. 최종적으로 애플리케이션 계층은 메시지를 해석하고 사용자에게 출력합니다.\n\n### 중간 장치와 캡슐화\n송신지에서 목적지까지의 경로에는 **라우터**나 **스위치** 같은 네트워크 장치들이 포함될 수 있습니다. 이러한 장치들은 네트워크 계층을 처리하는 방식이 다릅니다.\n\n**라우터**는 **물리 계층, 데이터 링크 계층, 네트워크 계층 (1-3계층)** 을 처리하며, 패킷을 분석하여 최적의 경로를 찾아 전송합니다.\n\n**스위치**는 **물리 계층과 데이터 링크 계층 (1-2계층)** 까지만 처리하며, 프레임을 기반으로 목적지를 결정합니다.\n\n## 종단 간 원칙 (End-to-End Principle)\n종단 간 원칙(E2E principle)은 현재의 인터넷 아키텍쳐를 형성하는데 중요한 역할을 한 설계원칙입니다. \n이 원칙은 특정한 애플리케이션 기능을 네트워크 코어(핵심부)에서 처리하는 것이 아니라, **가능하면 네트워크의 끝단(end systems)** 에서 구현해야 한다는 개념을 제안합니다.\n\n즉, **네트워크 자체는 단순하고 최소한의 역할만 수행해야 하며, 복잡한 기능과 지능은 애플리케이션이 실행되는 종단에서 구현하는 것이 바람직하다**는 철학입니다.\n\n네트워크 설계의 기초가 된 논문 "End-to-End Arguments in System Design" (Saltzer, Reed, Clark)에 따르면, 어떤 기능이 완벽하게 구현되려면 **해당 기능을 필요로 하는 애플리케이션이 직접 수행해야 한다**고 설명합니다.\n네트워크 자체에서 특정 기능을 제공하려 해도, 개별 애플리케이션이 이를 완전히 활용하거나 맞춤형으로 조정하기 어렵기 때문입니다.\n\n또한, 모든 애플리케이션이 동일한 기능을 필요로 하는 것이 아니기 때문에, 네트워크 코어에 특정 기능을 추가하면 이를 필요로 하지 않는 애플리케이션에도 강제 적용되는 문제가 발생할 수 있습니다.\n따라서, 네트워크 코어는 필수적이고 공통적인 기능만 수행하도록 설계해야 합니다.\n\n종단 간 원칙 덕분에 인터넷은 빠르게 성장할 수 있었습니다. 네트워크의 핵심부를 바꾸는 것은 어렵지만, 끝단에서 혁신적인 애플리케이션과 서비스가 자유롭게 개발될 수 있었기 때문입니다.\n다양한 애플리케이션이 유연하게 설계될 수 있었던 것도 네트워크의 코어가 아닌 엔드포인트에서 기능을 구현하는 방식을 따랐기 때문입니다.\n\n결과적으로, **하위 계층의 프로토콜은 특정 애플리케이션에 의존하지 않고, 네트워크 자원을 효율적으로 관리하는 역할에 집중**할 수 있습니다.\n이처럼 상위 계층은 개별 애플리케이션에 맞게 설계되고, 하위 계층은 애플리케이션과 무관하게 네트워크 인프라를 최적화하는 것이 종단 간 원칙의 핵심입니다.\n\n### 종단 간 원칙의 위반 사례\n종단 간 원칙은 인터넷의 발전과 확장에 많은 이점을 제공했지만, 현실적인 이유로 인해 이 원칙이 지켜지지 못하는 경우도 존재합니다.\n대표적인 사례로 **방화벽(Firewall)** 과 **네트워크 주소 변환(NAT, Network address translation) 박스**가 있습니다.\n\n#### 방화벽과 트래픽 필터링\n방화벽은 네트워크의 경계에서 동작하며, 네트워크를 통해 들어오거나 나가는 트래픽을 모니터링하는 역할을 합니다.\n보안 정책에 따라 정상적인 트래픽은 허용하고, 악의적인 트래픽은 차단합니다.\n\n이건 보안 측면에서 매우 중요하지만, **중간 네트워크 장치가 엔드 호스트 간의 통신을 차단할 수 있기 때문에** 종단 간 원칙을 위반하는 사례가 됩니다.\n방화벽이 특정 패킷을 차단하면 송신 호스트와 수신 호스트가 직접 통신하는 것이 불가능해질 수 있기 때문입니다.\n\n#### NAT (Network Address Translation) 박스\n인터넷 주소 공간이 부족해지면서 등장한 해결책 중 하나가 **NAT** 입니다. \nNAT은 **하나의 공인 IP 주소를 여러 개의 사설 IP 주소를 사용하는 내부 네트워크와 공유하도록 하는 기술**입니다.\n\n**NAT의 동작 방식**\n\n가정에서 여러 대의 기기를 인터넷에 연결한다고 가정해보면, 보통 Internet service provider(ISP)는 공유기에 **단 하나의 public IP 주소**를 할당합니다.\n하지만 가정 내의 **각 장치는 사설 네트워크에서 개별적인 private IP 주소**를 가질 수 있습니다.\n\n이 때, NAT이 동작하는 방식은 다음과 같습니다.\n1. 내부 네트워크의 장치가 public internet 상의 호스트로 데이터를 전송하려고 하면, 공유기는 **출발지 IP 주소를 자신의 public IP 주소로 변환**한 후 외부로 전송합니다.\n2. 외부에서 오는 응답 패킷의 목적지 IP는 공유기의 public IP 주소이므로, 공유기는 **NAT 변환 테이블을 참고하여 적절한 내부 IP로 변환한 후 전달**합니다.\n\nNAT 변환 테이블은 **public IP 주소 및 포트 번호**와 **내부 네트워크의 IP 주소 및 포트 번호**를 매핑하여 관리합니다.\n예를 들어, 내부 호스트 `10.0.0.4`가 포트 `3345`를 사용하여 public IP `120.70.39.4`의 포트 `5001`과 통신한다고 가정하면:\n- `출발지 IP 10.0.0.4, 출발지 포트 3345` → 변환 후 `IP: 120.70.39.4, 출발지 포트: 5001`\n- `목적지 IP 120.70.39.4, 목적지 포트 5001` → 변환 후 `IP: 10.0.0.4, 목적지 포트: 3345`\n\n이런 방식으로 NAT는 **단 하나의 public IP address를 이용해 다수의 내부 장치가 인터넷과 통신**할 수 있도록 해줍니다.\n\n#### NAT가 종단 간 원칙을 위반하는 이유\nNAT를 사용하는 네트워크 내부의 호스트는 public internet에서 직접 접근할 수 없습니다. 즉, 외부 호스트가 NAT 내부의 호스트로 직접 연결을 시도하는 것이 기본적으로 불가능합니다.\n\n종단 간 원칙의 핵심은 **인터넷의 엔드포인트(호스트)들이 직접 통신할수 있도록 하는 것**인데, NAT은 이 원칙을 깨고 중간에서 IP 주소를 변환하고 트래픽을 조정하는 역할을 합니다.\n\n따라서 NAT는 **네트워크 코어에서 특정한 기능을 수행하면서, 엔드 호스트 간 직접적인 통신을 방해하기 때문에** E2E 원칙을 위반하는 사례로 간주됩니다.\n\n#### NAT 문제를 해결하기 위한 우회 방법\nNAT로 인해 공인 인터넷의 호스트가 NAT 내부 호스트와 직접 통신할 수 없는 문제가 발생하지만, 이를 해결하기 위한 몇 가지 우회 기법이 존재합니다.\n- **STUN (Session Traversal Utilities for NAT)**\n  - NAT가 사용되는 환경에서 클라이언트가 **자신의 공인 IP 주소와 포트 번호를 발견할 수 있도록 도와주는 프로토콜**입니다.\n  - NAT 뒤에 있는 호스트가 외부 서버를 통해 자신이 사용하는 public IP/port를 확인하고, 이를 통해 통신을 설정할 수 있습니다.\n- **UDP Hole Punching**\n  - UDP 기반의 연결을 설정할 때, NAT를 통해 양쪽 호스트가 서로 직접 연결을 수립하는 기법입니다.\n  - 양쪽 호스트가 **동시에 NAT 바깥의 공용 서버에 패킷을 전송**함으로써, **각 공유기의 NAT 변환 테이블을 조작**하여 직접적인 UDP 연결을 가능하게 합니다.\n  - P2P network (Skype, 온라인 게임 등)에서 주로 사용됩니다.\n  \n  \n그럼, **종단 간 원칙을 위반하지 않는 사례**도 살펴보겠습니다.\n\nWiFi와 같은 일부 데이터 링크 계층 프로토콜은 기본적인 오류 수정 기능을 포함하고 있습니다. 이는 물리적 매체가 간섭이나 노이즈로 인해 쉽게 오류가 발생할 수 있기 때문입니다.\n\n그렇다면 **이러한 오류 수정 기능이 E2E principle을 위반하는 것일까요?**\n\n정답은 **위반이 아니다** 입니다.\n\n종단 간 원칙의 위반은 일반적으로 **특정 기능이 엔드 호스트에서만 완벽하게 구현될 수 있음에도 불구하고, 네트워크 내부에서 이를 처리하려고 할 때 발생**합니다. \n\n하지만 WiFi의 오류 수정 기능은 이와 다릅니다. **물리적 계층의 특성상 반드시 필요한 기능이기 때문**입니다.\n무선 네트워크는 유선 네트워크보다 더 많은 간섭과 신호 감쇠를 겪기 때문에, 기본적인 오류 검출 및 수정 기능이 없으면 안정적인 통신이 불가능해집니다.\n\n즉, 이러한 기능이 없으면 상위 계층(전송 계층, 애플리케이션 계층 등)에서 원활한 데이터 송수신이 어려워지므로, 네트워크의 전반적인 신뢰성이 떨어질 수 있습니다.\n데이터 링크 계층에서 이루어지는 오류 수정은 종단 간 원칙을 위반하는 것이 아니라, **네트워크의 안정성을 보장하기 위한 현실적인 조치**라고 볼 수 있습니다.\n'},{slug:"computer-networks/internet-protocol-stack",categorySlug:"computer-networks",title:{ko:"인터넷 프로토콜 스택 구조",en:"Hourglass Shape of Internet Protocol Stack"},date:"2025-02-23",category:{ko:"컴퓨터 네트워크",en:"Computer Networks"},description:{ko:"인터넷 프로토콜 스택과 모래시계 아키텍쳐에 대한 설명",en:"Internet protocol stack and its hourglass shape"},content:"\n인터넷 프로토콜 스택은 모래시계 형태의 계층 구조를 가지고 있습니다. 하지만 인터넷 아키텍쳐가 처음부터 이런 구조를 가지고 있었던 것은 아닙니다.\n\n1990년대 초반까지만 해도 인터넷의 네트워크 계층은 IPv4 하나로 통일된 것이 아니라, **여러 개의 경쟁 프로토콜이 존재했던 시기**였습니다.\n예를 들어, IPX(Internetwork Packet Exchange), X.25 Frame Relay Protocol 등이 IPv4와 경쟁하며 사용되었는데 시간이 지나면서 다른 프로토콜들은 점점 사라지게 되었습니다.\n\n인터넷 프로토콜 스택이 모래시계 모양을 갖게 된 이유는 **상위 계층(애플리케이션 계층)과 하위 계층(물리 계층)의 변화는 활발하게 이루어지는 반면, 중간 계층(네트워크/전송 계층)은 오랜 기간 유지되었기 때문**입니다.\n\n#### 상위 계층에서의 혁신\n애플리케이션 계층에서는 새로운 서비스와 프로토콜이 지속적으로 등장하고 사라지는 것이 일반적입니다. \n웹 브라우징을 위한 **HTTP/HTTPS**, 파일 전송을 위한 **FTP**, 이메일을 위한 **SMTP, IMAP, POP3** 등 수많은 프로토콜이 등장했고, 최근에는 **RESTful API, gRPC** 등 새로운 애플리케이션 계층 기술도 발전하고 있습니다.\n애플리케이션 계층은 새로운 사용자 요구사항과 기술 발전에 맞춰 빠르게 변화하기 때문에 지속적인 혁신이 이루어집니다.\n\n#### 하위 계층에서의 변화\n물리 계층도 새로운 전송 매체가 등장하면서 지속적으로 변화하고 있습니다.\n데이터 전송 속도를 높이고, 더 안정적인 네트워크를 구축하는 것이 주요 목표이기 때문에 하드웨어 기술이 발전함에 따라 새로운 프로토콜과 기술이 빠르게 도입됩니다.\n\n### 중간 계층의 안정성: IPv4, UDP, TCP가 쉽게 바뀌지 않는 이유\n네트워크 및 전송 계층은 인터넷의 핵심 기능을 담당하며, **모든 상위 및 하위 계층이 이 계층에 의존**하기 때문에 쉽게 대체되기 어렵습니다.\n\n1. **호환성과 네트워크 효과**\n    - 네트워크 계층에서 하나의 프로토콜이 표준으로 자리 잡으면, 모든 네트워크 장비(라우터, 스위치, 서버 등)가 이를 지원해야 합니다.\n    - IPv4는 초기에 널리 채택되었고, 이후 네트워크 인프라 대부분이 IPv4를 기반으로 구축되었기 때문에 다른 네트워크 계층 프로토콜이 경쟁에서 도태되었습니다.\n    - 전송 계층에서도 TCP/UDP가 거의 모든 인터넷 애플리케이션에서 사용되었기 때문에, 새로운 전송 계층 프로토콜이 등장하더라도 기존의 네트워크와 호환성을 유지하는 것이 어렵습니다.\n2. **대체 비용이 높음**\n    - 새로운 네트워크 계층 프로토콜이 등장했더라도, 기존의 인프라와 완전히 호환되지 않으면 적용하기 어렵습니다.\n    - IPv6은 1990년대부터 개발되었지만, 여전히 IPv4가 널리 이용되는 이유도 기존 인프라와의 호환성 문제와 전환 비용 때문입니다.\n3. **핵심 기능의 단순성**\n    - 네트워크 계층의 역할은 **데이터를 최적의 경로를 통해 전달**하는 것입니다.\n    - 전송 계층의 TCP와 UDP는 각각 **신뢰성이 필요한 통신**과 **빠른 데이터 전송이 필요한 통신** 이라는 단순하고 강력한 역할을 수행합니다.\n    - 이러한 기본적인 기능이 잘 동작하기 때문에 새로운 프로토콜을 도입할 유인이 적습니다.\n"},{slug:"computer-networks/hosts-and-networks",categorySlug:"computer-networks",title:{ko:"계층별 장치와 스패닝 트리 알고리즘",en:"Layer Devices and Spanning Tree Algorithm"},date:"2025-02-23",category:{ko:"컴퓨터 네트워크",en:"Computer Networks"},description:{ko:"물리, 데이터링크, 네트워크 계층의 장치들과 네트워크 간 연결 방법",en:"L1, L2, L3 devices and interconnecting hosts"},content:"\n컴퓨터 네트워크에는 호스트 간 연결을 제공하거나 서로 다른 네트워크를 연결하는 다양한 장치들이 존재합니다.\n이러한 장치들은 서로 다른 계층에서 동작하며, 각각 고유한 기능과 한계를 가지고 있습니다.\n\n## 계층별 장치\n### 물리 계층 (L1) 장치: 리피터(Repeater)와 허브(Hub)\n리피터와 허브는 **물리 계층**에서 동작하는 장치로, **디지털 신호를 수신하고 그대로 재전송하여 ethernet 세그먼트 간 연결을 제공**합니다.\n\n**리피터**는 신호가 약해지는 것을 방지하기 위해 신호를 증폭하여 전달하는 역할을 합니다.\n\n**허브**는 여러 호스트를 물리적으로 연결하는 장치로, 수신된 데이터를 네트워크에 연결된 모든 장치로 전달합니다.\n\n이런 장치들은 대부분 **단순하고 저렴하며, 계층적으로 구성할 수 있다는 장점**이 있습니다. \n하지만, **연결된 모든 호스트가 동일한 충돌 도메인(Collision domain)에 족하게 되어 하나의 링크를 공유하는 방식으로 데이터 충돌이 발생할 가능성이 높습니다.**\n\n### 데이터 링크 계층 (L2) 장치: 브릿지(Bridge)와 L2 스위치(L2 Switch)\n브릿지와 스위치는 **데이터링크 계층**에서 동작하며, **MAC 주소를 기반으로 패킷을 전달**하는 역할을 합니다.\n\n**브릿지**는 두 개의 네트워크 세그먼트를 연결하며 수신한 패킷의 MAC 주소를 확인하여 적절한 포트로 전달합니다.\n\n**L2 스위치**는 여러 개의 포트를 가지고 있으며, 각 포트마다 MAC 주소를 학습하여 목적지 MAC 주소에 따라 패킷을 전송합니다.\n\n이 장치들은 **직접 연결되지 않은 호스트 간의 통신을 가능**하게 하며, 네트워크 충돌을 줄이는 역할을 합니다.\n하지만 출력 포트의 대역폭이 제한되어 있어 **트래픽 도착 속도가 출력 용량을 초과하면 버퍼링이 필요**하며, **버퍼가 가득 차면 패킷 손실이 발생**할 수 있습니다.\n\n#### 학습 브릿지 (Learning Bridge)\n브릿지는 여러 개의 입출력을 가지고 있는데, 모든 프레임을 무조건 전송하는 것이 아니라 학습 과정을 통해 목적지에 따라 프레임을 선택적으로 전달할 수 있습니다.\n\n이를 위해 **포워딩 테이블**을 유지하며 프레임이 불필요한 포트로 전달되는 것을 방지합니다.\n\n\n**브릿지의 프레임 전달 방식**\n1. 브릿지는 처음에 모든 포트를 통해 프레임을 전달합니다. (Unknown unicast)\n2. 수신된 프레임의 출발지 주소를 확인해서 **해당 호스트가 어느 포트에 위치하는지 학습**합니다.\n3. 포워딩 테이블을 구축해서 이후엔 필요한 포트로만 프레임을 전달합니다.\n4. 동일한 포트에 있는 호스트 간의 통신은 해당 포트 내에서만 처리하여 네트워크 트래픽을 최적화합니다.\n\n#### 스패닝 트리 알고리즘과 루프 방지\n브릿지를 사용하여 LAN을 확장하는 경우 **네트워크 내에 루프가 발생하면 패킷이 무한히 순환하는 문제가 발생**할 수 있습니다.\n이는 브릿지가 들어오는 프레임을 여러 개의 포트로 중복 전송하면서 발생하는 현상입니다.\n\n이 문제를 해결하기 위해 **스패닝 트리 알고리즘**을 사용할 수 있습니다. \n이 알고리즘은 **네트워크 토폴로지를 트리 형태로 변환**하여 루프를 제거하는 역할을 합니다.\n\n스패닝 트리 알고리즘은 아래와 같이 동작합니다.\n1. 모든 브릿지가 초기에는 자신을 루트로 간주하고 메시지를 보냅니다.\n2. 네트워크 내에서 가장 작은 ID를 가진 브릿지가 루트 브릿지로 선택됩니다.\n3. 각 브릿지는 루트까지의 최단 경로를 찾고, 그 정보를 업데이트하여 공유합니다.\n4. 루프를 방지하기 위해 일부 링크(포트)가 비활성화 됩니다.\n5. 결과적으로 트리 구조가 형성되며 패킷 루프 문제가 해결됩니다.\n\n### 네트워크 계층 (L3) 장치: 라우터(Router)와 L3 스위치 (L3 Switch)\n라우터와 L3 스위치는 **IP 주소를 기반으로 서로 다른 네트워크 간의 데이터 전달을 수행**합니다.\n이 장치들은 네트워크를 여러 개의 서브넷으로 분할하여 트래픽을 효율적으로 관리할 수 있도록 도와주고, **라우팅 프로토콜을 사용하여 패킷을 최적의 경로로 전달**합니다.\n\n**라우터**는 IP 주소를 확인하여 최적의 경로를 선택하고, 패킷을 전달하는 기능을 수행합니다.\n\n**L3 스위치**는 라우팅 기능이 포함된 스위치로, 일반적인 L2 스위치보다 더 빠른 속도로 IP 패킷을 전달할 수 있습니다.\n\n"},{slug:"computer-networks/multiplexing-demultiplexing",categorySlug:"computer-networks",title:{ko:"전송 계층의 멀티플렉싱과 디멀티플렉싱",en:"Transport layer's Multiplexing and Demultiplexing"},date:"2025-02-23",category:{ko:"컴퓨터 네트워크",en:"Computer Networks"},description:{ko:"전송 계층의 멀티플렉싱/디멀티플렉싱에 대해 알아봅시다",en:"How multiplexing/demultiplexing work in transport layer"},content:"\n## 멀티플렉싱/디멀티플렉싱\n전송 계층의 주요 기능 중 하나는 **한 호스트에서 여러 애플리케이션이 동시에 네트워크를 사용할 수 있도록 하는 멀티플렉싱** 기능입니다.\n\n멀티플렉싱은 **송신 호스트**가 여러 **애플리케이션의 데이터를 수집하고, 이를 전송 계층 세그먼트로 변환**하는 과정입니다. \n\n반대로, 디멀티플렉싱은 **수신 호스트**가 네트워크 계층에서 전달받은 **세그먼트를 확인하고, 올바른 애플리케이션으로 데이터를 전달**하는 과정입니다.\n\n### 멀티플렉싱이 필요한 이유\n컴퓨터에서 여러 애플리케이션이 동시에 네트워크를 사용할 때, **각 애플리케이션이 올바른 데이터 패킷을 받도록 보장**하는 것이 중요합니다.\n\n예를 들어 한 사용자가 인스타그램을 사용하면서 동시에 spotify에서 음악을 듣고 있다면 두 개의 애플리케이션이 각각 다른 서버와 데이터를 송수신해야 합니다.\n\n하지만 네트워크 계층에서는 오직 IP 주소만 사용하기 때문에, **패킷이 어떤 애플리케이션으로 전달되어야 하는지**를 구분할 수 없습니다.\n\n#### 멀티플렉싱 동작 원리\n\n전송 계층에서는 각 애플리케이션을 구분하기 위해 **포트 번호**를 사용합니다.\n1. 각 애플리케이션은 고유한 포트 번호를 할당받고, 이를 통해 통신을 진행합니다.\n2. 애플리케이션이 네트워크를 사용할 때, 소켓을 열어서 특정 포트에서 데이터를 수신하도록 설정합니다.\n3. 따라서 패킷이 도착하면 **전송 계층은 포트 번호를 확인하고 해당 포트와 연결된 애플리케이션으로 데이터를 전달**합니다.\n\n\n만약 위 예제 사용자의 상황이라면 전송 계층은 **각 애플리케이션이 사용하는 포트 번호**를 기반으로 데이터를 분류해서 처리해야 합니다.\n- 인스타그램 -> 포트 443 (HTTP) 사용\n- spotify -> 포트 4070 사용\n\n전송 계층은 이 정보를 기반으로 **멀티플렉싱하여 패킷을 송신**하고, **수신 측에서는 디멀티플렉싱**하여 해당 애플리케이션으로 데이터를 전달합니다.\n### 멀티플렉싱 종류\n멀티플렉싱 방식은 **연결을 설정하는지 여부**에 따라 두 가지로 나뉩니다.\n\n1. **비연결형 (Connectionless) 멀티플렉싱**\n    - **UDP 기반** 멀티플렉싱\n    - 송신자가 수신자와 연결을 설정하지 않고 바로 데이터를 전송\n    - **패킷 손실 가능성이 있지만 빠르고 간단**한 방식\n    - DNS, VoIP, 온라인 게임 등에서 사용\n2. **연결형 (Connection-Oriented) 멀티플렉싱**\n    - **TCP 기반** 멀티플렉싱\n    - 송신자와 수신자가 먼저 연결을 설정한 후 데이터를 전송 **(3-way handshake)**\n    - **데이터의 신뢰성과 순서** 보장\n    - 웹 브라우징, 이메일, 파일 전송 등에서 사용\n    \n## 전송 계층의 소켓 식별 방법\n전송 계층은 소켓을 식별하기 위해 세그먼트의 특정 필드를 활용합니다. \n\n### UDP의 소켓 식별 방법\nUDP는 `Two-Tuple`을 사용하여 소켓을 식별합니다. \n\nUDP 소켓은 **목적지 IP 주소**와 **목적지 포트 번호**로 구분되는데, 송신 호스트가 **어떤 출발지 포트를 사용하든 상관없이** 동일한 목적지 포트로 전송된 데이터는 같은 소켓으로 전달됩니다. \n\n따라서 **여러 호스트가 동일한 서버의 같은 포트**로 데이터를 보낼 수도 있습니다.\n\n### TCP의 소켓 식별 방법\nTCP는 `Four-Tuple`을 사용하여 소켓을 식별합니다.\n\nTCP 소켓은 **출발지 IP 주소, 출발지 포트, 목적지 IP, 목적지 포트**로 구분됩니다.\n\n즉, 같은 서버의 동일한 포트로 여러 클라이언트가 접속하더라도, **각 클라이언트의 출발지 IP 및 포트가 다르므로 개별적인 연결을 유지**할 수 있습니다.\n\n### 웹 서버에서의 멀티플렉싱\n웹 서버는 하나의 포트에서 다수의 클라이언트 요청을 처리해야 합니다. 이를 위해 웹 서버는 다수의 클라이언트의 동시 접속을 각기 다른 세션으로 구분하여 처리할 수 있습니다.\n\n"},{slug:"computer-networks/tcp",categorySlug:"computer-networks",title:{ko:"TCP 프로토콜",en:"TCP Protocol"},date:"2025-02-23",category:{ko:"컴퓨터 네트워크",en:"Computer Networks"},description:{ko:"TCP 프로토콜에 대해 자세히 알아봅시다",en:"Deep dive into TCP Protocol"},content:"\n\n## 3-Way Handshake\nTCP는 신뢰성을 보장하는 연결 지향형 프로토콜로, 데이터를 전송하기 전에 **반드시 연결을 설정**하는 과정을 거쳐야 합니다.\n\n이때 사용하는 방식이 **3-way handshake** 입니다. \n이 과정에서는 클라이언트와 서버가 서로 통신이 가능한 상태인지 확인하고, 데이터 전송을 위한 준비를 완료합니다.\n\n1. 먼저 클라이언트는 서버에 **연결 요청(SYN 패킷)** 을 보냅니다. \n이때 **SYN 플래그를 1**로 설정하고, **초기 순서 번호(ISN, Initial Sequence Number)** 를 포함하여 서버로 전송합니다.\n\n2. 서버는 이 요청을 수락한 후, **SYN-ACK 패킷**을 응답합니다.\n이 패킷에는 클라이언트의 **ISN에 1을 더한 값**과 **서버의 ISN**이 포함됩니다.\n\n3. 마지막으로, 클라이언트는 서버의 응답을 확인한 후 **ACK 패킷**을 다시 서버로 전송합니다.\n\n이렇게 TCP 3-way handshake가 완료되면, 클라이언트와 서버는 신뢰할 수 있는 데이터 전송을 시작할 준비가 완료됩니다.\n\n### 4-Way Handshake\nTCP 연결이 설정되었다면 **연결 종료 시에도 신뢰성을 보장**하기 위해 4단계 과정을 거치게 됩니다. 이를 **4-way Handshake**라고 합니다.\n\n1. 먼저, 클라이언트가 더 보낼 데이터가 없을 경우 **FIN 패킷**을 서버로 전송합니다.\n\n2. 서버는 이 요청을 수락한 후, **ACK 패킷**으로 응답합니다.\n이 단계에서 서버는 클라이언트의 연결 종료 요청을 수락했지만 아직 데이터를 보낼 수 있는 상태입니다.\n\n3. 서버도 더 이상 보낼 데이터가 없을 경우, **FIN 패킷**을 클라이언트로 전송합니다.\n\n4. 클라이언트는 서버의 FIN 패킷을 수신한 후, **ACK 패킷**을 서버로 전송하며 연결 종료를 완료합니다.\n이 과정에서 TCP는 신뢰성을 보장하기 위해 **일정 시간 동안 대기**한 후 최종적으로 연결을 종료합니다.\n\n## TCP의 신뢰성 보장\n**네트워크 계층은 기본적으로 신뢰성이 보장되지 않기** 때문에 패킷이 손실되거나 순서가 뒤바뀌어 도착할 가능성이 있습니다.\n이러한 문제는 일부 패킷이 유실되면 파일이 손실될 수 있기 때문에 파일 다운로드와 같은 애플리케이션에서 심각한 영향을 줄 수 있습니다.\n\n이 문제를 해결하는 방법 중 하나는 UDP처럼 애플리케이션 개발자가 직접 네트워크 손실을 감지하고 복구하도록 하는 것입니다.\n하지만 신뢰성이 중요한 서비스에서는 TCP를 사용하는 것이 훨씬 더 효율적입니다. \nTCP는 **데이터가 손실되지 않고, 순서대로 도착하고, 오류 없이 전달**되는 것을 보장합니다.\n\nTCP에서 신뢰성을 보장하려면 송신 측에서 수신 측이 어떤 데이터를 정상적으로 받았는지, 어떤 데이터가 손실되었는지를 알아야 합니다.\n이를 위해 **ACK**을 사용합니다.\n\n수신 측은 받은 데이터를 확인하는 메시지를 송신 측에 보내고, 만약 송신 측이 일정 시간 내에 ACK을 받지 못하면 해당 패킷이 손실된 것으로 간주하고 재전송합니다.\n이를 **자동 재전송 요청 (ARQ, Automatic Repeat reQuest)** 이라고 합니다.\n\n### 신뢰성 보장 기법\n1. **Stop-and-Wait ARQ (정지 대기 ARQ)**: 가장 단순한 방식으로, **송신 측이 하나의 패킷을 보낸 후 수신 측의 ACK을 기다렸다가 다시 다음 패킷을 보내는 방식**입니다.\n하지만 이 방법은 대기 시간이 길어질 경우 전송 속도가 매우 느려진다는 단점이 있습니다.\n2. **Sliding window** 방식: stop-and-wait의 단점을 개선하기 위해 **한 번에 여러 개의 패킷을 전송**할 수 있도록 한 방법입니다.\n송신 측이 미리 **정해진 윈도우 크기(Window size) 만큼의 패킷**을 연속으로 보내고, 수신 측으로부터 ACK을 받으면 추가적인 패킷을 전송할 수 있습니다.\n\n### 데이터 손실 복구 방식\n1. **Go-Back-N** 방식: 수신 측이 **받은 패킷의 순서가 맞지 않으면 그 이후의 모든 패킷을 폐기**하고, 송신 측은 **폐기된 패킷 이후의 모든 데이터를 다시 전송**하는 방식입니다.\n이 방식은 간단하지만 하나의 패킷이 손실될 경우 많은 데이터를 다시 전송해야 하는 비효율적인 점이 있습니다.\n2. **Selective Acknowledgement (SACK, 선택적 확인 응답)**: Go-Back-N의 단점을 개선한 방식으로, 수신 측이 받은 패킷에 대한 정보를 개별적으로 송신 측에 알리고, 송신 측은 **손실된 패킷만 다시 보내는 방법**입니다.\n\n### 패킷 손실 감지 방법\n1. **Timeout 기반 재전송**: 일정 시간동안 ACK이 도착하지 않으면 해당 패킷이 손실된 것으로 판단하고 다시 전송합니다.\n2. **빠른 재전송 (Fast Retransmit)**: TCP는 **중복된 ACK**을 활용하여 패킷 손실을 보다 빠르게 감지합니다.\n동일한 데이터에 대해 **3번 이상의 중복된 ACK을 수신**하면 해당 패킷이 손실되었다고 판단하고 즉시 재전송합니다.\n예를 들어 패킷 7이 손실되었을 때, 수신 측은 계속해서 패킷 7에 대한 ACK을 보냅니다. \n송신 측이 같은 ACK을 3번 받으면 바로 패킷 7을 다시 전송하는 방식입니다.\n\n## 전송 속도 제어 메커니즘\n네트워크에서 데이터를 전송할 때 전송 속도를 적절히 조절하는 것이 매우 중요합니다.\n\n예를 들어 사용자가 1GB 파일을 원격 호스트로 전송하려고 할 때, **전송 속도를 얼마로 설정**해야 할까요?\n\n이상적으로는 100Mbps 네트워크를 사용한다면 100Mbps로 전송하는 것이 최적일 것처럼 보이지만, 현실적으로는 그렇지 않습니다.\n\n첫 번째 문제는 **송신자가 링크의 정확한 용량을 알지 못한다**는 점입니다. 네트워크 환경은 항상 변동되며, 현재 사용 가능한 대역폭이 얼마인지 미리 알 수 없습니다.\n\n두 번째로, 네트워크에는 여러 사용자가 존재하며 **같은 링크를 여러 명이 공유할 경우 공정한 분배가 필요**합니다.\n만약 한 사용자가 과도한 속도로 데이터를 전송한다면 다른 사용자의 네트워크 품질이 저하될 수 있습니다.\n또한, 수신자가 여러 개의 파일을 동시에 받고 있다면 송신자는 이를 고려해야 합니다.\n\n그럼 전송 속도를 조절하는 기능을 **네트워크 스택의 어느 계층에서** 구현해야 할까요?\n\n한 가지 방법은 애플리케이션 개발자가 **직접 속도 제어 메커니즘을 구현**하는 것입니다. \nUDP가 이러한 방식을 사용하며 데이터 전송 속도를 애플리케이션이 직접 관리하도록 합니다.\n하지만 대부분의 애플리케이션에서 전송 속도 제어는 필수적인 기능이므로 이를 **전송 계층에서 제공**하는 것이 훨씬 효율적입니다.\n\n### 흐름 제어 메커니즘 (Flow Control)\nTCP에서 전송 속도를 제어하는 첫 번째 이유는 **수신 버퍼가 넘치는 것을 방지하기 위해서**입니다.\nTCP는 **수신 측에서 데이터를 버퍼에 저장한 후 애플리케이션이 이를 읽어가도록** 합니다.\n하지만 수신 측이 여러 프로세스를 동시에 처리하고 있거나 데이터를 즉시 읽지 못하는 경우 버퍼에 데이터가 쌓일 수 있습니다.\n\n이러한 문제를 해결하지 위해 TCP는 **송신 속도를 수신 속도에 맞추는** Flow control 메커니즘을 제공합니다.\n\n이 메커니즘의 핵심은 송신자가 현재 수신자가 처리할 수 있는 데이터 양을 파악하는 것입니다.\n이를 위해 TCP는 **수신 윈도우(receive window, `rwnd`)** 라는 변수를 유지하며 이는 수신자가 처리할 수 있는 여유 공간을 나타냅니다.\n\n#### 동작 방식\nTCP 연결을 통해 두 호스트 A와 B가 통신하는 상황을 가정해 보겠습니다.\nA가 B로 파일을 전송하려고 할 때 B는 이 연결을 위해 **수신 버퍼(`RcvBuffer`)** 를 할당합니다.\n\n수신 측에서는 다음 두 개의 변수를 유지합니다:\n- **`LastByteRead`**: 애플리케이션이 버퍼에서 읽은 마지막 바이트의 번호\n- **`LastByteRcvd`**: 네트워크에서 수신하여 버퍼에 저장된 마지막 바이트의 번호\n\nBuffer overflow를 방지하려면 다음 조건이 항상 유지되어야 합니다.\n\n**`LastByteRcvd - LastByteRead <= RcvBuffer`**\n\n여유 공간을 계산할 때는 `rwnd`를 사용합니다.\n\n**`rwnd = RcvBuffer - (LastByteRcvd - LastByteRead)`**\n\n수신자는 매번 송신자에게 ACK을 보낼 때 `rwnd`값을 포함하여 현재 수신할 수 있는 공간을 알립니다.\n송신자는 다음 두 변수를 유지하며 수신자의 여유 공간을 고려합니다:\n\n- **`LastByteSent`**: 송신자가 전송한 마지막 바이트의 번호\n- **`LastByteAcked`**: 송신자가 전송한 데이터 중 수신자로부터 ACK을 받은 마지막 바이트의 번호\n\n송신자는 unacked data sent를 계산하여 `rwnd`를 초과하지 않도록 보장해야 합니다.\n\n**`LastByteSent - LastByteAcked <= rwnd`**\n\n#### Flow control에서 발생할 수 있는 문제와 해결책\n위와 같은 방식에서는 한 가지 문제가 발생할 수 있습니다.\n\n예를 들어, 수신자가 송신자에게 `rwnd = 0`이라고 알리면 송신자는 데이터 전송을 중단합니다. \n그리고 수신측에서는 애플리케이션이 데이터를 읽어가면서 버퍼에 남는 공간이 생길 수도 있습니다. 하지만 **송신자는 이를 알 방법이 없기 때문에 새로운 데이터를 전송하지 못하는 문제**가 발생합니다.\n\n이 문제를 해결하기 위해 TCP는 `rwnd = 0` 상태에서도 송신자가 **1 byte 크기의 세그먼트를 주기적으로 전송**하도록 합니다.\n\n이를 통해 송신자는 수신자로부터 **ACK을 받을 때마다 최신 `rwnd`값을 확인**할 수 있으며, 수신 버퍼에 여유 공간이 생기면 즉시 데이터를 전송할 수 있습니다.\n\n### 혼잡 제어 메커니즘 (Congestion Control)\n전송 속도를 제어해야 하는 또 다른 중요한 이유는 네트워크에서 **혼잡(congestion)** 을 방지하기 위해서입니다.\n네트워크가 혼잡해지면 패킷 손실이 증가하고 지연 시간이 길어지는 문제가 생길 수 있습니다.\n\n네트워크는 동적인 환경이므로 **사용자들이 네트워크에 접속하고 연결을 종료하는 일이 지속적으로 발생**합니다. 따라서 네트워크의 혼잡 상태도 끊임없이 변하게 됩니다.\n\n이러한 변동성 때문에 혼잡 제어 메커니즘은 단순히 정적인 속도 제한을 설정하는 것이 아니라 **네트워크의 상태를 지속적으로 감지하고 이에 따라 전송 속도를 조정**할 수 있어야 합니다.\n\n#### Congestion Control 특징\n1. **효율성**: 네트워크 자원을 최대한 활용하면서 불필요한 혼잡을 방지하는 균형점을 찾아야합니다.\n2. **공정성**: 네트워크를 사용하는 모든 사용자들이 **동일한 병목 링크(Bottleneck link)** 를 공유할 때, 각 사용자가 공정한 대역폭을 가져야합니다.\n(네트워크 정책에 따라 달라지지만) 일반적으로 같은 조건의 Flow들은 **동일한 네트워크 자원을 균등하게 할당**받아야 합니다.\n3. **낮은 지연**: 지연을 최소화 하면서 높은 성능을 유지하는 방법으로 설계되어야 합니다.\n4. **빠른 수렴**: 네트워크에서 flow가 공정한 대역폭을 배분받기까지 걸리는 시간이 짧아야 합니다.\n\n#### 구현 방법\n1. **네트워크 기반(Network-assisted) congestion control**\n\n    이 방식에서는 네트워크 자체가 혼잡 상태를 감지하고 송신자에게 **Explicit feedback**을 제공하여 혼잡을 해결하도록 돕습니다.\n    \n    예를 들어 라우터가 **ICMP 소스 퀀치** 메시지를 보내 송신자에게 혼잡이 발생했음을 알릴 수 있습니다. 송신자는 이를 받아들이고 전송 속도를 줄일 수 있습니다.\n    \n    하지만 이 방법에는 몇 가지 한계가 있습니다. 네트워크가 심각하게 혼잡해지면 **ICMP 패킷조차 손실될 가능성**이 있어 피드백이 효과적으로 전달되지 않을 수 있습니다.\n    또한, 네트워크 장비가 혼잡 제어를 지원하려면 추가적인 프로토콜과 기능이 필요하므로 **구현이 복잡해지고 비용이 증가**할 수 있습니다.\n    \n2. **종단 간(End-to-End) congestion control**\n\n    이 방식에서는 네트워크가 혼잡 상태를 직접 알리지 않고 **송신자가 네트워크의 상태를 스스로 추론**하여 전송 속도를 조절합니다.\n    즉, 네트워크에서 발생하는 패킷 손실, 지연 증가 등을 기반으로 **송신자가 혼잡을 감지하고 대응**하는 방식입니다.\n    \n    TCP는 바로 이 **e2e congestion control**을 사용합니다. 이건 종단 간 원칙과도 잘 맞아떨어지는 개념인데, 네트워크 계층에서는 패킷 전달을 담당하고 혼잡 제어는 전송 계층에서 처리하는 것이 이상적이라는 설계 철학이 반영된 것입니다.\n    \n    그러나 현대 네트워크에서는 일부 라우터가 **Explicit Congestion Notification (ECN)** 이나 **Quantized Congestion Notification (QCN)** 과 같은 프로토콜을 사용하여 송신자에게 혼잡 상태를 알릴 수 있습니다.\n    이렇게 종단 간 방식을 고수하기 보다는 네트워크의 피드백을 활용하는 하이브리드 방식도 점점 활용되고 있습니다.\n\n#### TCP의 혼잡 감지 방법\nTCP는 혼잡을 감지하기 위해 **두 가지 주요 신호**를 사용합니다.\n\n1. **패킷 지연 (Packet delay)**\n\n    네트워크가 혼잡해지면 라우터의 버퍼에 패킷이 대기하면서 **큐가 쌓이고 전송 지연이 증가**하게 됩니다.\n    이로 인해 왕복 시간(RTT, Rount Trip Time)이 증가하는데 송신자는 ACK 패킷을 기반으로 RTT를 측정하여 혼잡을 감지할 수 있습니다.\n    \n    하지만 delay-based congestion inference는 구현이 쉽지 않습니다.\n    네트워크의 지연 시간은 혼잡 외에도 다양한 요인에 의해 변동될 수 있기 때문입니다. 따라서 **TCP는 기본적으로 패킷 지연을 직접적인 혼잡 신호로 사용하지 않습니다.**\n    \n2. **패킷 손실 (Packet loss)**\n\n    네트워크가 심하게 혼잡해지면 라우터의 버퍼가 가득 차서 패킷을 드롭하게 됩니다. \n    패킷 손실의 원인엔 여러 가지가 있지만 (TTL 만료, 네트워크 혼잡, 하드웨어 오류 등등) 대부분의 손실은 네트워크 혼잡으로 인해 발생합니다.\n    \n초기 TCP 구현에서는 **패킷 손실이 감지되면 이를 혼잡의 신호로 해석하고 전송 속도를 줄이는 방식**을 사용했습니다.\n\n#### 동작 방식\nTCP는 혼잡 제어를 위해 `cwnd` 개념을 사용합니다.\n이는 **송신자가 한 번에 보낼 수 있는 데이터의 최대 크기**를 의미합니다.\n\n`cwnd`는 `rwnd`와 유사하지만, 수신 측이 아닌 **네트워크의 혼잡 상태를 기반으로 조절**된다는 차이가 있습니다.\n\nTCP는 **probe-and-adapt** 방식을 통해 `cwnd` 크기를 조절합니다.\n네트워크가 안정적인 경우, `cwnd`를 점진적으로 증가시켜 더 많은 데이터를 전송하도록 시도합니다.\n패킷 손실이 감지되면 혼잡이 발생한 것으로 판단하고 창 크기를 줄여 혼잡을 완화합니다.\n\n송신자는 **네트워크의 상태(`cwnd`) 또는 수신자의 처리 능력(`rwnd`) 중 더 작은 값**에 맞춰 전송 속도를 조절해야합니다.\n\n#### AIMD\nTCP가 혼잡에 따라 송신 윈도우 크기를 조절하는 방식은 **AIMD (Additive Increase / Multiplicative Decrease)** 라고 불립니다.\n\n1. **Additive Increase(가산 증가)** 방식\n\n    TCP 연결은 초기 송신 윈도우 크기를 일정하게 설정한 후, 점진적으로 증가시킵니다.\n    일반적으로 초기 윈도우 크기는 2로 설정되며 매 RTT(Rount Trip Time)마다 선형적으로 증가하는 방식입니다.\n    \n    즉, **송신자가 `cwnd` 개수만큼의 패킷을 성공적으로 전송하면 `cwnd`의 크기가 증가**합니다. \n    \n    또한 TCP는 모든 패킷의 ACK을 기다린 후 증가시키는 것이 아니라, **개별적인 ACK을 수신할 때마다 즉시 증가**시키는 방식을 사용합니다.\n\n    증가량은 MSS(Maximum Segment Size)에 기반하며 아래의 수식을 따릅니다.\n    \n    **`Increment = MSS * (MSS/cwnd)`**\n    \n2. **Multiplicative Decrease(배수 감소)** 방식\n    \n    TCP는 패킷 손실이 발생하면 `cwnd` 값을 **기존 값의 절반**으로 줄입니다. `cwnd` 값은 **최소 1**까지 줄어들 수 있고 그 이하로는 내려가지 않습니다.\n    \n이러한 과정이 반복되면서 `cwnd`는 지속적으로 증가했다가 감소하는 패턴을 보이는데, 이를 **톱니형 패턴**이라고 합니다.\n\nTCP의 여러 구현 방식 중에서 TCP Reno는 두 가지 종류의 패킷 손실을 기반으로 혼잡을 감지합니다. \n1. **세 번의 중복 ACK을 수신하는 경우**: 네트워크가 경미한 혼잡 상태에 있다는 신호이며, `cwnd` 값을 절반으로 줄입니다.\n2. **특정 시간 동안 ACK을 받지 못하는 타임아웃 이벤트**: 타임아웃은 심각한 혼잡 상태로 간주되며, `cwnd` 값을 초기 윈도우 상태로 재설정합니다.\n\n#### Slow Start\nSlow start는 송신 호스트가 네트워크의 용량을 모를 때, 즉 **새로운 연결이 시작될 때 적용**됩니다. \n초기에는 송신 윈도우 크기를 1로 설정하고, **각 ACK을 받을 때마다 윈도우 크기를 두 배씩 증가**시킵니다.\n\n즉, 처음 1개의 패킷을 보내고, 다음에는 2개, 그 다음에는 4개, 8개 식으로 증가합니다. \n\n이를 통해 네트워크가 허용하는 최적의 전송 속도를 신속하게 찾을 수 있습니다.\n\n하지만 Slow start가 계속되면 송신 윈도우가 과도하게 증가하여 네트워크 혼잡이 발생할 수 있습니다.\n이를 방지하기 위해 **congestion threshold를 넘어서면 AIMD 방식으로 전환**됩니다. \n\n#### TCP 공정성이 보장되지 않는 경우\n1. **RTT의 차이**\n\n    TCP Reno는 ACK을 기반으로 `cwnd` 크기를 조정하는데, **RTT가 짧은 연결일수록 ACK을 빨리** 받을 수 있어 `cwnd`를 더 빨리 증가시킬 수 있습니다.\n    \n    반면, RTT가 긴 연결은 같은 속도로 증가하지 못하고 상대적으로 낮은 전송 속도를 유지해야 합니다.\n        \n2. **여러 개의 병렬 TCP 연결을 사용하는 경우**\n\n    다수의 연결을 가진 애플리케이션이 불공정하게 더 많은 네트워크 자원을 가져갈 수 있습니다.\n\n위와 같은 문제로 인해 일부 네트워크 환경에서는 다양한 조정 기법이 도입되기도 합니다.\n\n예를 들어 TCP의 경쟁적인 특성을 완화하고자 **RTT를 고려한 대역폭 할당 방식**을 적용하거나, **다중 연결 사용을 제한하는 정책을 활용**하는 방법이 있습니다.\n\n#### TCP Cubic\n기존의 TCP Reno는 네트워크 대역폭이 높거나 지연 시간이 큰 경우 네트워크 활용도가 낮다는 문제가 있었습니다.\n이를 해결하기 위해 TCP의 여러 개선 버전이 등장했고, 그 중 하나가 TCP CUBIC 입니다. \n\nTCP CUBIC은 **CUBIC 다항식 항수를 사용하여 `cwnd` 크기를 조절**합니다.\n\n**핵심 아이디어**\n\nTCP가 세 개의 중복 ACK을 받았을 때, `cwnd` 크기를 절반으로 감소시킵니다. \n\n윈도우 크기가 `W_max`일 때 패킷 손실이 발생하여 혼잡이 감지되었다고 가정하면, 다시 윈도우 크기를 증가시킬 때 **처음에는 빠르게 증가시키지만 `W_max`에 가까워질수록 증가 속도를 점진적으로 줄이는 방식**을 사용합니다.\n\n만약 `W_max`에 도달했는데도 패킷 손실이 발생하지 않는다면 이전 손실이 transient congestion이나 기타 원인으로 발생한 것일 수 있습니다.\n\n이 경우, **이후에는 윈도우 크기를 더 적극적으로 증가**시키는 방식으로 아래와 같이 동작합니다:\n\n        W(t) = C(t-K)^3 + W_max\n\n        W_max: 마지막 패킷 손실이 발생했을 때 윈도우 크기\n        C: 스케일링 상수 (네트워크 환경에 따라 조정)\n        K: cwnd가 W_max로 도달하는데 걸리는 시간\n\n특히 TCP CUBIC의 중요한 특징은 **시간을 기준으로 윈도우 크기를 조절**한다는 점입니다.\n이를 통해 TCP CUBIC은 RTT가 다른 연결 간에도 보다 공정하게 네트워크 자원을 공유하는 **RTT-fair** 한 특성을 가질 수 있습니다.\n"},{slug:"system-design/event-broker-vs-message-broker",categorySlug:"system-design",title:{ko:"이벤트 브로커와 메시지 브로커",en:"Event Broker and Message Broker"},date:"2025-02-23 18:11",category:{ko:"시스템 디자인",en:"System Design"},description:{ko:"이벤트 브로커와 메시지 브로커의 차이, RabbitMQ와 Kafka의 동작 원리",en:"Difference between event broker and message broker, how RabbitMQ and Kafka work"},content:'\n오늘은 이벤트 브로커와 메시지 브로커, 그리고 각각의 대표적인 예시인 Apache Kafka와 RabbitMQ에 대해 알아보겠습니다.\n\n## 이벤트 브로커 (Event Broker)\n이벤트 브로커는 **시스템 내에서 일어나는 다양한 사건이나 상태 변화를 다른 컴포넌트에 전달**하는 중개자 역할을 합니다.\n\n예를 들어, 온라인 쇼핑몰에서는 사용자가 상품을 장바구니에 담거나 결제하는 등의 행동이 이벤트로 발생할 수 있습니다.\n이러한 이벤트들은 직접적으로 다른 컴포넌트에 전달되는 것이 아니라 이벤트 브로커를 통해 전달되어 **여러 시스템이나 서비스가 동시에 반응**할 수 있도록 할 수 있습니다.\n\n시스템의 각 부분은 이벤트 브로커를 통해 **서로 분리되어 동작**하게 되는데, 이를 통해 한 부분에서 발생한 변화가 다른 부분에 영향을 주더라도 서로 강하게 의존하지 않게 됩니다.\n\n만일 결제 시스템에 문제가 생겨도 주문 처리나 재고 관리 시스템은 이미 발생한 이벤트를 기반으로 자신의 업무를 계속 진행할 수 있습니다.\n\n이런 구조 덕분에 장애가 발생했을 때 **문제를 국소적으로 격리**할 수 있고 **시스템 전체의 안정성을 높일 수 있는 효과**가 있습니다. (Loose coupling)\n\n또한, 이벤트 브로커는 발생한 이벤트 데이터를 기록하고 저장하는 기능도 제공합니다. \n예를 들어 사용자가 웹사이트에서 발생시킨 모든 행동 기록을 이벤트 브로커가 수집해 저장해 놓으면 나중에 이 데이터를 분석해 **사용자 행동 패턴을 파악**하거나 **문제 발생 시 재처리할 수 있는 기반**을 마련할 수 있습니다.\n\n이러한 기능은 **실시간 모니터링**이나 **로그 수집**, **감사**와 같은 다양한 활용 사례에 유용하게 쓰입니다.\n\n### Pub/Sub 모델\n이벤트 브로커는 pub/sub 모델을 채택하고 있는데, 이 모델에서 이벤트를 생성하는 쪽은 **publisher**, 이벤트를 받아 처리하는 쪽은 **consumer**라고 부릅니다.\n\nPublisher는 자신이 **생성한 이벤트를 이벤트 브로커에 전달**하고, 이벤트 브로커는 이 **이벤트를 구독하고 있는 여러 consumer들에게 동시에 전달**합니다.\n\n예를 들어, 온라인 쇼핑몰에서 상품이 구매되면 결제 시스템, 주문 관리 시스템, 재고 관리 시스템, 심지어는 고객에게 알림을 보내는 시스템 등이 모두 이 이벤트를 받아 각각의 역할을 수행할 수 있습니다.\n\n다른 예시를 생각해보면 이벤트 브로커는 마치 **도서관의 사서**와 같다고 볼 수 있습니다.\n\n도서관에서 책을 요청하면 사서가 책을 찾아 여러 독자에게 전달해 주는 것처럼, 이벤트 브로커도 각 시스템의 요청이나 상태 변화를 받아 필요한 모든 곳에 전달합니다.\n이 과정에서 각 시스템은 직접 서로를 호출할 필요 없이 **간접적으로 소통**할 수 있게 됩니다.\n\n### Apache Kafka\nKafka는 이벤트 브로커의 대표적인 예시로 주로 **대용량의 실시간 데이터 스트림**을 처리하는 데 최적화되어 있습니다.\n\nKafka에서는 **모든 이벤트가 로그 형태로 기록**되며, 이 로그는 분산 시스템 내 여러 노드에 걸쳐 저장됩니다.\n\n예를 들어 대규모 웹 애플리케이션에서 사용자 행동 데이터나 서버 로그 같은 이벤트가 발생하면\n이 데이터를 Kafka에 기록해 여러 consumer가 동시에 실시간 분석, 모니터링, 경고 등의 작업을 수행할 수 있습니다.\n\nEvent broker의 특성처럼 Kafka의 pub/sub 모델은 publisher가 데이터를 보내면 여러 소비자가 그 로그를 구독하여 각자의 필요에 따라 데이터를 처리할 수 있습니다.\n이 과정에서 이벤트가 지속적으로 기록되기 때문에 **나중에 필요할 때 과거의 데이터를 재분석하거나 시스템 에러 발생 시 재처리**를 쉽게 할 수 있습니다.\n\n#### 예제\n월드컵처럼 실시간 이벤트가 많은 대회를 다루는 웹사이트를 운영한다고 가정해봅시다.\n\n경기가 진행되는 동안 골이 들어가거나 선수 교체가 이루어질 때마다 해당 정보를 빠르게 업데이트해야 합니다.\n\n이를 위해 이벤트가 발생할 때마다 **큐(queue)** 에 저장하며, 이벤트를 큐에 삽입하는 서버나 프로세스를 **producer**라고 부릅니다.\n\n반대로, 큐에서 이벤트를 읽고 웹사이트를 업데이트하는 서버를 **consumer**라고 합니다.\n\n현재 월드컵은 48개 팀이 참가하지만, 만약 1000개 팀이 동시에 경기를 진행하는 대회로 확장된다면 발생하는 이벤트 수가 급증할 것입니다.\n\n이 경우, 하나의 서버가 큐를 관리하는 방식으로는 부담을 감당하기 어렵고, consumer 또한 넘쳐나는 데이터를 처리하지 못할 것입니다.\n이 때는 **시스템을 확장하여 여러 대의 서버를 활용**해야 하는 상황이 발생합니다.\n\n그러나 단순히 여러 서버에 이벤트를 무작위로 분배하면 문제가 생길 수 있습니다.\n예를 들어, 어떤 서버에서는 경기가 시작되기 전에 골이 들어가는 것으로 표기될 수도 있고, 선수가 경고를 받기 전에 이미 퇴장당한 것으로 기록될 수도 있습니다.\n\n따라서 **이벤트 순서를 유지**하면서도 여러 서버에서 부하를 나누어 처리하는 방법이 필요합니다.\n\nKafka의 핵심 개념 중 하나는 **사용자가 직접 메시지의 분배 전략을 정의할 수 있다**는 것입니다.\n\n위 예제에서 가장 적절한 방법은 **경기단위로 이벤트를 분배하는 것**입니다. 즉, **같은 경기에 대한 이벤트는 동일한 큐(Partition)에 저장되도록 구성**하면 한 경기 내에서는 모든 이벤트가 순서대로 처리될 수 있습니다.\n\n하지만 consumer가 **처리해야 할 데이터가 너무 많다**면 어떻게 해결할 수 있을까요?\n\nKafka에서는 **consumer group**을 활용해 이 문제를 해결할 수 있습니다. 여러 consumer가 같은 consumer group에 속하면 Kafka는 **각 이벤트가 오직 하나의 consumer에게만 할당되도록 보장**합니다.\n그럼 부하를 여러 consumer가 나누어 처리하면서도 중복 처리를 방지할 수 있습니다.\n\n만약 웹사이트가 축구뿐만 아니라 농구 같은 다른 스포츠 이벤트도 다루기로 결정했다면 Kafka의 **topic** 개념을 활용할 수 있습니다.\n\n**각 이벤트는 특정한 topic에 속하며, consumer는 특정한 토픽만 구독**하면 됩니다. 예를 들어 축구 웹사이트 전용 consumer는 축구 토픽만 구독하고, 농구 웹사이트 전용 consumer는 농구 토픽만 구독하면 됩니다.\n\n#### 기본 개념\n앞서 설명한 예제를 기반으로 Kafka의 핵심 개념에 대해 좀 더 알아보겠습니다.\n\n1. **Kafka 클러스터와 브로커**\n    \n    Kafka 클러스터는 여러 개의 **브로커**로 구성 됩니다.\n    브로커는 각각 독립적인 서버로, 데이터를 저장하고 클라이언트 요청을 처리하는 역할을 합니다.\n    브로커가 많을수록 더 많은 데이터를 저장할 수 있고, 더 많은 클라이언트를 처리할 수 있습니다.\n\n2. **파티션과 로그 구조**\n\n    각 브로커는 여러 개의 **파티션**을 가집니다.\n    파티션은 **불변(immutable)한 메시지의 순차적인 저장 공간**으로, 새로운 메시지가 계속 추가되는 구조입니다.\n    이 구조는 **로그(log) 파일**과 유사하게 생각하면 됩니다.\n    Kafka는 파티션 단위로 데이터를 분산 저장하고 병렬로 처리하기 때문에 파티션을 통해 시스템을 확장할 수 있습니다.\n\n3. **토픽과 파티션의 차이**\n    \n    **토픽은 파티션을 논리적으로 그룹화하는 개념**입니다.\n    Kafka에서 데이터를 주고받을 때는 항상 특정 토픽을 통해 이루어집니다.\n    토픽은 항상 **다중 producer를 허용**하며, 하나의 토픽에는 0개, 1개, 또는 여러 개의 producer가 데이터를 쓸 수 있습니다.\n\n4. **Kafka의 메시지 큐 vs. 스트림 처리 방식**\n    \n    Kafka는 **메시지 큐(Message Queue)** 로 사용할 수도 있고, **스트림(Stream)** 으로 사용할 수도 있습니다.\n    \n    메시지 큐 방식은 consumer가 메시지를 읽은 후 **처리가 완료되었음을 명시적으로 확인**합니다.\n    스트림 방식은 consumer가 메시지를 읽고 처리는 하지만 **Kafka에 처리 완료를 하지는 않습니다**.\n\n#### 동작 원리\nKafka에서 이벤트가 발생하면 producer는 메시지를 포맷팅한 후 토픽으로 전송합니다.\nKafka의 메시지는 필수 필드인 **value**와 선택 필드인 **key, timestamp, headers**로 구성됩니다. \n\n    Key: 메시지가 어느 파티션에 저장될지를 결정하는데 사용됩니다. key가 없으면 Kafka는 메시지를 무작위로 파티션에 배치합니다.\n    Timestamp: 메시지의 순서를 결정하는데 사용됩니다.\n    headers: HTTP header처럼 키-값 쌍으로 메타데이터를 저장할 수 있습니다. \n\n1. **파티션 할당 및 브로커 처리**\n    \n    Kafka는 메시지의 키를 해싱하여 특정 파티션에 할당합니다.\n    키가 없는 경우 **라운드 로빈**이나 설정된 다른 로직을 이용해 파티션을 배정합니다.\n    여기서 **같은 키를 가진 메시지는 항상 같은 파티션에 저장되어 순서가 유지**됩니다.\n    \n    Kafka는 메시지가 할당된 **파티션을 어느 브로커가 관리하는지 확인**하기도 합니다.\n    **Kafka 컨트롤러**가 이 메타데이터를 유지하고 Producer는 해당 브로커로 메시지를 전송하게 됩니다.\n\n2. **Kafka의 로그 구조 및 메시지 처리 방식**\n\n    **파티션**은 **append-only log** 형태로 동작하는데, 메시지는 끝에 추가되며 수정이나 삭제되지 않습니다.\n    \n    이 방식이 가지는 장점은 다음과 같습니다.\n        \n        불변성 (Immutability): 메시지가 한 번 저장되면 변경되지 않아 일관성이 유지됩니다.\n        고성능 (Efficiency): 디스크의 순차 쓰기(sequential write)를 활용하여 높은 처리량을 제공합니다.\n        확장성 (Scalability): 파티션을 여러 브로커에 분산시켜 시스템 부하를 효율적으로 분배할 수 있습니다.\n\n    Kafka의 메시지는 **각 파티션 내에서만 순서가 보장**되며, 각 메시지는 **offset**을 부여받습니다.\n    여기서 offset은 **특정 파티션에서의 메시지 위치**를 나타내고, consumer가 메시지를 읽을 때 이걸 기준으로 진행 상태를 관리합니다.\n    \n3. **복제 및 내구성**\n\n    Kafka는 **leader-follower** 모델을 이용해 데이터 복제를 수행합니다.\n        \n        리더 복제본 (Leader replica): 각 파티션의 리더는 메시지의 읽기 및 쓰기를 담당합니다.\n        팔로워 복제본 (Follower replica): 다른 브로커에 분산 저장되어 리더 복제본을 백업하는 역할을 합니다.\n        동기화 및 장애 복구 (sync and failover): 팔로워들은 리더의 메시지를 동기화하며 최신 데이터를 유지합니다.\n            만약 리더에 장애(failure)가 발생하면 최신 데이터를 가진 팔로워가 새로운 리더로 승격(promote)됩니다.\n            Kafka의 컨트롤러가 전체 복제 및 장애 조치를 관리합니다.\n    \n4. **Consumer의 동작 방식**\n    \n    consumer는 토픽에서 메시지를 읽어오는 역할을 하는데 두 가지 방식으로 동작할 수 있습니다.\n    \n    1. **Push model**: 메시지가 도착하면 즉시 consumer에게 전달\n    2. **Pull model**: consumer가 일정 주기로 Kafka에서 메시지를 조회    \n\n#### Kafka는 언제 사용해야 할까?\n위에서 정리했다시피 Kafka는 **메시지 큐** 또는 **스트림**으로 활용될 수 있으며 두 방식의 가장 큰 차이는 **consumer가 데이터를 처리하는 방식**에 있습니다.\n\n1. **메시지 큐로 사용하는 것이 적절한 경우**\n    \n    1. **비동기 처리가 필요한 경우**:\n    Youtube와 같은 비디오 플랫폼을 예로 들어봅시다. 사용자가 동영상을 업로드하면 저화질 버전은 즉시 제공하고 고화질 인코딩은 Kafka 토픽에 메시지를 추가하여 여유가 생길 때 처리할 수 있습니다.\n    \n    2. **메시지의 순서를 보장해야 하는 경우**:\n    온라인 티켓 예매 시스템 같은 경우 사용자가 도착한 순서대로 티켓 구매 페이지에 접근해야 합니다.\n    Kafka를 **가상 대기열로 활용**하면서 사용자가 접근한 **순서를 유지하며 메시지를 소비하도록 보장**할 수 있습니다.\n    \n    3. **Producer와 consumer를 분리하여 독립적으로 확장해야 하는 경우**:\n    일반적으로 **producer가 메시지를 생성하는 속도가 consumer가 처리하는 속도보다 빠를 때** 발생합니다. \n    MSA (Microservice Architecture) 에서는 서비스 간 결합도를 낮추고, 특정 서비스가 다운되더라도 다른 서비스에 영향을 주지 않도록 비동기 메시지 큐를 활용합니다.\n    \n2. **스트림으로 사용하는 것이 적절한 경우**\n    \n    1. **실시간으로 데이터를 지속적으로 처리해야 하는 경우**:\n    광고 클릭 데이터를 실시간으로 수집/집계하는 Ad Click Aggregator 시스템을 예로 들 수 있습니다.\n    Kafka를 활용하면 **실시간으로 수집된 클릭 데이터를 빠르게 분석하고 광고주에게 즉시 피드백을 제공**할 수 있습니다.\n    \n    2. **여러 consumer가 동시에 메시지를 처리해야 하는 경우**:\n    Youtube live 댓글 시스템 같은 실시간 방송 플랫폼에서는 댓글을 여러 consumer에게 동시에 전달해야 합니다.\n    Kafka를 pub/sub system으로 활용하면 **여러 consumer가 동일한 메시지를 소비할 수 있도록 보장**할 수 있습니다.\n\n#### 단일 브로커의 성능 한계\nKafka를 이용한 설계를 할 때는 먼저 단일 Kafka 브로커의 한계를 이해하는 것이 중요합니다.\n**예상되는 메시지 처리량(throughput)** 과 **메시지 크기**를 잘 고려하여 확장이 필요한지에 대한 여부를 판단해야 합니다.\n\nKafka 메시지 크기에는 **hard limit이 없지만** 설정 파일에서 `message.max.bytes`를 통해 조정할 수 있습니다.\n그러나 최적의 성능을 위해선 **메시지 크기를 1MB 이하로 유지**하는 것이 권장됩니다.\n메시지가 작을수록 메모리 부담이 줄어들고 네트워크 활용이 최적화되기 때문입니다.\n\n또한, Kafka는 데이터베이스가 아니며 대형 파일 저장용 시스템도 아니라는 점을 명심해야 합니다.\n**메시지는 빠르게 처리될 수 있어야 하고 큰 데이터를 직접 저장하는 것은 비효율적**입니다.\n\n예를 들어 Youtube같은 동영상 플랫폼을 설계할 때 업로드된 동영상을 Kafka에 저장하는 것이 아니라 S3 같은 분산 파일 시스템에 저장하고, Kafka 메시지에는 **해당 파일의 위치만 저장**하는 것이 올바른 접근법입니다.\n\n좋은 하드웨어 환경에서는 단일 브로커가 약 **1TB의 데이터를 저장**하고 **최대 100만개의 메시지를 초당 처리**할 수 있습니다.\n다만, 이는 메시지 크기와 하드웨어 사양에 따라 다를 수 있고 일반적인 개략적 추정치입니다.\n만약 Kafka의 처리량이 이 범위를 넘지 않는다면 확장을 고려할 필요가 없을 수도 있습니다.\n    \n#### 확장 전략\n1. **수평 확장 (Horizontal scaling)**\n    \n    가장 단순한 방법은 **Kafka 클러스터에 더 많은 브로커를 추가**하는 것입니다.\n    브로커를 추가하면 로드가 분산되며 장애 내성이 향상됩니다.\n    \n    그러나 브로커를 추가하는 것만으로는 확장이 되지 않는데, **토픽의 파티션 개수를 충분히 설정**해야 브로커 추가의 효과를 볼 수 있습니다.\n    파티션이 충분하지 않으면 새로 추가된 브로커가 활용되지 않으므로 파티션 개수 증가가 필수입니다.\n    \n2. **파티셔닝 전략 (Partitioning strategy)**\n    \n    가장 중요한 확장 전략은 **어떻게 데이터를 파티션할 것인지 결정하는 것**입니다.\n    \n    Kafka는 메시지 키의 해시값을 기반으로 파티션을 결정하는데 잘못된 키 선택은 특정 파티션에 과부하(**Hot partition**)를 발생시킬 수 있습니다. \n    좋은 키를 선택하려면 트래픽이 고르게 분산될 수 있도록 설계해야 합니다.\n\n#### Hot Partition 문제 해결 전략\n1. **무작위 파티셔닝 (Random Partitioning)**\n    \n    키를 제공하지 않으면 Kafka는 메시지를 랜덤한 파티션으로 분배합니다.\n    이 방법은 트래픽이 균등하게 분산된다는 장점이 있지만 **메시지 순서 보장이 어렵습니다.**\n    메시지 순서가 중요하지 않은 경우에 사용 가능합니다.\n    \n2. **랜덤 솔팅 (Random Salting)**\n    \n    **키 값에 랜덤 값(숫자, Timestamp 등)을 추가**하여 분산을 유도하는 기법입니다.\n    예를 들어, 광고 클릭 로그를 `ad_id` 기반으로 파티셔닝하면 특정 인기 광고에 트래픽이 집중될 가능성이 있습니다.\n    \n    여기서 `ad_id + random_salt`를 사용해서 여러 파티션에 트래픽을 분산할 수 있습니다.\n    단, **consumer에서 데이터를 집계하는 로직이 복잡**해질 수 있습니다.\n    \n3. **복합 키 (Compound Key) 사용**\n  \n    단일 `ad_id` 대신 `ad_id + geolocation`, `ad_id + user_id` 등 복합 키를 사용하여 트래픽을 분산할 수 있습니다.\n   \n4. **백 프레셔 (Back Pressure) 적용**\n    \n    과부하가 발생하면 **producer가 메시지를 생성하는 속도를 늦추도록** 조정할 수도 있습니다.\n    \n#### 성능 최적화\n\nKafka를 이벤트 스트림으로 사용할 경우 성능 최적화가 중요해집니다.\n\n이 때, **배치 전송**과 **메시지 압축** 등과 같은 기법을 사용할 수 있습니다.\n\n배치 전송은 producer가 메시지를 개별적으로 전송하는 대신 일정량을 모아서 한 번에 전송하는 방법입니다.\n\n또한, KafKa는 GZIP, Snappy, LZ4 등의 압축 알고리즘을 지원하며 압축을 활성화하면 네트워크 전송 속도를 높이고 저장 공간을 절약할 수 있습니다.\n\n## 메시지 브로커 (Message Broker)\n메시지 브로커의 주요 목적은 **메시지를 안정적으로 전송하고 각 시스템이 독립적으로 작동**할 수 있도록 하는 것입니다.\n\n메시지 브로커는 메시지를 **Queue나 Topic과 같은 구조에 저장**하고, consumer가 준비되면 해당 메시지를 전달하여 순차적 또는 병렬적으로 처리할 수 있게 합니다.\n\n예를 들어, 사용자가 주문을 완료하면 메시지 브로커는 이 주문 데이터를 결제 처리 시스템에 전달하고, 결제가 완료된 후 다시 주문 처리 시스템에 결과를 전달하는 과정을 중개합니다.\n\n이벤트 브로커가 도서관의 사서와 같았다면 메시지 브로커는 **우편 배달 시스템**과 비슷하다고 볼 수 있습니다.\n\n편지를 보내는 사람이 직접 수취인에게 전달하는 대신 우체국에 맡기는 것처럼 메시지 브로커는 발신자로부터 메시지를 받아 중간에서 필요한 곳으로 전달합니다.\n\n### RabbitMQ\nRabbitMQ는 전통적인 메시지 브로커의 대표적인 예입니다.\n\nRabbitMQ에서는 **메시지가 큐에 저장되고, consumer가 해당 큐에서 하나씩 메시지를 가져와 처리하는 방식**으로 동작합니다.\n\n예를 들어 전자상거래 시스템에서 주문이 들어오면 주문 처리 요청 메시지가 RabbitMQ 큐에 저장되고, 주문 처리 서비스가 이 큐에서 메시지를 하나씩 꺼내 처리합니다.\n\nRabbitMQ의 **라우팅 기능**을 이용하면 특정 조건이나 주제에 따라 메시지를 다양한 큐로 분배할 수 있어 시스템 간의 통신을 보다 세밀하게 조절할 수 있습니다.\n\n#### 동작 원리\nRabbitMQ의 기본 구성 요소는 크게 **producer, consumer, exchange, queue, binding**으로 구분할 수 있습니다.\n\n**Producer**는 애플리케이션에서 **메시지를 생성하고 RabbitMQ에 전달**하는 역할을 합니다.\n이때 메시지를 직접 queue에 넣는 것이 아니라, 먼저 **exchange로 메시지를 전송**합니다.\n\n**Exchang**e는 들어오는 **메시지를 어떻게 queue로 라우팅할 것인지 결정**하는 중추적인 역할을 합니다.\nExchange엔 여러 종류가 있는데, 대표적으로 **direct, topic, fanout, headers** exchange가 있습니다.\n각 exchange는 routing key나 바인딩 조건에 따라 메시지를 적절한 queue로 분배합니다.\n\n**Queue**는 **실제로 메시지가 저장되는 공간**입니다.\n메시지는 저장된 후, 준비된 consumer에게 전달되어 처리됩니다.\n\nRabbitMQ는 메세지의 신뢰성과 안정성 보장을 위해 큐에 저장된 메시지에 대해 **persistence 옵션을 제공**하며, \nconsumer가 메시지를 받아 처리한 후에는 메시지에 대한 **ACK을 받아야 메시지를 삭제**합니다.\n이 과정은 메시지 유실이나 중복 처리 방지에 중요한 역할을 합니다.\n\n**Binding**은 exchange와 queue 사이의 **연결 규칙을 정의**합니다.\nBinding을 통해 특정 routing key나 패턴에 맞는 메시지가 어떤 queue로 전달될지 결정되므로, 메시지 흐름을 세밀하게 정의할 수 있습니다.\n\n**Consumer**는 큐에 저장된 **메시지를 받아 처리**하는 역할을 합니다.\n여러 consumer가 하나의 큐를 구독할 경우, RabbitMQ는 메시지를 **라운드 로빈 방식** 등으로 분배하여 각 consumer가 메시지를 균등하게 처리할 수 있도록 지원합니다.\n\nConsumer가 메시지를 처리하고 난 후 ACK을 보내야하는데, 만약 메시지 처리에 실패하면 RabbitMQ는 해당 메시지를 **재전달하거나 DLX 또는 다른 큐로 라우팅** 할 수 있습니다.\n\n\n## 차이점\n이벤트 브로커는 **"어떤 일이 발생했다"는 사실 자체를 전파**하는 데 중점을 둡니다. 예를 들어 온라인 쇼핑몰에서 사용자가 결제를 완료했을 때 그 사건을 기록하고 여러 시스템에 동시에 알리는 역할을 할 수 있습니다.\n\n반면, 메시지 브로커는 **특정 작업이나 요청을 안전하게 전달**하는 데 집중합니다.\n예를 들어, 주문 처리를 위해 결제 요청을 보내거나 작업 큐에 저장된 작업을 하나씩 처리하는 시스템에서 메시지 브로커는 메시지를 큐잉하여 전달하고, 재시도나 배달 보증 등의 기능을 통해 데이터의 신뢰성을 보장합니다.\n\n또한 이벤트 브로커는 이벤트 자체를 **지속적으로 기록하고 저장**하여 나중에 재처리나 분석에 활용할 수 있는 반면, 메시지 브로커는 일반적으로 메시지를 즉시 처리하는 **단기적인 데이터 전달**에 집중합니다.\n\n이처럼 이벤트 브로커는 주로 **시스템의 상태 변화나 사건 발생의 "기록"** 을 다루고, 메시지 브로커는 **특정 작업의 "수행"** 과 관련된 데이터를 다루는 데 초점을 맞춥니다.\n\nKafka와 RabbitMQ 사용 사례를 비교하자면 Kafka는 **높은 처리량, 내구성, 재처리 기능** 등이 중요한 이벤트 스트리밍 환경에, RabbitMQ는 **복잡한 라우팅, 메세지 우선 순위, 큐 기반의 작업 분산 처리**와 같은 요구 사항이 있을 때 효과적인 선택이 됩니다.\n\n## References\nhttps://medium.com/riskified-technology/message-broker-vs-event-broker-when-to-use-each-one-of-them-15597320a8ba#:~:text=I%20would%20like%20to%20discuss,have%20a%20working%20experience%20with.\nhttps://kafka.apache.org/uses\nhttps://www.cloudamqp.com/blog/rabbitmq-use-cases-explaining-message-queues-and-when-to-use-them.html\nhttps://www.youtube.com/watch?v=DU8o-OTeoCc&ab_channel=HelloInterview-SWEInterviewPreparation\nhttps://medium.com/riskified-technology/message-broker-vs-event-broker-when-to-use-each-one-of-them-15597320a8ba\n'},{slug:"computer-networks/intradomain-routing-algorithm",categorySlug:"computer-networks",title:{ko:"인트라도메인 라우팅 알고리즘",en:"Intradomain Routing Algorithm"},date:"2025-02-23 14:21",category:{ko:"컴퓨터 네트워크",en:"Computer Networks"},description:{ko:"인트라도메인 라우팅에 대해 자세히 알아봅시다",en:"Deep dive into Intradomain Routing Algorithm"},content:"\n## 개요\n네트워크의 근본적인 목표는 **두 호스트 간의 데이터 전송을 가능하게 하는 것**입니다.\n이를 위해 데이터를 출발지에서 목적지까지 효율적으로 전달하는 **최적의 경로**를 찾는 것이 중요합니다.\n\n이번 글에서는 단일 관리 도메인 내 라우터들 간 최적의 경로를 결정하는 **인트라도메인 라우팅 알고리즘**에 대해 알아보도록 하겠습니다.\n\n## 라우팅 알고리즘\n\nTCP 또는 UDP를 이용해 연결이 설정된 두 호스트를 예로 들어보겠습니다.\n\n각 호스트는 **기본 라우터 (default router)** 를 알고 있으며, 패킷을 전송할 때 먼저 이 기본 라우터로 보냅니다.\n하지만 **기본 라우터를 지난 후에는 어떤 일이 일어날까요?**\n\n패킷이 출발지에서 목적지로 이동하는 동안, 각 **중간 라우터는 패킷을 적절한 다음 라우터로 전달하는 역할**을 합니다.\n\n패킷이 라우터에 도착하면 라우터는 **포워딩 테이블 (Forwarding table)** 을 참조하여 해당 패킷을 어느 인터페이스를 통해 전송할지 결정합니다.\n여기서 **포워딩**은 **라우터 내에서 패킷을 들어오는 링크에서 나가는 링크로 전달하는 과정**을 의미합니다.\n\n반면 **라우팅**은 라우터들이 **라우팅 프로토콜을 사용하여 최적의 경로를 설정하는 과정**을 의미합니다.\n만약 동일한 관리 도메인에 속한 라우터들 간의 경로를 설정하는 경우, 이를 **인트라도메인 라우팅** 또는 **Interior Gateway Protocol(IGP)** 라고 합니다.\n서로 다른 관리 도메인에 속한 라우터들이 협력하여 경로를 결정하는 경우, 이건 **인터도메인(interdomain) 라우팅**이라고 합니다.\n\n이번 글에서는 **인트라도메인 라우팅 알고리즘**을 중심으로 살펴볼텐데, 보다 쉽게 이해하기 위해서 네트워크를 그래프로 모델링할 수 있습니다.\n\n이 때 **라우터는 노드(node)** 로 표현 되고, **라우터간의 연결(link)는 엣지(edge)** 로 표현할 수 있습니다.\n그리고 각 엣지에는 특정한 **비용(cost)** 이 할당됩니다.\n\n## Link-state Routing Algorithm\n링크 상태 알고리즘에서는 **다익스트라 알고리즘**을 기반으로 하여 출발지에서 모든 노드까지의 최단경로 트리(Shortest Path Tree, SPT)를 구성합니다. \n여기서는 **네트워크 내 모든 노드가 전체 네트워크 토폴로지와 링크 비용**을 알고 있고, 이 정보는 **브로드캐스트**를 통해 모든 노드에게 전달됩니다.\n\n#### 기본 용어\n     u: 출발지 노드(기준 노드)\n     v: 네트워크 내의 모든 다른 노드\n     D(v): 출발지 노드 u에서 v까지 현재 알려진 최소 비용 경로\n     p(v): 출발지 노드 u에서 v까지 현재 최소 비용 경로에서 v 바로 직전의 노드\n     c(u, v): 출발지 노드 u에서 직접 연결된 이웃 v까지의 비용\n     N': 출발지 노드 u에서 현재까지 확정된 최소 비용 경로에 포함된 노드의 집합\n#### 알고리즘\n1. **초기화**\n\n    **다익스트라 알고리즘(Dijkstra's algorithm)** 은 먼저 **출발지 노드 `u`의 직접 연결된 이웃들에 대한 비용을 설정**하는 단계로 시작됩니다.\n    출발지 `u`와 직접 연결된 노드는 링크 비용을 그대로 사용하고, 연결되지 않은 노드들은 무한대 값으로 설정됩니다.\n    \n    또한, `N'`은 처음에 출발지 노드 u만 포함하도록 설정됩니다.\n\n2. **반복 연산**\n    \n    초기화 이후에는 반복문을 통해 **모든 목적지 노드 `v`에 대해 경로를 찾는 과정**을 거칩니다.\n    \n    먼저 아직 `N'`에 포함되지 않은 노드 중에서 현재까지의 최소 비용을 가진 노드 `w`를 선택하고, 그 노드를 `N'` 집합에 추가합니다.\n    \n    그리고 `w`의 모든 이웃 노드 `v`에 대해 `D(v)`를 업데이트 합니다.\n    \n    `D(v)`의 값은 기존 `D(v)` 값과, 현재까지의 최소 비용 경로 `D(w)`에 대해 `w`에서 `v`까지의 비용을 더한 값 중 작은 값으로 갱신됩니다.\n\n    `D(v) = min(D(v), D(w) + c(w,v))`\n    \n    위 과정을 네트워크의 모든 노드가 `N'`에 포함될 때까지 반복합니다.\n\n최종 결과로 **출발지 `u`에서 모든 노드까지의 최단경로 트리**를 구성하게 됩니다.\n\n#### 계산 복잡도\n이 알고리즘에서 최단 경로를 찾기위해 수행해야 하는 주요 연산은 **최소 비용을 가지는 노드를 찾는 것**과 **해당 노드를 기준으로 다른 노드들의 경로 비용을 업데이트하는 것**으로 나눌 수 있습니다.\n\n1. 첫 번째 iteration에서는 전체 n개의 노드 중에서 최소 비용을 가지는 노드를 찾아야 합니다.\n2. 두 번째 iteration에서는 남아있는 n-1 개의 노드 중에서 최소 비용 노드를 찾습니다.\n3. 세 번째 iteration에서는 n-2개를 탐색하고, 이런 식으로 마지막에는 1개의 노드만 남습니다.\n\n따라서 전체적으로 탐색해야 하는 노드 개수는 다음과 같습니다:\n\n**`n + (n - 1) + (n - 2) + ... + 1 = n(n+1)/2`**\n\n따라서 최악의 경우 O(n^2)의 시간 복잡도를 가지는데, 이 복잡도를 개선하기 위해 priority queue를 사용하면 최소 비용 노드를 찾는 연산을 O(log n)으로 줄일 수 있습니다.\n\n하지만 **기본적인 다익스트라 알고리즘에서는 O(n^2) 이므로, 일반적인 링크 상태 라우팅의 시간 복잡도도 같다**고 할 수 있습니다.\n\n또한, 출발지 노드가 u가 아닌 x인 경우에도, 이웃의 수가 달라도 알고리즘은 모든 노드가 포함될 때까지 동일한 반복 횟수를 수행합니다.\n\n## Distance-Vector Routing Algorithm\n거리 벡터 라우팅 알고리즘은 **반복적, 비동기적, 분산적** 방식으로 동작하는 방식입니다.\n\n이 알고리즘은 **Bellman-Ford 알고리즘**을 기반으로 하는데, 각 라우터는 자신이 목적지까지 도달하는 비용 정보를 담은 거리 벡터를 유지하고\n이 정보를 정기적으로 이웃 노드들과 교환하면서 네트워크의 최적 경로를 계산합니다.\n\n#### 알고리즘\n1. **초기화**\n\n    먼저, 각 노드는 **자신이 직접 연결된 이웃 노드들과의 링크 비용을 기반으로 초기 거리 벡터를 설정**합니다.\n    이웃하지 않은 노드에 대해서는 비용을 무한대로 설정합니다.\n\n2. **거리 벡터 교환 및 업데이트**\n\n    그 후, 각 노드는 **주기적으로** 또는 **링크 상태 변경이 감지**될 때 자신의 거리 벡터를 이웃 노드들에게 보냅니다.\n    \n    이웃 노드들은 수신한 거리 벡터를 기반으로 자신의 거리 벡터를 다음의 Bellman-Ford 방정식을 사용하여 업데이트합니다:\n        **`Dx(y) = min{c(x,v) + Dv(y)}`**\n    \n    즉, 노드 `x`가 목적지 `y`에 도달하는 최소 비용을 구하기 위해 **이웃 노드 `v`를 거쳐 가는 최소 경로**들을 고려합니다.\n\n3. **수렴**\n\n    네트워크 내 모든 라우터가 더 이상 새로운 업데이트를 받지 않아 **각자의 거리 벡터가 변경되지 않을 때** 최종 라우팅 테이블이 완성됩니다.\n\n거리 벡터 라우팅 알고리즘은 **구현이 간단하고 오버헤드가 적다**는 장점이 있지만\n네트워크 변경이 있을 경우 안정화 하는데 **시간이 오래 걸릴 수** 있는 단점이 있습니다.\n\n반면에 링크 상태 라우팅 알고리즘은 네트워크 전체의 토폴로지를 공유하여 **더 빠르고 안정적인 경로 설정**이 가능합니다.\n\n### Count-to-Infinity 문제\n거리 벡터 라우팅 알고리즘에서는 각 라우터가 주기적으로 자신의 거리 벡터를 이웃 라우터들에게 공유하고, 이를 기반으로 최적 경로를 갱신합니다.\n\n하지만 **링크 비용이 급격히 증가할 경우**, 잘못된 경로 정보가 반복적으로 업데이트되면서 두 개 이상의 노드가 서로를 통해 목적지에 도달한다고 잘못 판단하며 비용이 점진적으로 증가하는 **무한 루프 현상**이 발생할 수 있습니다.\n\n이를 해결하기 위해 **Split Horizon**이나 **Poison Reverse** 방법을 사용할 수 있습니다.\n#### Poison Reverse\n```\n            [X]\n           /   \\\n      (비용 4)  (비용 5)\n         /         \\\n      [Y]  <---->   [Z]\n```\n여기서 Y와 Z는 각각 X로 가는 경로를 가지고 있으며, 서로 정보를 교환합니다.\n만약 Z가 X로 가는 최적 경로가 Y를 통해서라고 판단한다면, Z는 Y의 정보를 참고하여 경로를 설정합니다.\n\n예를 들어, Y와 X 사이의 직접 연결 비용이 급격하게 증가하여 4에서 60이 되었다고 가정해봅시다.\nY는 직접 연결 비용이 높아졌으므로, “혹시 Z를 통해 X에 도달할 수 있지 않을까?” 하고 Z의 정보를 확인하게 됩니다.\n만약 Z 역시 Y를 통해 X에 도달하는 경로를 사용 중이라면, 잘못된 업데이트로 인해 Y와 Z가 서로를 참조하는 루프가 발생할 수 있습니다.\n```\n                  [X]\n                 /   \\\n        (직접 비용 60)  (직접 비용 5)\n               /           \\\n            [Y]  <------>   [Z]\n                    ↑\n    (Poison Reverse: Z는 Y에게 X 비용을 ∞로 전달)\n```\nPoison Reverse 기법을 사용하면 **라우터 Z는 자신이 X로 가는 최적 경로가 Y를 경유하는 경우, Y에게 “X로 가는 비용이 ∞입니다”라고 광고**합니다.\n이렇게 되면, Y는 Z로부터 받은 정보에 따라 “내가 X로 가기 위해 Z를 경유하는 것은 불가능하다(비용이 무한대)”고 판단하여, 루프 형성을 방지할 수 있습니다.\n\n단, 이 방법은 두 노드 간의 문제 해결에는 효과적이지만 3개 이상의 노드가 관련된 경우에는 해결책이 되지 않습니다.\n\n## Routing protocol 예제\n### RIP (Routing Information Protocol)\nRIP는 거리 벡터 알고리즘을 기반으로 하는 애플리케이션 레벨 프로세스 프로토콜로, **홉 수(Hop count)** 를 메트릭으로 사용합니다. \n\n인접 라우터 간에 주기적으로 RIP 응답 메시지를 통해 자신의 거리 벡터(목적지까지의 홉 수 정보)를 교환하고, \n각 라우터는 목적지 서브넷, 해당 목적지로 가기 위한 최단 경로상의 다음 라우터, 그리고 홉 수 정보를 포함하는 라우팅 테이블을 유지합니다.\n\n만약 라우터가 **일정 시간동안 인접 라우터로부터 업데이트를 받지 못하면**, 해당 이웃을 연결이 끊긴 것으로 간주하고 라우팅 테이블을 갱신합니다.\n\n하지만 **경로 업데이트의 지연, 수렴 시간, 그리고 count-to-infinity 문제** 등이 RIP의 단점으로 지적됩니다.\n\n### OSPF (Open Shortest Path First)\nOSPF는 링크 상태 라우팅 프로토콜로 대규모 네트워크나 ISP (Internet Service Provider) 환경에서 주로 사용됩니다.\n\nOSPF에서는 모든 라우터가 **Link State Advertisement (LSA)** 를 통해 자신과 입접 라우터의 링크 상태를 브로드캐스트하고, 전체 네트워크의 토폴로지를 구성합니다.\n\n여기서 네트워크를 여러 영역으로 나눌 수 있으며, 이 중 하나의 영역은 **백본 영역(Backbone area)** 으로 지정되어 다른 영역 간의 라우팅을 담당합니다.\n\n각 라우터는 다익스트라 알고리즘을 사용하여 **자신을 기준으로 SPT를 구성**하고, 이를 기반으로 **포워딩 정보(FIB)를 업데이트** 합니다.\n\n링크 상태 변화가 감지되면 즉시 LSA를 플러딩하여 네트워크 전체에 전파하며, 정기적으로도 갱신됩니다.\n\n#### OSPF 메시지 처리 과정\n1. **LS 업데이트 수신**\n    \n    인접 라우터로부터 LS 업데이트 패킷(여러 LSA 포함)을 수신하면 OSPF processor가 이를 분석하여 새로운 LSA인지 중복 LSA인지를 확인합니다. \n    \n2. **링크 상태 데이터베이스 갱신 및 SPF 예약**\n    \n    새로운 LSA일 경우, **링크 상태 데이터베이스를 갱신**하고, 이후 다익스트라 기반의 **SPF 계산을 예약**합니다.\n    \n3. **LSA 플러딩**\n    \n    처리된 LSA는 적절한 인터페이스를 통해 인접 라우터로 다시 플러딩 됩니다.\n    \n4. **SPF 계산 및 FIB 업데이트**\n\n    예약된 SPF 계산이 실행되어 SPT를 구성하고, 그 결과가 FIB에 저장됩니다.\n    \n5. **데이터 패킷 전달**\n\n    업데이트된 FIB를 참고하여 실제 데이터 패킷이 적절한 인터페이스로 전송됩니다.\n\n## Hot Potato Routing\n대규모 네트워크에서는 내부 라우팅(IGP)와 외부 라우팅(BGP)이 함께 사용됩니다.\n\n목적지가 네트워크 외부인 경우, 네트워크 내부에서는 여러 개의 출구 지점(egress point) 중 **IGP 비용이 가장 낮은**,\n즉 **가장 가까운 출구를 선택하여 패킷을 빠르게 외부로 내보내는 방식**을 Hot Potato Routing이라고 합니다.\n"},{slug:"system-design/elasticsearch",categorySlug:"system-design",title:{ko:"엘라스틱서치",en:"Elasticsearch"},date:"2025-02-24 14:16",category:{ko:"시스템 디자인",en:"System Design"},description:{ko:"엘라스틱서치의 기본 개념과 동작 원리",en:"Intro to Elasticsearch and how it works"},content:'\n## 개요\n시스템을 설계할 때 종종 **많은 데이터 중에서 원하는 정보를 찾아내는** 작업이 필요할 때가 있습니다.\n이 때, 일반적인 데이터베이스로 충분할 때도 있지만 데이터가 많거나 검색 조건이 복잡할 경우엔 전용 검색 엔진이 필요하기도 합니다.\n\nElasticsearch는 그 중 대표적인 **검색 엔진**으로 **정렬, 필터링, 순위 매김, 페이징** 등 다양한 기능을 제공합니다.\n\n또한, 내부 동작 원리를 이해한다면 **분산 시스템 설계, 데이터 구조 최적화, immutable** 등과 같은 개념을 배울 수도 있습니다.\n\n## 기본 개념\nElasticsearch의 핵심 구성 요소는 **문서, 인덱스, 매핑, 필드** 입니다.\n\n1. **문서(Document)**\n\n    **문서**는 **검색 대상이 되는 데이터의 최소 단위**입니다. \n    \n    반드시 웹 페이지나 글일 필요는 없으며 단순한 **JSON 객체**로 표현할 수 있습니다.\n    예를 들어, 영화 데이터베이스를 구축한다고 가정하면 아래와 같이 하나의 문서가 영화 한 편의 정보를 담습니다.\n    ```\n    {\n      "id": "MOV001",\n      "title": "기생충",\n      "director": "봉준호",\n      "rating": 8.6,\n      "releaseDate": "2025-01-01T00:00:00.000Z"\n    }\n    ```\n\n2. **인덱스(Index)**\n\n    인덱스는 **여러 문서들을 논리적으로 모아둔 컨테이너**입니다.\n    \n    **데이터베이스의 테이블**과 유사한 개념으로, 예를 들면 `movies`라는 인덱스에 영화 정보들이 모두 저장됩니다.\n\n3. **매핑(Mapping)**\n\n    **매핑**은 **인덱스에 저장될 데이터의 구조(스키마)를 정의**합니다.\n     \n    즉, 각 문서에 포함된 필드(제목, 감독, 평점, 개봉일 등)의 데이터 타입과 검색 방법을 미리 지정합니다.\n    예를 들어, 아래와 같은 매핑을 설정하면 `id`는 정확한 값 검색이 가능한 `keyword` type, `title`은 텍스트 분석을 거쳐 검색할 수 있는 `text` type 등으로 지정할 수 있습니다.\n\n    단, **매핑에 너무 많은 필드를 포함**시키면 실제 검색에 사용하지 않는 데이터까지 인덱싱되어 **클러스터 메모리 오버헤드가 증가**할 수 있으므로 주의해야 합니다.\n\n    ```\n    {\n      "properties": {\n        "id": { "type": "keyword" },\n        "title": { "type": "text" },\n        "director": { "type": "text" },\n        "rating": { "type": "float" },\n        "releaseDate": { "type": "date" }\n      }\n    }\n    ```\n\n## 사용법\nElasticsearch는 **REST API**를 통해 인덱스 생성, 데이터 저장, 검색 등을 수행할 수 있습니다.\n\n자세한 사용법은 엘라스틱서치 공식 문서에서 쉽게 찾아보실 수 있습니다.\n\n## 동작 원리\nElasticsearch는 아주 빠른 검색을 도와주는 프로그램인 **Apache Lucene** 위에서 동작하는 여러 작업들을 조율하는 상위 시스템이라고 볼 수 있습니다.\n\n쉽게 말하면, **Lucene**은 영화 제목이나 감독 같은 **정보를 빠르게 찾을 수 있도록 도와주는 엔진(검색 도구)** 이고, **Elasticsearch**는 이 **Lucene 엔진을 여러 대의 노드에서 동시에 사용할 수 있게 관리해주는 역할**을 합니다.\n\nElasticsearch 클러스터는 여러 종류의 **노드**로 이루어져 있습니다.\n각 노드는 영화 데이터를 저장하거나 검색 요청을 받아 처리하는 등 서로 다른 역할을 맡습니다.\n\n- **마스터 노드**는 전체 클러스터를 관리하며 **새로운 노드를 클러스터에 추가**하거나 **불필요한 노드를 제거하는 등**의 클러스터 수준의 작업을 합니다.\n\n- **데이터 노드**는 **실제로 데이터를 저장하는 역할**을 합니다.\n여기서 저장된 데이터는 실제 영화 저장뿐만 아니라, 검색을 빠르게 하기 위해 미리 만들어 둔 **Lucene 인덱스도 포함**됩니다.\n\n- **코디네이팅 노드**는 사용자로부터 "영화 \'인셉션\' 같은 걸 찾아줘" 라는 요청을 받고, **어느 데이터 노드에 그 작업을 맡길지 결정**한 후 각 노드로부터 받은 결과를 모아 다시 **사용자에게 전달하는 역할**을 합니다.\n\n- **인제스트 노드**는 새로운 데이터가 들어올 때 이를 미리 처리하여 **인덱싱을 준비**합니다.\n\n- **머신러닝 노드**는 영화 추천이나 분석 등 복잡한 작업을 따로 처리합니다.\n\n#### 예시\n예를 들어, 영화 스트리밍 사이트에서 사용자가 새로운 영화를 등록한다고 가정해 보겠습니다.\n\n1. 사용자가 영화 데이터를 **인제스트 노드**에 보내면, 인제스트 노드가 먼저 데이터를 정리한 후 **코디네이팅 노드**에 전달합니다.\n\n2. 코디네이팅 노드는 "어떤 노드가 이 데이터를 저장하고 검색하기에 좋을까?"를 판단해서 적절한 **데이터 노드**에 그 일을 맡깁니다.\n\n3. 데이터 노드는 실제로 **영화 데이터를 저장**하면서, 나중에 검색할 때 빠르게 찾을 수 있도록 미리 만들어둔 **Lucene 인덱스에 이 정보를 반영**합니다.\n\n4. **코디네이팅 노드**는 여러 데이터 노드로부터 받은 결과를 모아 사용자에게 보여줍니다.\n\n#### 데이터 노드의 구조\n**데이터 노드**는 영화의 원본 정보(예: 영화의 상세 설명 등)를 **그대로 보관**하는 동시에, 검색 속도를 높이기 위해 **Lucene 인덱스라는 별도의 자료 구조**를 만듭니다.\n이를 쉽게 비유하자면 **영화에 대한 모든 상세 정보를 보관하는 책장**과, 그 **책장에서 원하는 영화를 빠르게 찾을 수 있도록 정리해둔 목차**가 따로 있는 것과 같습니다.\n\n데이터 노드는 검색 요청이 들어오면 두 단계로 처리합니다.\n\n1. **Query 단계**: 미리 만들어둔 인덱스(목차)를 이용해 관련 문서들을 빠르게 찾아냅니다.\n\n2. **Fetch 단계**: 찾은 문서의 ID나 필요한 데이터만 선택적으로 가져옵니다.\n\n이상적인 쿼리는 **원본 데이터를 전혀 읽지 않고 인덱스에 포함된 정보만으로 응답**을 줄 수 있는 경우입니다.\n\n데이터 노드에 저장되는 인덱스는 여러개의 **샤드**와 그 **복제본**으로 구성되어 있습니다.\n\n쉽게 말하면 하나의 영화 데이터베이스를 **여러 개의 작은 책장(샤드)으로 분할해 저장**하는 것과 같습니다.\n그리고 각 **책장마다 영화 정보가 어떻게 정리되어 있는지 목차(Lucene 인덱스)** 가 따로 마련되어 있어, 사용자가 특정 영화 제목을 검색할 때 **모든 책장을 일일이 뒤지지 않고도 해당 영화가 있는 책장을 빠르게** 찾을 수 있습니다.\n\n여기서 주의할 점은 Lucene 인덱스와 elasticsearch 인덱스는 서로 다른 개념이라는 것입니다.\n\n- **Elasticsearch 인덱스**는 영화 데이터와 같이 문서들을 논리적으로 모아둔 컨테이너입니다.\n- **Lucene 인덱스**는 각 샤드가 실제로 데이터를 저장하고 검색을 수행하는 low-level 자료구조로, 한 샤드마다 하나의 Lucene 인덱스가 존재합니다.\n\n검색 작업은 **모든 관련 샤드에서 병렬로 진행**되고 코디네이팅 노드가 각 샤드에서 받은 결과들을 모아 정렬한 후 최종적으로 사용자에게 응답을 제공합니다.\n\n또한, 각 샤드에는 **복제본(Replica)** 이 있어서 한 샤드에 문제가 생기더라도 다른 복제본이 대신 그 역할을 할 수 있습니다.\n만일 한 샤드가 처리할 수 있는 초당 처리량(TPS)이 `X`라면 `Y`개의 복제본을 통해 이론적으로 `X * Y`의 TPS을 처리할 수 있는데, 코디네이팅 노드는 **복제본까지 모두 활용**해 검색 요청을 각 샤드(기본 + 복제본)로 분산시켜 노드 당 작업 부하를 줄입니다.\n\n**각 샤드는 Lucene 인덱스와 1:1 대응**됩니다.\n즉, Elasticsearch 인덱스 내의 각 샤드는 실제 검색과 인덱싱 작업을 수행하는 하나의 Lucene 인덱스입니다.\nElasticsearch는 이러한 Lucene 인덱스들을 여러 노드에 걸쳐 관리함으로써 높은 가용성과 확장성을 제공합니다.\n\n#### Lucene 인덱스의 구조\n\nLucene 인덱스는 여러 개의 **세그먼트**라는 작은 단위로 이루어져 있고, 세그먼트는 검색 엔진의 기본 단위입니다.\n\n여기서 "세그먼트"란 문서 데이터를 인덱싱한 후 저장하는 **불변(immutable)한 컨테이너**를 말합니다. \n한 번 생성된 세그먼트는 변경되지 않습니다.\n\n예를 들어 영화 정보가 새로 추가되면 Elasticsearch는 즉시 기존 인덱스를 수정하지 않고,\n먼저 문서를 **메모리 버퍼에 임시로 저장한 후 일정량이 모이면 하나의 세그먼트**로 만들어 디스크에 기록합니다.\n\n만약 데이터가 많이 쌓이면 **여러 세그먼트를 하나로 합치는 병합(merge) 작업**을 수행하여,\n이 과정에서 삭제된 문서나 업데이트로 인해 soft-delete 되어있던 불필요한 데이터를 정리합니다.\n\n영화 정보를 **수정**할 때도 기존 세그먼트를 직접 수정하지 않고, 해당 문서를 soft-delete 처리한 후 새 문서를 삽입합니다.\n\n이처럼 수정할 때 바로 덮어쓰지 않는 이유는 **데이터가 한 번 정리되어 저장되면 다시 바꾸지 않는 불변(immutable)한 성질** 때문인데, 이 구조는 여러 장점이 있습니다.\n\n1. **쓰기 성능 향상**: 새로운 문서를 추가할 때 기존 세그먼트 수정 없이 빠르게 추가할 수 있습니다.\n2. **효율적인 캐싱 가능**: 세그먼트는 변경되지 않으므로 메모리나 SSD에 안전하게 캐시할 수 있습니다.\n3. **간소화된 동시성 처리**: 읽기 작업 시 데이터가 중간에 변경되지 않기 때문에 여러 사용자가 동시에 접근해도 문제가 발생하지 않습니다.\n4. **쉬운 복구**: 시스템 장애가 발생해도 세그먼트 상태가 일정하므로 복구에 용이합니다.\n5. **최적화된 압축**: 불변 데이터는 더 효과적으로 압축할 수 있습니다.\n    \n    데이터가 변하지 않으므로 압축 알고리즘은 반복되는 패턴이나 중복된 정보를 더 빨리 찾아내고 이를 반영할 수 있습니다.\n    그리고 데이터가 변경되지 않으므로 한 번 압축 작업을 최적화해 두면 이후 다시 재계산할 필요가 없습니다.\n    \n6. **빠른 검색**: 검색을 위한 자료구조와 알고리즘을 최적화할 수 있습니다.\n\n하지만 불변 구조는 **주기적으로 세그먼트를 병합**해야하고, 병합이 진행되기 전까지는 **임시 저장 공간이 증가**한다는 단점도 있습니다.\n\n#### Lucene 세그먼트의 주요 기능\n\nLucene 세그먼트는 단순히 문서를 저장하는 컨테이너 이상의 역할을 하는데, 세그먼트 내부에는 검색에 최적화된 다양한 자료구조가 들어있습니다.\n\n그 중 가장 중요한 두 가지는 다음과 같습니다.\n\n1. **Inverted Index**\n\n    Inverted Index는 모든 문서에서 등장하는 **고유한 단어**들을 **Key**로 하여 각 단어가 등장하는 **문서들의 ID 목록을 저장**합니다.\n        \n    예를 들어, 10억 편의 영화 중에서 "인셉션"이라는 단어가 들어간 영화만 찾고 싶을 때, 모든 영화를 처음부터 끝까지 뒤지는 대신 "인셉션"에 해당하는 문서 ID 목록만 빠르게 조회할 수 있습니다.\n    이렇게 하면 검색 시간이 O(n)에서 O(1) 정도로 크게 단축됩니다.   \n    \n2. **Doc Values**\n\n    만약 검색 결과를 가격이나 평점처럼 특정 필드를 중심으로 **정렬**해야 한다면 Doc Values라는 자료구조가 사용됩니다.\n    \n    Doc Values는 모든 문서의 해당 필드 값을 **column 단위로 연속적으로 저장**하고, 전체 문서를 읽지 않고도 필요한 데이터만 빠르게 읽어올 수 있게 도와줍니다.\n    (Spark나 Redshift같은 대규모 데이터 분석 도구들도 유사한 방식으로 데이터를 저장합니다.)\n\n#### 코디네이팅 노드\n**코디네이팅 노드**는 검색 요청을 받고 이를 처리할 때 **"어떤 방식으로 검색하는 것이 가장 빠를까?"** 라는 결정을 내리기도 합니다.\n\n여기서 가장 중요한 단계는 **Query planning** 입니다.\n\n쿼리 플래너는 검색 쿼리를 분석하여 어떤 방식으로 검색하는 것이 가장 효율적인지 결정합니다.\n예를 들어, "크리스토퍼 놀란" 감독의 영화를 검색할 때, 놀란 감독의 **이름이 영화 데이터 전체에 얼마나 자주 등장**하는지, **영화 제목이나 설명의 길이**는 어떤지 등의 정보를 분석해서 효율적인 검색 순서를 결정합니다.\n\n즉, 쿼리 플래너는 각 필드의 통계, 인기 키워드, 문서 길이 등 여러가지 요소를 고려하여 검색 순서를 선택하고, 여러 노드의 결과를 어떻게 합칠지 결정합니다.\n\n## 고려 사항\n1. Elasticsearch는 **검색 전용 엔진**이므로 데이터의 영구 저장은 다른 데이터베이스에 하고, elasticsearch는 그 데이터에 대한 검색을 제공하는 용도로 사용하는 것이 좋습니다.\n2. Elasticsearch는 읽기/검색 작업에 최적화되어 있으므로, 만약 **데이터가 자주 수정된다면 성능이 떨어질 수** 있습니다.\n3. 검색 결과가 **실시간으로 최신 정보를 반영하지 않을 수** 있습니다. (**eventual consistency**) 그래서 실시간성이 중요한 경우에는 다른 대안을 고려해야 합니다.\n4. 데이터를 효율적으로 검색하기 위해서는 **데이터 구조를 미리 잘 설계(비정규화)** 해야 합니다.\n5. Elasticsearch와 주 **데이터 저장소간의 데이터 동기화 문제**에 주의해야 합니다.\n\n## 특징\n1. 데이터가 **한 번 저장되면 바뀌지 않는 불변성**을 이용하면 데이터의 캐싱, 압축, 동시 접근 등이 훨씬 용이해집니다.\n2. **검색 요청을 처리하는 과정과 데이터를 저장하는 과정을 분리**하여 각각 독립적으로 최적화할 수 있습니다.\n    \n    예를 들어 데이터의 양이 너무 많아 저장과 인덱싱 처리 능력이 중요하다면 데이터 노드를 추가하여 저장 공간과 인덱싱 성능을 확장시킬 수 있고,\n    사용자가 검색 요청을 많이 보내는 경우에는 코디네이팅 노드를 추가하여 쿼리 처리 능력을 강화할 수도 있습니다.\n    \n3. 특정 **검색 패턴에 맞춰 데이터를 저장하는 인덱싱 전략**은 검색 성능에 큰 영향을 미칩니다.\n4. 여러 대의 노드가 함께 작업하는 분산 시스템은 확장성과 fault tolerance를 제공하지만, 데이터 일관성이나 네트워크 문제 등 복잡한 문제들도 함께 발생하므로 **CAP Theorem 사이의 균형**을 잘 맞춰야합니다.\n5. 특정 용도에 맞춰 **최적화된 자료구조를 선택**하는 것이 성능 향상에 매우 중요합니다.\n\n## References\nhttps://www.paradedb.com/blog/elasticsearch_vs_postgres\n\nhttps://medium.com/swlh/bkd-trees-used-in-elasticsearch-40e8afd2a1a4\n\nhttps://j.blaszyk.me/tech-blog/exploring-apache-lucene-index/\n'},{slug:"computer-networks/AS-and-interdomain-routing-algorithm",categorySlug:"computer-networks",title:{ko:"AS와 인터도메인 라우팅 알고리즘",en:"AS and Interdomain Algorithm"},date:"2025-02-24 21:18",category:{ko:"컴퓨터 네트워크",en:"Computer Networks"},description:{ko:"AS와 인터도메인 라우팅에 대해 알아봅시다",en:"Autonomous System and Interdomain Algorithm"},content:"\n## 인터넷 생태계의 구성 요소\n오늘날의 인터넷은 단일 네트워크가 아니라 서로 연결된 여러 네트워크로 구성된 복잡한 생태계입니다.\n이 생태계를 구성하는 주요 요소는 다음과 같습니다.\n\n1. **인터넷 서비스 제공자 (ISP, Internet Service Provider)**\n    \n    ISP는 규모와 역할에 따라 세 가지 유형으로 나뉩니다.\n    \n    - **Access ISP (Tier-3)**: 최종 사용자에게 직접 인터넷 연결을 제공하는 소규모 ISP\n    - **Regional ISP (Tier-2)**: 여러 access ISP를 모아 연결하며 중간 규모의 네트워크를 형성\n    - **Global ISP (Tier-1)**: 전 세계에 걸쳐 **backbone 네트워크**를 운영하며, 약 10여 개의 대형 Tier-1 ISP가 존재합니다.\n        작은 네트워크들은 주로 regional ISP나 access ISP를 통해 Tier-1 ISP에 연결됩니다.\n    \n2. **인터넷 교환 지점 (IXP, Internet Exchange Points)**\n    \n    IXP는 여러 네트워크(예를 들어 ISP와 CDN)가 물리적인 인프라를 통해 서로 연결되어 **트래픽을 로컬에서 교환할 수 있게 해주는 시설**입니다.\n    2019년 기준 전 세계에 약 500여 개의 IXP가 존재합니다.\n\n3. **콘텐츠 전송 네트워크 (CDN, Content Delivery Network)**\n\n    CDN은 **콘텐츠 제공자가 최종 사용자에게 콘텐츠를 더 효율적으로 전달**하고, **연결 비용을 줄이기 위해** 구축한 네트워크입니다\n    \n    예를 들어, Google이나 Netflix와 같은 CDN은 전 세계에 분산된 다수의 데이터 센터와 수백 대의 서버를 보유하고 있습니다.\n    \n위와 같은 생태계는 기본적으로 **계층적 구조**를 띄고 있습니다.\n\n예를 들어, 소규모 access ISP는 더 큰 regional ISP의 고객이 되며, regional ISP는 다시 Tier-1 ISP의 고객이 되는 식입니다.\n\n각 계층의 네트워크들은 **같은 유형의 다른 네트워크와 경쟁**합니다. 예를 들어 Tier-1 ISP끼리는 서로 경쟁하고, Regional ISP 역시 서로 경쟁합니다.\n\n동시에, 경쟁 관계에 있는 ISP들도 전 세계 **고객들에게 연결성을 제공하기 위해 상호 협력**해야 합니다. \nISP들은 고객 수나 지리적 위치에 따라 다양한 상호 연결 전략을 사용합니다.\n\nISP들은 다음과 같은 추가적인 상호 연결 옵션을 사용합니다.\n\n- **PoP (Point of Presence)**: ISP 네트워크 내에 위치한 하나 이상의 라우터로, 고객 네트워크가 해당 ISP에 접속할 때 사용합니다.\n- **Multihoming**: 한 ISP가 여러 제공자 네트워크에 동시에 연결되어 보다 안정적인 연결성을 확보하는 방식입니다.\n- **Peering**: 두 ISP가 별도의 비용 없이 서로의 네트워크에 직접 트래픽을 전달하기 위해 합의하는 관계입니다.\n\n## Autonomous System (AS)\n각 ISP나 CDN은 하나 이상의 Autonomous System (AS)로 운영됩니다.\n\nAS는 **동일한 관리 권한 하에 운영되는 라우터와 그 링크의 집합**입니다.\n\n각 AS는 자체 정책을 수립하고, 트래픽 엔지니어링 결정 및 상호 연결 전략을 구현하며, 네트워크 내/외부의 트래픽 경로를 관리합니다.\n\n라우팅 프로토콜엔 **BGP**(외부 라우팅, Border Gateway Protocol)와 **IGP**(내부 라우팅, Internal Gateway Protocol)이 있는데 IGP에 관한 내용은 Intradomain routing algorithm 포스트에서 확인하실 수 있습니다.\n\n### AS 간 비즈니스 관계\nAS 간에는 주로 두 가지 비즈니스 관계가 존재합니다.\n\n1. **Provider-Customer 관계 (Transit)**\n\n    **고객 AS는 제공자 AS에게 비용을 지불**하고, 제공자 AS는 고객 AS의 트래픽을 자신의 라우팅 테이블에 포함된 목적지로 전달합니다.\n    \n2. **Peering 관계**\n\n    **두 AS가 서로의 고객에게 트래픽을 전달할 때 비용 없이 직접 연결**합니다.\n    피어링 관계는 트래픽이 크게 비대칭적이지 않은 경우에 형성되며, 규모가 비슷한 경우 (특히 Tier-1 간) 혹은 소규모 ISP끼리 비용 절감을 위해 이루어집니다.\n\n또한, 제공자 AS는 고객의 트래픽 양, 즉 연결 대역폭을 기반으로 과금 방법이 달라질 수 있습니다:\n\n- **고정 가격 방식**: 미리 정해진 범위 내의 대역폭 사용 시 일정 비용을 청구합니다.\n- **실제 사용량 기반 방식**: 주기적인 측정을 통해 95th percentile을 기준으로 비용을 산정합니다.\n    \n어떤 경우에는 라우팅 정책이 고객 트래픽의 양을 늘려 제공자의 수익을 극대화하기 위해 설계되기도 합니다.\n\n## BGP Routing 정책\nBGP에서 한 AS가 어떤 경로를 외부에 광고(Export)하고, 어떤 경로를 수신(Import)할지는 중요한 결정입니다.\n\n### 경로 광고(Export)\n- **고객으로부터 학습한 경로**\n    \n    고객 AS로부터 받은 경로는 **가능한 한 많은 이웃 AS에 광고**해서 고객 트래픽이 더 많이 유입되도록 합니다.\n\n- **제공자 또는 피어로부터 학습한 경로**\n\n    이 경우, 해당 경로는 비용 문제가 있기 때문에 일반적으로 **고객에게만 광고**하고 다른 제공자나 피어에게는 광고하지 않습니다.\n\n### 경로 수신(Import)\n여러 AS로부터 동일 목적지에 대한 경로를 수신할 경우, 우선순위는 보통 다음과 같이 결정됩니다:\n1. 고객 경로\n2. 피어 경로\n3. 제공자 경로\n\n이런 우선순위는 **불필요하게 다른 AS를 경유하지 않도록** 하여 비용을 최소화 하는 것이 목적입니다.\n\n### 기본 개념\n#### BGP 세션\nBGP 세션은 **두 라우터(피어)가 TCP 연결을 통해 반영구적으로 유지하면서 라우팅 정보를 교환하는 연결**입니다.\n\n**eBGP(External BGP)** 는 서로 다른 AS 간의 border router들이 설정하는 세션이고, **iBGP(Internal BGP)** 는 동일한 AS 내에서 내부 라우터들 간에 설정하는 세션입니다.\n\n#### BGP 메시지\nBGP 세션이 수립되면 다음과 같은 메시지가 교환됩니다:\n\n- **UPDATE** 메시지\n    \n    **Announcement**: 새로운 경로 또는 기존 경로 업데이트를 광고\n    \n    **Withdrawal**: 이전에 광고한 경로가 더 이상 유효하지 않을 때 전송\n    \n- **KEEPALIVE** 메시지\n    \n    세션 유지를 위해 주기적으로 교환\n\n#### 경로 속성\n- **AS-PATH**: 경로가 거쳐온 AS 번호들의 목록으로, 루프를 방지하고 최단 경로를 선택하는 데 사용됩니다.\n- **NEXT-HOP**: 목적지까지의 다음 홉 라우터의 IP 주소를 나타내며, 내부 라우터는 이를 사용해 최종 목적지로 트래픽을 전달합니다.\n\n### BGP 결정 과정\n라우터가 동일한 목적지에 대해 여러 경로를 수신할 경우, BGP는 여러 속성을 기준으로 최적의 경로를 선택합니다.\n\n- **LocalPref (Local Preference)**\n\n    **같은 AS 내에서 외부 경로를 선택할 때** 어떤 경로를 우선 사용할지를 결정합니다.\n    \n    예를 들어, 특정 AS로부터 학습한 경로에 **높은 LocalPref 값을 부여하면 그 경로가 우선 선택**되어 트래픽의 출구 지점으로 사용됩니다.\n    \n- **MED (Multi-Exit Discriminator)**\n\n    여러 연결 지점이 존재할 때, **인바운드 트래픽이 어느 링크를 통해 들어올지 결정**하는데 사용됩니다.\n    \n    **낮은 MED 값을 가진 링크가 선호**되며 이는 AS 간의 여러 연결 상황에서 인바운드 경로를 조정하는 데 도움을 줍니다.\n    \n이 외에도 각 AS는 자체 정책과 비즈니스 관계에 따라 경로의 광고 및 수신을 제어합니다.\n\n## IXP와 피어링\nIXP는 **여러 AS가 물리적 인프라를 통해 서로 연결되어 트래픽을 교환**할 수 있도록 지원해줍니다.\n대규모 IXP일 경우, 수만 개의 피어링 링크가 존재하며 일일 트래픽 양은 글로벌 Tier-1 ISP 수준에 필적할 정도입니다.\n\nIXP는 DDoS 공격 완화 역할도 수행하며 여러 연구와 실제 운영에서 중요한 역할을 하고 있습니다.\n\n\n### 피어링 방법\n1. 각 AS는 공개 AS 번호(ASN)을 보유해야 하며 IXP 시설에 라우터를 배치하여 IXP 스위치에 연결합니다.\n2. BGP를 실행할 수 있어야 하며 IXP의 약관 (GTC)에 동의해야 합니다.\n3. 비용 측면에서는 초기 회선 구축 비용, 월별 포트 사용 요금, 경우에 따라 연회비 등이 발생할 수 있으나 실제 트래픽 교환은 대체로 정산 없이 (settlement-free) 이루어집니다.\n\n### 제공 서비스\n- **Public peering**: IXP 인프라를 통해 다수의 AS와 비용 부담 없이 트래픽을 교환하는 서비스\n    \n- **Private peering**: 두 AS 간 전용 회선을 통한 트래픽 교환\n    \n- **Route server**: 다수의 AS 간 피어링 세션을 중앙에서 관리하여 BGP 세션 수를 줄이고 multilateral peering 지원\n    \n- **Remote peering**: 물리적으로 IXP에 직접 참여하지 않더라도 제3자를 통해 IXP에 접속하는 방식\n\n### 검증\nBGP는 복잡하고 다양한 라우터 제조사의 설정 언어에 따라 달라지기 때문에 오작동이나 Misconfiguration이 발생할 수 있습니다.\n\n이 때, BGP가 올바르게 동작하는지는 **경로 가시성(path visibility)** 과 **경로 유효성(route validity)** 으로 평가할 수 있습니다.\n\nPath visibility는 **목적지까지의 경로가 네트워크 내에서 올바르게 전파되는 지**를 확인하는 것이고, Route validity는 **목적지로 트래픽이 실제 도달하는 지**를 확인하는 것입니다.\n\n이를 사전에 점검하기 위해 RCC(Router Configuration Checker)와 같은 도구가 사용되며, 정적 분석을 통해 구성 오류를 사전에 탐지할 수 있습니다.\n\n"},{slug:"computer-networks/router-design",categorySlug:"computer-networks",title:{ko:"라우터 디자인",en:"Router Design"},date:"2025-02-24 22:15",category:{ko:"컴퓨터 네트워크",en:"Computer Networks"},description:{ko:"라우터 디자인과 그 알고리즘에 대해 알아봅시다",en:"Router design and its algorithms"},content:'\n## 라우터\n라우터의 주요 임무는 **패킷을 올바른 출력 포트로 전달**하고, **라우팅 프로토콜을 실행하여 경로를 관리**하는 것입니다.\n### 구성 요소\n#### Forwarding Plane\nForwarding plane의 역할은 **패킷이 들어오는 인터페이스에서 적절한 output 인터페이스로 빠르게 전달**하는 것입니다.\n이것은 일반적으로 몇 나노초 단위의 매우 짧은 시간에 **하드웨어**로 구현됩니다.\n\n구성 요소는 다음과 같습니다.\n\n1. **입력 포트**: 외부 링크의 신호를 받아들이고, 패킷의 캡슐화를 해제하고, 패킷의 목적지 IP를 확인한 후 포워딩 테이블(FIB)에서 어떤 출력 포트로 보낼지 결정합니다.\n2. **Switching fabric**: 입력 포트로부터 받은 패킷을 출력 포트로 전달합니다. 메모리 기반, 버스 기반, 크로스바 방식 등이 있습니다.\n3. **출력 포트**: switching fabric을 통해 전달된 패킷을 수신하고, 큐잉한 후 최종적으로 외부 링크로 전송합니다.\n\n#### Control Plane\nControl Plane은 **라우팅 프로토콜 (RIP, OSPF, BGP 등)을 실행하여 라우팅 테이블을 구성**하고 이 정보를 바탕으로 **포워딩 테이블(FIB)을 생성**하는 작업을 수행합니다.\n\n주로 **소프트웨어로 동작**하며 라우팅 프로세서 내부에서 실행되거나 SDN 환경에서는 원격 컨트롤러가 이 역할을 대신할 수 있습니다.\n\n### 동작 과정\n패킷이 라우터에 도착하면 다음과 같은 순서로 처리됩니다.\n\n1. **Lookup**\n    \n    패킷 도착 시 **입력 포트에서 목적지 IP 주소를 확인**합니다.\n    \n    **Longest Prefix Match** 알고리즘을 사용해 FIB에서 가장 적합한 경로를 찾습니다.\n    \n2. **Switching**\n\n    Lookup 결과에 따라 패킷을 **입력 포트에서 선택된 출력 포트로 전달**합니다.\n    빠른 스위칭을 위해 크로스바 스위치 등이 사용되며, 여러 입력 포트가 동일한 출력 포트로 보내려 할 경우 스케줄링 문제가 생길 수도 있습니다.\n    \n3. **Queueing**\n\n    출력 포트에 전달한 패킷은 **링크 혼잡 시 임시로 대기열에 저장**됩니다.\n    FIFO, WFQ 등 다양한 큐잉 방식이 사용되며 QoS를 지원합니다.\n    \n4. **부가 처리**\n    \n    IP 버전, TTL 감소, checksum 재계산 등을 수행하고 SNMP, ICMP, TCP/UDP 등의 프로토콜을 통해 관리 및 오류 보고 처리를 합니다.\n    라우팅 프로토콜을 통해 업데이트된 정보를 기반으로 **FIB를 재구성**합니다.\n\n### 스위칭 방식\n라우터 내부에서 패킷을 전달하기 위한 스위칭 방식에는 여러 가지가 있습니다.\n1. **메모리 기반 스위칭**\n\n    입력 포트에서 패킷을 수신하면 interrupt를 발생시켜 **라우팅 프로세서 메모리로 패킷을 복사**합니다.\n    이 때, 프로세서는 목적지 주소를 확인한 후 해당 패킷을 다시 출력 포트 버퍼로 복사합니다.\n    \n    프로세서 개입으로 인해 **처리 지연**이 생길 수 있습니다.\n\n2. **버스 기반 스위칭**\n\n    입력 포트가 패킷에 내부 헤더(출력 포트 지정 정보)를 추가한 후 공유 버스로 보냅니다.\n    **모든 출력 포트가 버스의 패킷을 받지만 오직 지정된 포트만 이를 저장**합니다.\n    \n    버스의 대역폭 제한으로 **단일 패킷**만 전송 가능합니다.\n    \n3. **크로스바 스위칭**\n    \n    N개의 입력 포트와 N개의 출력 포트를 연결하는 2N개의 버스를 사용해서 **교차점에서 스위칭을 수행**합니다.\n    서로 다른 입/출력 포트 간에 **동시에 여러 패킷을 전달**할 수 있습니다.\n    \n### Prefix Matching 및 Lookup 알고리즘\n라우터는 패킷을 전달하기 전에 **FIB에서 목적지 주소에 맞는 경로를 찾아야** 하는데 이 때 prefix-match lookup 알고리즘이 사용됩니다.\n\n인터넷이 커지면서 라우터에 명시적으로 모든 목적지를 저장하기 어려워지고, **IP 주소를 prefix 단위로 그룹화** 하게 되었습니다.\n**CIDR(Classless Inter-Domain Routing)** 로 인해 **길이가 가변적인 prefix**들이 등장하면서 Longest prefix match 문제를 해결해야합니다.\n\n#### 주요 기법\n1. **Unibit Trie**\n    \n    각 노드가 **0또는 1의 두 가지 분기**를 가지며 루트에서 시작해 입력 IP의 비트를 따라 내려갑니다.\n    마지막에 성공한 노드의 prefix가 longest prefix match 결과가 됩니다.\n\n2. **Multibit Trie**\n\n    한 노드에서 **여러 비트를 동시에 확인**하여 메모리 접근 횟수를 줄이는 방식입니다.\n    \n    **Fixed-Stride Trie**는 모든 노드에서 **동일한 비트 수**를 사용하여 분기하고, **Variable-Stride Trie**는 각 노드마다 최적의 분기 비트 수를 **동적으로 조절**하여 메모리 효율을 높입니다.\n    \n    Fixed-stride가 3인 Multibit trie를 예로 들어보겠습니다.\n    \n    데이터베이스에 저장된 prefix `P1: 101 (3비트), P2: 11001 (5비트), P3: 111 (3비트)`가 있을 때, P2의 길이가 5비트 이므로 3의 배수(6비트)로 맞추기 위해 **controlled prefix expansion**을 적용해야 합니다.\n    \n    ```\n            [Root] (Level 0, 3비트)\n              /      |         \\\n        "101": P1   "110": Node B   "111": P3\n                   (Level 1, 3비트)\n                     /         \\\n              "010": P2     "011": P2\n    ```\n    \n    루트에서 3비트 단위로 분기할 때, 입력 주소가 `101`이면 `P1`, `111`이면 `P3`로 바로 매칭됩니다.\n    \n    입력 주소가 `110`으로 시작하면 하위 노드로 내려가서 다음 3비트를 확인합니다.\n    \n    따라서, 주소가 예를 들어 `1100101010`인 경우에는 루트에서 `110`분기를 따라 내려가고, 하위 노드에서 `010`분기를 선택해서 `P2`와 longest prefix matching이 이루어집니다.\n3. **Prefix Expansion**\n    \n    **주어진 prefix를 선택한 stride 길이에 맞게 확장**하여 매칭 시 누락되는 경우를 방지합니다.\n    이로 인해 데이터베이스 크기는 증가하지만, 룩업 속도는 향상됩니다.\n    \n    예를 들어, 원래 Prefix가 `101` (3비트) 이고, 선택한 stride 길이가 2비트라면 원래 Prefix 길이인 3은 2의 배수가 아니므로 가장 가까운 2의 배수인 4로 확장해야 합니다.\n    \n    `101`을 4비트로 확장하려면 마지막 비트를 0과 1 두 가지 경우로 채웁니다: `1010`, `1011`\n    \n    원래 prefix `101`은 확장 후 **두개의 접두사 `1010`과 `1011`로 대체**됩니다. \n    이렇게 확장된 prefix들은 고정 stride 방식의 multibit trie에서 룩업 시 누락없이 빠르게 처리될 수 있습니다.\n### Concerns\n인터넷 사용 기기의 증가와 트래픽 폭증으로 인해 처리 및 메모리 요구가 증가하고 있습니다.\n또한, 고속 링크로 인한 높은 데이터 전송량 처리가 필요해졌습니다.\n\n이 때, **빠른 룩업 속도**와 **메모리 효율** 사이의 균형이 필요하고 IP prefix의 가변 길이와 매우 큰 테이블 크기로 인해 효율적인 알고리즘 설계가 필수적입니다.\n\n## Packet Classification\n기존에는 패킷 포워딩이 주로 **목적지 IP 주소의 longest prefix match**에 의존했지만 인터넷 환경이 점점 복잡해짐에 따라 네트워크는 추가 요구사항들을 충족해야합니다.\n1. **QoS (Quality of Service) 보장**\n    \n    실시간 영상, 음성 통화 같이 지연이나 패킷 손실에 민감한 애플리케이션의 경우, 특정 트래픽에 대해 low latency, consistent bandwidth, 낮은 변동성을 보장해야 합니다.\n2. **보안 보장**\n\n    방화벽을 통해 악의적인 트래픽을 차단하거나 특정 규칙에 따라 트래픽을 필터링하여 네트워크 보안을 강화해야 합니다.\n3. **트래픽 유형 기반 라우팅**\n\n    비디오 트래픽과 일반 데이터를 다른 경로로 전달하거나 트래픽을 분리하여 자원을 예약하는 등의 기능이 필요합니다.\n    \n따라서 단순히 목적지 IP 만으로 패킷을 처리하는 것으로는 부족하며, **TCP/UDP port, 출발지 IP, TCP Flag** 등 여러 필드를 기반으로 세밀한 분류가 필요합니다.\n\n### 패킷 분류의 간단한 해결책\n#### 선형 검색 (Linear Search)\nRule 데이터베이스에 있는 규칙들을 순차적으로 탐색하여 매칭되는 규칙을 찾는 방법입니다.\n\n이 때 규칙의 수가 적을 때는 괜찮지만, 수천 개 이상의 규칙이 존재하면 매우 느려집니다.\n\n#### 캐싱 (Caching)\n최근에 매칭된 결과를 캐시에 저장하여 동일하거나 유사한 패킷이 도착할 때 빠르게 결과를 반환합니다.\n\n하지만 캐시 적중률이 높더라도 캐시 미스가 발생할 경우 선형 검색을 수행해야 하므로 평균 탐색 시간이 늘어날 수 있습니다.\n\n#### Passing Labels\nMPLS나 DiffServ에서 사용되는 방법인데 **네트워크 엣지에서 패킷 분류를 수행**한 후, 패킷에 라벨을 부여하여 **중간 라우터에서는 라벨만 확인하고 포워딩**함으로써 복잡한 분류 과정을 피할 수 있습니다.\n\n### 더 나아간 해결책\n네트워크 환경에서 분류 규칙은 여러 종류로 구성되기 때문에 단순 선형 검색으로는 한계가 있습니다. \n\n#### Set-Pruning Trie\n**목적지 prefix를 기반으로 Trie를 구성**한 뒤, **각 리프 노드에 해당하는 하위 트리(출발지 prefix를 포함하는)를 연결**합니다.\n\n하지만 하나의 출발지 prefix가 여러 목적지 트리에 나타날 수 있어 **메모리 사용량이 급증**할 수 있습니다.\n\n예를 들어, 다음과 같은 규칙이 있다고 가정해봅시다.\n| **규칙** | **목적지 prefix** | **출발지 prefix**  | **설명**  |\n|-----------|-------------|----------|----------|\n| R1   | `00*`     | `0*`  | 목적지가 `00`으로 시작, 출발지가 `0`으로 시작하는 규칙 |\n| R2   | `00*`     | `10*`  | 목적지가 `00`으로 시작, 출발지가 `10`으로 시작하는 규칙 |\n| R3   | `00*`     | `0*`  | 목적지가 `00`으로 시작, 출발지가 `0`으로 시작하는 규칙 |\n| R4   | `01*`     | `11*`  | 목적지가 `01`으로 시작, 출발지가 `11`으로 시작하는 규칙 |\n| R5   | `00*`     | `11*`  | 목적지가 `00`으로 시작, 출발지가 `11`으로 시작하는 규칙 |\n\n이 때, 먼저 목적지 접두사를 기준으로 trie를 구성하면 아래와 같은 형태가 될 수 있습니다.\n```\n                 [Root]\n                    │\n         (첫 번째 비트 = \'0\')\n                    │\n                [노드: "0"]\n                 /       \\\n  (두 번째 비트 = \'0\')   (두 번째 비트 = \'1\')\n           /                    \\\n  [노드: "00"]            [노드: "01"]\n```\n`00` 노드에 속한 규칙들의 출발지 prefix는 다음과 같습니다: `R1, R3: 0*, R2: 10*, R5: 11`\n\n위 정보를 바탕으로 `00`노드에 해당하는 규칙들의 출발지 trie를 구성해보면 다음과 같습니다.\n```\n           [Source Root]\n              /      \\\n         (0) /         \\ (1)\n            /           \\\n      [0-branch]      [1-branch]\n            |          /       \\\n         "0*"       "10*"      "11*"\n```\n\n여기서 라우터는 먼저 패킷의 목적지 주소를 이용해 목적지 trie에서 longest prefix match를 진행합니다.\n예를 들어, 패킷의 목적지 주소가 `001...` 이라면 `0 -> 0` 경로를 따라 `00` 노드에 매칭됩니다.\n\n그 다음, 해당 `00`노드에 연결된 출발지 trie에서 패킷의 출발지 주소에 대해 longest prefix match를 수행합니다.\n예를 들어, 패킷의 출발지 주소가 `101...`인 경우, 출발지 trie의 오른쪽 분기를 따라가며 `10*` 또는 `11*` 중 어느 것이 매칭되는지 확인하고 가장 적합한 규칙을 선택합니다.\n\n#### Backtracking 활용 기법\n각 목적지 prefix는 정확히 **해당하는 출발지 trie를 한 번만 저장**하고, 룩업 시에 목적지 trie에서 longest prefix를 찾은 후 그 **조상 노드들에 연결된 출발지 trie들을 backtracking** 합니다.\n\n이 때 각 규칙이 한 번만 저장되므로 메모리 사용량이 줄어들지만 backtracking으로 인해 **룩업 시간이 증가**합니다.\n\n#### Grid of Tries\n사전에 **스위치 포인터(switch pointer)를 계산**하여 backtracking 시 불필요한 탐색을 건너뜁니다.\n\n### Scheduling과 HOL(Head-of-Line) 블로킹\n패킷 분류 외에도 라우터는 switching fabric을 통해 패킷을 전달할 때 패킷 스케줄링 문제에 직면합니다.\n\n#### HOL Blocking\n하나의 큐에서 가장 앞에 있는 패킷이 블로킹되면 뒤따르는 모든 패킷의 전송이 지연됩니다.\n\n이 때, 각 **출력 포트에 별도의 큐를 구성(Output queuing)** 하여 한 출력에 문제가 생겨도 다른 출력에는 영향을 주지 않도록 한다던가, \n**단일 물리 큐를 여러 가상 큐로 나누어(Parallel Iterative Matching)** 동시에 여러 패킷을 처리할 수 있도록 만들 수 있습니다.\n\n#### Scheduling 알고리즘\n1. **Take-the-Ticket 알고리즘**\n    \n    각 입력은 원하는 출력에 대해 티켓을 요청하고, 출력은 요청 받은 순서대로 티켓을 부여합니다.\n    \n    이 때 **한 흐름이 계속 티켓을 선점**하면 다른 흐름들은 오랜 시간 대기하게 되어 **HOL Blocking이 발생**합니다.\n    \n2. **Deficit Round Robin (DRR)**\n\n    **각 흐름의 고정의 할당량(quantum)과 누적 미사용량(deficit counter)을 부여**하여 할당량 내에서 패킷을 전송하고 남은 잔여량은 다음 라운드로 이월합니다.\n    이렇게 하면 각 흐름에 대해 대역폭을 공정하게 분배할 수 있습니다.\n    \n### Traffic Scheduling: 토큰 버킷 및 누수 버킷\n라우터는 **트래픽의 전송률을 제어**하여 과도한 버스트나 혼잡을 방지해야 하는데, 이를 위해 주로 사용하는 토큰 버킷과 누수 버킷 기법에 대해 알아보겠습니다.\n#### 토큰 버킷 (Token Bucket)\n\n일정 속도로 토큰이 버킷에 축적되며 패킷 전송 시 패킷 크기에 해당하는 토큰이 소모됩니다.\n버킷 최대 크기가 있어 버킷이 가득 차면 추가 토큰은 버려집니다.\n\n이로 인해 평균 전송률을 제한하면서도 **버킷에 축적된 토큰 만큼의 버스트 전송은 허용**될 수 있습니다.\n\n#### 누수 버킷 (Leaky Bucket)\n누수 버킷은 일정한 속도로 물(패킷)이 새어나가는 버킷과 유사하게 동작합니다.\n버킷이 가득 차면 새로운 패킷은 버려집니다.\n\n트래픽을 shaping 하거나, 과도한 트래픽을 걸러내어(policing) **네트워크에 일정한 전송률을 보장**합니다.\n'},{slug:"til/2025-02-25",categorySlug:"til",title:{ko:"2025-02-25",en:"2025-02-25"},date:"2025-02-25 16:57",category:{ko:"TIL",en:"TIL"},description:{ko:"Mongo Atlas full-text search에서 search node가 여러 개일 때 발생하는 문제",en:"Issues with multiple search nodes in Mongo Atlas full-text search"},content:"\nMongo Atlas Search에서 full-text search를 사용할 때 여러 search node로 쿼리를 분산시킬 수 있다.\n그런데 쿼리를 실행할 때마다 **어느 search node를 사용하냐에 따라 결과가 달라진다**는 사실을 발견했다.\n\n특히 search score가 낮은 document들만 꾸준히 드랍되는 것을 목격할 수 있었다.\n구체적으로, query를 돌릴 때 각 search node가 몇 개의 문서를 훑어보고 결과를 도출하는지 확인할 수 있는데, 그 숫자가 검색할 때마다 달라지는 현상이 있었다. (따라서 검색 결과도 달라졌다.)\n\n\nMongo support 팀에 문의한 결과 이런 경우가 가끔 발생한다고 응답이 왔고, 아직 정확한 원인을 파악하지 못했다고 한다.\n\n대신, search node(`mongot`)를 전용 노드에서 따로 실행하는 대신 **데이터베이스 자체(`mongod`)와 같은 노드에서 실행**하면 일관성있는 결과를 얻을 수 있을 것이라는 답변을 받았다.\n\n하지만 서포트 팀에서 얘기한 솔루션은 [공식 문서](https://www.mongodb.com/docs/atlas/atlas-search/about/deployment-options/#fts-deployment-options)에 따르면 Testing/Prototyping 환경에 적합한 것으로, 이 사용 사례는 우리가 처한 상황과는 맞지 않다. \n우리가 인덱스 해야하는 총 문서는 2억 건 이상이고, 데이터 양도 당연히 10GB는 훨씬 넘기 때문이다.\n\n그리고 `mongot`와 `mongod`가 같은 노드에서 실행되면 두 프로세스 간 리소스 contention이 발생할 수 있어 이상적인 환경은 아닌 것 같다.\n\nElasticsearch처럼 `mongot`도 Apache Lucene을 기반으로 만들어져있는데, [공식 문서](https://www.mongodb.com/docs/atlas/atlas-search/atlas-search-overview/#fts-architecture)에 따르면 세 가지 일을 담당한다.\n\n1. Atlas search 인덱스 생성\n2. 문서 상태 및 인덱스 변경 사항 모니터링\n3. 검색 쿼리 처리: 여기서 문서 ID와 검색 점수를 산출하고, 이 내용을 바탕으로 `mongod`에서 최종 결과를 가져온다\n\n처음엔 2번 과정에서 동기화 문제가 있어서 그런건가 싶었는데, 데이터베이스에 아무 변화가 없고 인덱스 rebuilding도 모두 완료된 상태에서도 검색 결과가 계속 달라지는 현상이 나타났다.\n(eventual consistency와는 관련이 없는 상황)\n\n그래서 지금 생각으로는 뭔가 인덱스에 있는 fuzzy search 때문에 Mongo 백그라운드에서 특정 document들을 제거 하는게 아닌가 싶긴 하지만, Mongo search 팀에서 일하는 사람이 원인을 모른다고 하니까 조금 답답하다.\n(하지만 우리보다 훨씬 복잡한 인덱스를 쓰는 사람들도 별 문제가 없는 사람들도 많았다고 하니 확실하진 않다.)\n\n우선 Mongo support에서 제시한 솔루션대로 내일 진행해보고, 쿼리 성능이나 결과를 좀 더 면밀히 분석한 후 추가로 글을 업데이트할 예정이다.\n"},{slug:"cs/cap-theorem",categorySlug:"cs",title:{ko:"CAP Theorem",en:"CAP Theorem"},date:"2025-02-25 17:14",category:{ko:"컴퓨터 공학",en:"Computer Science"},description:{ko:"CAP 이론",en:"Definition of CAP Theorem"},content:"\nCAP Theorem은 분산 시스템이 **동시에 만족시킬 수 없는** 세 가지 특성입니다.\n\n### 1. Consistency\nConsistency는 분산 시스템에 있는 **모든 노드가 같은 시점에 동일한 데이터**를 갖도록 보장하는 특성입니다.\n\n쉽게 말하면, 한 은행 지점에서 입금을 하고, 다른 지점에 방문했을 때도 즉시 동일한 잔액을 확인할 수 있어야 하는 상황을 의미합니다.\n만약 A에서 입금을 했는데 B 지점에서는 반영되지 않아 잔액이 다르다면, 이는 일관성(consistency)이 보장되지 않는 상태입니다.\n\n### 2. Availability\nAvailability는 **시스템이 항상 응답을 제공할 수 있는 능력**을 뜻합니다.\n\n만약 시스템 일부에 장애가 발생하더라도 여전히 서비스가 지속되어 요청에 대해 항상 응답을 제공해야 합니다.\n\n예를 들어 카페에 방문했을 때, 한 손님이 커피를 주문했는데 어떤 이유로 카페에서 커피를 제공하지 못한다면 그 카페는 가용성이 낮다고 볼 수 있습니다.\n\n다르게 말해, 어떤 이유로 커피가 늦어지더라도 나중에라도 커피를 제공하는 것처럼 반드시 응답(정상적인 응답 혹은 오류메시지라도) 받아야 한다는 점이 있습니다.\n\n### 3. Partition Tolerence\nPartition Tolerence는 **시스템 네트워크의 일부 구간이 끊기는 일이 발생하더라도 시스템이 정상적으로 작동하는 능력**을 의미합니다.\n\n예를 들어, 한 도시의 도로에 공사가 진행되어 통행이 불가능한 상태일때도 다른 우회도로를 통해 조금 오래 걸리더라도 차량 간 이동이 가능한 상황을 생각해 보시면 됩니다.\n\n분산 시스템에서는 복제 노드를 만들어서 사용자에게 응답할 수 있도록 처리할 수 있습니다.\n\n### 정리\nCAP Theorem은 위 세 가지 특성 중에서 두 가지만을 동시에 완벽하게 만족시킬 수 있다는 이론입니다.\n\n보통 네트워크 장애(Partition)를 완전히 배제하는 건 불가능하기 때문에 보통 Consistency와 Availability 사이에서 하나를 희생해야만 합니다.\n\nMongoDB는 **CP(Consistency + Partition Tolerence)** 를 따르는데, 만약 primary node에 문제가 생겼다면 secondary(복제된) 노드 중 하나가 primary로 promote 되어야 합니다.\n이 때, 새로운 primary 노드가 생기는 동안 **모든 쓰기 작업은 사용 불가능한 (NOT available) 상태**가 되므로 MongoDB는 CP system이라고 볼 수 있습니다.\n"},{slug:"til/2025-02-26",categorySlug:"til",title:{ko:"2025-02-26",en:"2025-02-26"},date:"2025-02-26 16:22",category:{ko:"TIL",en:"TIL"},description:{ko:"RabbitMQ Temporary queue 사용법",en:"How and when to use rabbitMQ temporary queues"},content:'\n데이터 파이프라인에서는 여러 서비스가 각각 다른 역할을 수행하는데, 때때로 **전체 흐름을 거치지 않고 특정 서비스의 결과만 확인**하고 싶을 때가 있다.\n\n예를 들어, A 서비스에서 데이터를 변형하고 B 서비스가 그 데이터를 데이터베이스에 넣는다고 가정해보자. 이때 B 서비스에서 데이터베이스 저장 과정을 생략하고 A 서비스의 결과값을 확인하는 방법은 여러 가지가 있다.\n\n두 서비스가 어떻게 연결되어 있느냐에 따라 방법이 달라질 수 있지만, 만일 RabbitMQ로 연결되어 있다면 크게 이런 방법들이 떠오른다:\n\n 1. **메시지 자체에 flag를 추가**하고 로그에서 결과값을 확인한다. \n    \n    메시지에 특정 flag가 있으면 다른 서비스들에서는 해당 메시지를 무시하도록 설정하는 방식이다.\n    하지만 이 방법은 다른 서비스들이 메시지를 실제로 읽어야 하므로 메시지 전송량이 증가하고, 결과값을 확인하려면 로그에서 해당 서비스에 대한 메시지를 뒤져야 한다는 단점이 있다.\n  \n 2. RabbitMQ의 **temporary queue**를 사용한다. \n \n    클라이언트가 연결되어있는 동안만 유지되는 임시 큐를 활용한다.\n    API 요청이 들어올 때마다 새로운 임시 큐를 생성하고, A 서비는 해당 큐에 결과값을 보낸다. \n    클라이언트는 이 큐에서 데이터를 읽은 후, 임시 큐를 삭제해서 불필요한 데이터가 쌓이는 걸 막을 수 있다.\n \n \n오늘은 2번 방법에 대해 간단히 얘기를 해보겠다.\n\n이 방법을 쓰면 API 요청으로 A 서비스 결과값을 즉시 확인하기가 훨씬 수월해진다.\n\nRabbitMQ에서 temporary queue를 만들 때는 **`exclusive=True`나 `auto_delete=True`** 같은 옵션을 사용할 수 있는데\n\n`exclusive=True`는 **한 connection에서만 접근 가능한 큐**가 되고, 그 connection(혹은 consumer)이 끊어지면 큐가 자동으로 제거된다.\n\n`auto_delete=True`는 구독중인 소비자 수가 0이 되면 큐가 제거되는데 여러 consumer가 연결해도 문제가 없다.\n\n그리고 아래 코드에서 콜백 함수가 한 개의 `Future`만 사용하기 때문에 동시에 하나의 응답만 받을 수 있다.\n그래서 동시에 여러 응답을 처리해야 하는 상황이면, **publish 시점에 메세지마다 correlation_id를 지정**해 주고, `on_response` 콜백 함수에서 `msg.properties.correlation_id` 값을 확인해 **각 `Future`에 매핑**해줘야 한다.\n(미리 dictionary를 만들어서 `key: correlation_id, value: Future` 식으로 관리)\n\n또한, A 서비스가 제대로 동작하지 않거나, 이미 다루고 있는 메시지 양이 많아 늦을 경우를 대비해 Timeout을 설정해두었다.\n\n아래 코드에서는 요청마다 새로운 큐를 생성하는 구조라서 동시에 많은 요청이 들어오면 큐가 너무 많이 생길 수 있다.\n나는 한 번에 많은 양의 요청을 고려하지 않아도 되었었는데, 만약 요청량이 많은 상황이라면 **큐 풀(pool)** 을 구성하거나 하나의 큐를 공유하면서 메세지마다 `correlation id`로 구분하면 될 것 같다.\n\n특히 대규모 트래픽에서는:\n\n1. API 요청을 비동기로 처리해 DB에 저장 후 요청 ID를 반환하고, 처리 완료 시 결과를 DB나 캐시에 저장해 별도의 endpoint로 조회\n2. 동시에 생성될 수 있는 최대 큐 개수를 제한하고, 요청들을 큐에 분산시켜 처리한다.\n\n이렇게 처리할 수 있지 않을까.. 하는 생각을 했다.\n\n```python\n# 1. temporary queue 선언: queue=""와 exclusive=True를 지정하면\n#    서버가 고유한 큐 이름을 자동으로 생성해주고,\n#    연결이 끊기면 해당 큐가 사라진다.\nreply_queue = await rabbit.queue_declare(queue="", exclusive=True)\nreply_queue_name = reply_queue.queue or ""\n\n# 2. 응답을 비동기로 기다리기 위한 Future 생성\n#    (아직 완료되지 않은 작업 결과를 담아둘 그릇이라고 보면 됨)\nloop = asyncio.get_running_loop()\nresponse_future = loop.create_future()\n\n# 3. on_response 콜백 함수: 임시 큐에서 메시지를 받으면 처리\nasync def on_response(msg: aiormq.abc.DeliveredMessage):\n    if not response_future.done():\n        response_body = msg.body.decode()\n        res_data = json.loads(response_body)\n        response_future.set_result(res_data)\n\n    await rabbit.basic_ack(msg.delivery.delivery_tag)\n\n# 4. 임시 큐 구독 시작: on_response로 메시지를 처리하도록 설정\nconsume_ok = await rabbit.basic_consume(reply_queue_name, on_response, no_ack=False)\nconsumer_tag = consume_ok.consumer_tag\n\n# 5. 메시지 발행: reply_to에 임시 큐 이름을 넣어둬야\n#    응답 메시지가 이 큐로 돌아온다.\nawait rabbit.basic_publish(\n    message_body,\n    routing_key=routing_key,\n    exchange=exchange,\n    properties=aiormq.spec.Basic.Properties(\n        reply_to=reply_queue_name,\n        content_type="application/json",\n    ),\n)\n\n# 6. 응답을 최대 N초간 기다림\ntry:\n    response_data = await asyncio.wait_for(response_future, timeout=N)\nexcept asyncio.TimeoutError:\n    response_data = {"error": "Timed out waiting for response."}\n\n# 7. 소비자 취소 및 임시 큐 삭제\nawait rabbit.basic_cancel(consumer_tag)\nawait rabbit.queue_delete(reply_queue_name)\n```\n'}],o=[{number:1,date:"2025-02-19",name:"Two Sum",tags:["Array","Hash Table"],approach:"Use hash map to store complement values",difficulty:"Easy",url:"https://leetcode.com/problems/two-sum/",solutions:[{id:"brute-force",approach:"Brute Force",code:"def twoSum(self, nums: List[int], target: int) -> List[int]:\n    for i in range(len(nums)):\n        for j in range(i + 1, len(nums)):\n            if nums[i] + nums[j] == target:\n                return [i, j]\n    return []",timeComplexity:"O(n\xb2)",spaceComplexity:"O(1)",explanation:"모든 가능한 쌍을 확인하는 방식으로, 이중 반복문을 사용합니다. 첫 번째 숫자와 두 번째 숫자의 합이 target과 같으면 해당 인덱스들을 반환합니다."},{id:"hash-map",approach:"Hash Map",code:"def twoSum(self, nums: List[int], target: int) -> List[int]:\n    seen = {}\n    for i, num in enumerate(nums):\n        complement = target - num\n        if complement in seen:\n            return [seen[complement], i]\n        seen[num] = i\n    return []",timeComplexity:"O(n)",spaceComplexity:"O(n)",explanation:"해시맵을 사용하여 각 숫자의 보수(target - 현재 숫자)를 저장합니다. 현재 숫자의 보수가 이미 해시맵에 있다면, 현재 인덱스와 해시맵에 저장된 인덱스를 반환합니다."}]},{number:2,date:"2025-02-19",name:"Task Scheduler",tags:["Heap","Queue"],approach:"Use a heap to manage task frequencies and a queue to track tasks in cooldown.",difficulty:"Medium",url:"https://leetcode.com/problems/task-scheduler/description/",solutions:[{id:"heap",approach:"Heap",code:"class Solution:\n    def leastInterval(self, tasks: List[str], n: int) -> int:\n        # 최대 힙을 사용하여 가장 빈도가 높은 작업을 먼저 처리\n        max_heap = []\n        task_counts = Counter(tasks)  # 각 작업의 빈도수 계산 (O(n))\n        \n        for count in task_counts.values():\n            max_heap.append(-count)  # 최대 힙을 만들기 위해 음수 값을 저장\n        \n        heapq.heapify(max_heap)  # O(n) 복잡도로 힙 변환\n        \n        time_elapsed = 0\n        cooldown_queue = deque()  # (남은 실행 횟수, 작업이 다시 실행 가능해지는 시간) 튜플 저장\n        \n        while max_heap or cooldown_queue:\n            time_elapsed += 1\n            \n            if max_heap:\n                remaining_executions = heapq.heappop(max_heap) + 1  # 작업 실행 (-1 증가)\n                \n                if remaining_executions < 0:  # 아직 실행해야 할 작업이 남아 있으면 큐에 추가\n                    cooldown_queue.append((remaining_executions, time_elapsed + n))\n            \n            # 가장 먼저 추가된 작업이 다시 실행 가능하면 max_heap으로 복귀\n            if cooldown_queue and cooldown_queue[0][1] == time_elapsed:\n                heapq.heappush(max_heap, cooldown_queue.popleft()[0])\n        \n        return time_elapsed\n",timeComplexity:"O(n): O(n log(26)) -> O(n), 각 작업은 최대 한 번만 heappop(), heappush() 실행 가능",spaceComplexity:"O(1): O(26) -> O(1)",explanation:"최대 힙을 사용하여 가장 빈도가 높은 작업을 먼저 실행합니다. 실행된 작업은 쿨다운 큐에 넣어 일정 시간이 지나야 다시 실행할 수 있도록 합니다. 쿨다운이 끝난 작업은 다시 힙에 추가하여 최소 시간으로 모든 작업을 처리합니다."}]},{number:3,date:"2025-02-19",name:"Design Twitter",tags:["Heap"],approach:"Use a min heap to get the 10 most recent tweets, adding previous tweets if available.",difficulty:"Medium",url:"https://leetcode.com/problems/design-twitter/",solutions:[{id:"heap",approach:"Heap",code:'class Twitter:\n    def __init__(self):\n        self.tweets = defaultdict(list)  # 사용자 ID별 트윗 리스트 저장\n        self.follows = defaultdict(set)  # 사용자 ID별 팔로우하는 사용자 목록 저장\n        self.counter = 0  # 트윗 정렬을 위한 시간 카운터 (최근 트윗이 가장 작은 값)\n\n    def postTweet(self, userId: int, tweetId: int) -> None:\n        """사용자가 새로운 트윗을 게시한다."""\n        self.counter -= 1  # 최신 트윗이 가장 먼저 나오도록 음수값 사용\n        self.tweets[userId].append((self.counter, tweetId))  # 트윗 저장\n\n    def getNewsFeed(self, userId: int) -> List[int]:\n        """사용자와 팔로우한 사람들의 최신 10개 트윗을 반환한다."""\n        followees = self.follows[userId]  # 사용자가 팔로우한 사람들 가져오기\n        followees.add(userId)  # 자신의 트윗도 포함\n\n        heap = []  # 최소 힙을 사용하여 최신 트윗 10개 유지\n\n        # 각 팔로우한 사용자의 가장 최신 트윗을 힙에 추가\n        for followee in followees:\n            if followee in self.tweets:\n                idx = len(self.tweets[followee]) - 1  # 최신 트윗의 인덱스\n                count, tweet_id = self.tweets[followee][idx]\n                heapq.heappush(heap, (count, tweet_id, followee, idx - 1))  # 최신 트윗 삽입\n\n        res = []\n        while heap and len(res) < 10:  # 최대 10개의 트윗을 가져옴\n            count, tweet_id, followee, idx = heapq.heappop(heap)  # 가장 최신 트윗 꺼내기\n            res.append(tweet_id)\n\n            if idx >= 0:  # 해당 사용자의 이전 트윗이 존재하면 힙에 추가\n                count, tweet_id = self.tweets[followee][idx]\n                heapq.heappush(heap, (count, tweet_id, followee, idx - 1))\n\n        return res\n\n    def follow(self, followerId: int, followeeId: int) -> None:\n        """followerId 사용자가 followeeId 사용자를 팔로우한다."""\n        self.follows[followerId].add(followeeId)\n\n    def unfollow(self, followerId: int, followeeId: int) -> None:\n        """followerId 사용자가 followeeId 사용자를 언팔로우한다."""\n        if followeeId in self.follows[followerId]:\n            self.follows[followerId].remove(followeeId)\n',timeComplexity:"O(n log n) (for getNewsFeed), O(1) (for other methods)",spaceComplexity:"O(N * m + N * M + n): O(N * m)(모든 사용자의 트윗 저장, N: 전체 사용자 수, m: 사용자당 최대 트윗 수), O(N * M)(팔로우 관계 저장, M: 사용자당 최대 팔로우 수), O(n)(getNewsFeed() 실행 시 힙 사용, n: userId에 연결된 총 팔로우 수)",explanation:"최대 힙을 사용하여 가장 최신 트윗을 가져옵니다. 각 사용자의 최신 트윗을 힙에 넣고, 가장 최신 트윗을 가져온 후 해당 사용자의 이전 트윗을 추가하여 최신순으로 유지합니다. 최대 10개의 트윗만 유지하여 뉴스 피드를 반환합니다. 팔로우 관계는 별도의 해시맵에 저장하여 관리합니다."}]},{number:4,date:"2025-02-20",name:"Design Add and Search Word Data Structure",tags:["Trie","DFS"],approach:"Use a Trie to store and search words, and utilize DFS with backtracking to handle wildcard '.' searches.",difficulty:"Medium",url:"https://leetcode.com/problems/design-add-and-search-words-data-structure",solutions:[{id:"trie",approach:"Trie, DFS",code:"class TrieNode:\n    def __init__(self):\n        self.children: = dict()  # 문자 -> TrieNode 매핑\n        self.word = False  # 현재 노드가 단어의 끝인지 여부\n\nclass WordDictionary:\n    def __init__(self):\n        self.root = TrieNode()\n\n    def addWord(self, word: str) -> None:\n        curr = self.root\n        \n        for c in word:\n            if c not in curr.children:  # 해당 문자가 Trie에 없으면 새 노드 추가\n                curr.children[c] = TrieNode()\n            curr = curr.children[c]  # 다음 노드로 이동\n        \n        curr.word = True  # 단어 끝을 표시\n        \n    def search(self, word: str) -> bool:        \n        def dfs(j, root):\n            curr = root\n            for i in range(j, len(word)):\n                c = word[i]\n                \n                if c == \".\":  # '.'은 어떤 문자와도 매칭 가능\n                    for child in cur.children.values():  # 현재 노드의 모든 자식 노드를 탐색\n                        if dfs(i + 1, child):  # 다음 문자를 재귀적으로 탐색\n                            return True\n                            \n                    return False  # 매칭되는 단어가 없음\n                else:\n                    if c not in curr.children:\n                        return False\n                        \n                    curr = curr.children[c]\n                    \n            return cur.word  # 단어 끝 여부 반환\n        \n        return dfs(0, self.root)\n",timeComplexity:"O(n) for addWord(), O(n) for search()",spaceComplexity:"O(t + n), where t is the total number of stored characters in Trie and n is the depth of recursive calls in search()",explanation:"Trie를 사용하여 단어를 추가하고 검색합니다. addWord()는 단어 길이 n에 비례하는 O(n) 시간에 수행됩니다. search() 또한 일반적인 경우 O(n)이지만, '.'이 포함되면 백트래킹이 발생할 수 있습니다. 공간 복잡도는 Trie에 저장된 총 문자 개수 t와 DFS 호출 깊이 n에 의해 결정됩니다."}]},{number:5,date:"2025-02-20",name:"Word Search II",tags:["Trie","DFS","Backtracking"],approach:"Store words in a Trie and use DFS with backtracking to find valid words on the board.",difficulty:"Hard",url:"https://leetcode.com/problems/word-search-ii/",solutions:[{id:"trie",approach:"Trie, DFS",code:'class TrieNode:\n    def __init__():\n        self.children = dict()\n        self.is_word = False\n    \n    def add_word(self, word):\n        curr = self\n        \n        for c in word:\n            if c not in curr.children:\n                curr.children[c] = TrieNode()\n            curr = curr.children[c]\n        \n        curr.is_word = True\n        \ndef findWords(self, board: List[List[str]], words: List[str]) -> List[str]:\n    # Trie를 생성하고 단어들을 추가\n    root = TrieNode()\n    for w in words:\n        root.add_word(w)\n    \n    num_rows, num_cols = len(board), len(board[0])\n    res = set()  # 중복 방지를 위해 set 사용\n    visit = set()  # 방문한 위치 추적\n    \n    def dfs(r, c, node, word):\n        # 보드를 벗어나거나 이미 방문한 위치이거나, 현재 문자가 Trie에 없는 경우 종료\n        if not 0 <= r < num_rows or not 0 <= c < num_cols or (r, c) in visit or board[r][c] not in node.children:\n            return\n        \n        visit.add((r, c))\n        \n        node = node.children[board[r][c]]  # Trie에서 현재 문자에 해당하는 노드로 이동\n        word += board[r][c]  # 단어에 문자 추가\n        \n        if node.is_word:  # Trie에 등록된 단어를 찾으면 결과에 추가\n            res.add(word)\n        \n        # 상, 하, 좌, 우 방향으로 DFS 탐색 수행\n        dfs(r - 1, c, node, word)\n        dfs(r + 1, c, node, word)\n        dfs(r, c - 1, node, word)\n        dfs(r, c + 1, node, word)\n        \n        visit.remove((r, c))  # 백트래킹(이전 상태로 복귀)\n        \n    # 보드의 모든 위치에서 DFS 시작\n    for r in range(num_rows):\n        for c in range(num_cols):\n            dfs(r, c, root, "")\n    \n    return list(res)\n',timeComplexity:"O(m * n * 4 * 3^(t-1) + s), where m is the number of rows, n is the number of columns, t is the maximum length of any word in words, and s is the sum of the lengths of all words.",spaceComplexity:"O(s), where s is the sum of the lengths of all words stored in the Trie.",explanation:"먼저 단어 목록을 Trie에 저장합니다. 그런 다음, board에서 가능한 모든 위치에서 DFS를 수행하여 단어를 찾습니다. DFS 중에는 백트래킹을 사용하여 이미 방문한 위치를 추적하고, 경로를 따라 Trie에 없는 문자가 나오면 탐색을 중단합니다. 검색된 단어는 set에 저장하여 중복을 방지하고, 최종적으로 리스트로 변환하여 반환합니다."}]},{number:6,date:"2025-02-21",name:"Subsets",tags:["DFS","Backtracking"],approach:"Use DFS with backtracking to explore both including and excluding each element.",difficulty:"Medium",url:"https://leetcode.com/problems/subsets",solutions:[{id:"backtracking",approach:"Backtracking, DFS",code:"def subsets(self, nums: List[int]) -> List[List[int]]:\n    res = []  # 모든 부분집합을 저장할 리스트\n    subset = []  # 현재까지 선택된 원소들을 저장할 리스트\n    \n    def dfs(i):\n        # i가 nums의 길이와 같으면, 모든 원소에 대해 선택 여부를 결정한 것이므로 결과에 추가\n        if i == len(nums):\n            res.append(subset[:])  # 현재 subset의 복사본을 추가\n            return\n        \n        # 현재 원소를 부분 집합에 포함시키는 경우\n        subset.append(nums[i])\n        dfs(i + 1)\n        \n        # 백트래킹: 이전 선택을 취소하고 원소를 포함시키지 않는 경우\n        subset.pop()\n        dfs(i + 1)\n    \n    dfs(0)\n    return res\n",timeComplexity:"최악의 경우 모든 원소에 대해 선택 또는 비선택의 두 가지 경우를 고려하므로, 시간 복잡도는 O(2ⁿ)입니다. 또한, 각 부분집합을 복사하는 데 O(n)의 시간이 소요되므로, 전체 시간 복잡도는 O(n * 2ⁿ)입니다.",spaceComplexity:"O(n)",explanation:"각 단계에서 현재 인덱스의 원소를 선택하거나 선택하지 않고 재귀 호출을 진행합니다. 인덱스가 리스트의 길이에 도달하면, 현재까지 구성된 부분집합의 복사본을 결과에 추가합니다. 이 과정에서 백트래킹을 통해 이전 선택을 취소하여 다른 경우의 수도 탐색할 수 있습니다."}]},{number:7,date:"2025-02-21",name:"Combination Sum",tags:["DFS","Backtracking"],approach:"Use DFS with backtracking to build candidate combinations that sum to the target.",difficulty:"Medium",url:"https://leetcode.com/problems/combination-sum/",solutions:[{id:"backtracking",approach:"Backtracking, DFS",code:"def combinationSum(self, candidates: List[int], target: int) -> List[List[int]]:\n    res = []  # 결과로 반환할 조합\n    subset = []  # 현재까지 선택된 숫자 조합\n    \n    def dfs(i, curr_sum):\n        # 현재 합이 target과 같으면, 현재 조합의 복사본을 추가\n        if curr_sum == target:\n            res.append(subset[:])\n            return\n        \n        # 인덱스가 끝에 도달했거나 현재 합이 target을 초과하면 종료        \n        if i == len(candidates) or curr_sum > target:\n            return\n        \n        # 현재 후보 숫자를 조합에 포함시키고 재귀적으로 같은 인덱스에서 탐색 (같은 숫자 재사용이 가능하기 때문)\n        subset.append(candidates[i])\n        dfs(i, curr_sum + candidates[i])\n        \n        # 백트래킹: 마지막에 추가한 숫자를 제거하고 다음 후보로 넘어감\n        subset.pop()\n        dfs(i + 1, curr_sum)\n    \n    dfs(0, 0)\n    return res\n",timeComplexity:"O(2^(t/m)) 최악의 경우 모든 가능한 조합을 탐색해야 함",spaceComplexity:"O(n)",explanation:"DFS와 백트래킹을 활용하여 후보 숫자들의 조합을 탐색하며, 현재 인덱스의 숫자를 포함시켜 합계를 갱신하고 재귀적으로 탐색을 진행합니다. 만약 현재 합이 목표값(target)과 같다면 해당 조합을 결과 리스트에 추가하며, 인덱스가 배열의 끝에 도달하거나 합이 목표를 초과하면 탐색을 중단합니다. 포함한 후에는 백트래킹을 통해 마지막으로 추가한 숫자를 제거하고 다음 후보로 넘어가며 모든 가능한 조합을 탐색합니다."}]},{number:8,date:"2025-02-21",name:"Combination Sum II",tags:["DFS","Backtracking"],approach:"Use DFS with backtracking and skip duplicates with a while loop.",difficulty:"Medium",url:"https://leetcode.com/problems/combination-sum-ii/",solutions:[{id:"backtracking",approach:"Backtracking, DFS",code:"def combinationSum2(self, candidates: List[int], target: int) -> List[List[int]]:\n    res = []  # 결과 조합 저장\n    subset = []  # 현재 조합 저장\n    candidates.sort()  # 중복 제거를 위해 후보 숫자 정렬\n    \n    def dfs(i, curr_sum):\n        if curr_sum == target:\n            res.append(subset[:])\n            return\n        \n        # 합이 타겟을 초과하거나 인덱스가 범위를 벗어나면 종료\n        if curr_sum > target or i == len(candidates):\n            return\n        \n        # 현재 후보 숫자를 포함시키고 다음 인덱스로 진행\n        subset.append(candidates[i])\n        dfs(i + 1, curr_sum + candidates[i])\n        subset.pop()\n        \n        # 중복된 숫자는 한 번만 처리하기 위해 While loop를 통해 건너뜀\n        while i + 1 < len(candidates) and candidates[i] == candidates[i + 1]:\n            i += 1\n        \n        dfs(i + 1, curr_sum)\n    \n    dfs(0, 0)\n    return res\n",timeComplexity:"O(n*(2^n))",spaceComplexity:"O(n)",explanation:"후보 숫자들을 정렬하고 DFS와 백트래킹을 이용하여 목표 합을 만족하는 조합을 찾습니다. 중복된 숫자는 While loop을 통해 한 번만 처리하여 중복 결과를 방지하고, 재귀적으로 다음 인덱스로 이동하면서 가능한 모든 조합을 탐색합니다."}]},{number:9,date:"2025-02-21",name:"Permutations",tags:["DFS","Backtracking"],approach:"Use DFS with backtracking and skip already existing num in for loop.",difficulty:"Medium",url:"https://leetcode.com/problems/permutations/",solutions:[{id:"backtracking",approach:"Backtracking, DFS",code:"def permute(self, nums: List[int]) -> List[List[int]]:\n    sol = []\n    res = []\n\n    def dfs():\n        if len(sol) == len(nums):\n            res.append(sol[:])\n            return\n\n        # 입력 리스트 nums의 모든 숫자에 대해 반복합니다.\n        # 이미 현재 순열(sol)에 포함된 숫자는 건너뛰어 중복 사용을 방지합니다.\n        for num in nums:\n            if num not in sol:\n                sol.append(num)\n                dfs()\n                sol.pop()\n\n    dfs()\n    return res\n",timeComplexity:"O(n * n!)",spaceComplexity:"O(n)",explanation:"DFS와 백트래킹을 이용하여 주어진 리스트의 모든 순열을 생성합니다. 현재 순열(sol)에 포함되지 않은 숫자만 선택하여 순열을 확장하며, 입력 리스트의 길이만큼 숫자가 모두 포함되면 완성된 순열의 복사본을 결과 리스트에 추가합니다. 재귀 호출 후에는 백트래킹을 통해 마지막에 추가한 숫자를 제거함으로써 다른 조합도 탐색할 수 있도록 합니다."}]},{number:10,date:"2025-02-23 19:48",name:"Meeting Rooms",tags:["Intervals","Array"],approach:"Sort intervals by start time and check for overlapping meetings.",difficulty:"Easy",url:"https://leetcode.com/problems/meeting-rooms/description/",solutions:[{id:"intervals",approach:"Intervals",code:"def canAttendMeetings(self, intervals: List[Interval]) -> bool:\n    # 회의 일정이 없으면 겹칠 수 없으므로 True 반환\n    if not intervals: return True\n\n    # 회의 시작 시간 기준으로 intervals를 정렬\n    intervals.sort(key=lambda i: i.start)\n    \n    # 첫 번째 회의를 기준으로 마지막으로 확인한 회의 시간 설정\n    last = intervals[0]\n\n    # 정렬된 회의 리스트의 두 번째 회의부터 순회하며 이전 회의와 겹치는지 확인\n    for interval in intervals[1:]:\n        \n        # 현재 회의의 시작 시간이 이전 회의의 종료 시간보다 크거나 같으면 겹치치 않으므로 기준 회의를 갱신\n        if interval.start >= last.end:\n            last = interval\n            continue\n        \n        else:\n            return False\n    \n    # 모든 회의가 겹치지 않으면 True 반환\n    return True\n",timeComplexity:"O(n log n)",spaceComplexity:"O(1)",explanation:"회의 일정들이 겹치는지 여부를 확인하기 위해 먼저 회의들의 시작 시간을 기준으로 정렬합니다. 정렬 후, 첫 번째 회의를 기준으로 설정하고, 나머지 회의들에 대해 현재 회의의 시작 시간이 마지막으로 확인한 회의의 종료 시간보다 크거나 같은지 검사합니다. 만약 그렇지 않다면 회의들이 겹치게 되어 참석이 불가능하므로 False를 반환하고, 모든 회의가 겹치지 않는다면 True를 반환합니다."}]},{number:11,date:"2025-02-23 20:14",name:"Insert Interval",tags:["Intervals","Array"],approach:"Sort intervals by start time, then merge overlapping intervals with the new interval.",difficulty:"Medium",url:"https://leetcode.com/problems/insert-interval/description/",solutions:[{id:"intervals",approach:"Intervals",code:"def insert(self, intervals: List[List[int]], newInterval: List[int]) -> List[List[int]]:\n    merged = []\n    i = 0\n    n = len(intervals)\n    \n    # newInterval의 시작 전에 끝나는 구간들은 그대로 결과에 추가합니다.\n    while i < n and intervals[i][1] < newInterval[0]:\n        merged.append(intervals[i])\n        i += 1\n    \n    # newInterval과 겹치는 구간들을 모두 병합합니다.\n    # 여기서 조건은 현재 구간의 시작이 newInterval의 종료보다 작거나 같은 경우입니다.\n    while i < n and intervals[i][0] <= intervals[1]:\n        start = min(newInterval[0], intervals[i][0])\n        end = max(newInterval[1], intervals[i][1])\n        newInterval = [start, end]\n        i += 1\n    merged.append(newInterval)\n    \n    # 나머지 구간들은 newInterval과 겹치지 않으므로 그대로 결과에 추가합니다.\n    while i < n:\n        merged.append(intervals[i])\n        i += 1\n    \n    return merged\n",timeComplexity:"O(n)",spaceComplexity:"O(n)",explanation:"주어진 구간(intervals)들을 정렬된 상태로 가정하고, 새로운 구간(newInterval)을 기존 구간들과 병합하는 방식으로 동작합니다. 먼저 newInterval의 시작보다 빨리 끝나는 구간들은 병합 대상이 아니므로 그대로 결과 리스트에 추가합니다. 그 후, newInterval과 겹치는 모든 구간들을 찾아 시작은 둘 중 작은 값, 종료는 둘 중 큰 값으로 갱신하며 병합을 수행합니다. 마지막으로, newInterval과 겹치지 않는 나머지 구간들을 결과 리스트에 추가하여 최종 병합된 구간 리스트를 반환합니다."}]},{number:12,date:"2025-02-23 20:32",name:"Non-Overlapping Intervals",tags:["Intervals","Array"],approach:"Sort intervals by start time and remove overlapping intervals by choosing the interval with the earliest end time.",difficulty:"Medium",url:"https://leetcode.com/problems/non-overlapping-intervals/",solutions:[{id:"intervals",approach:"Intervals, Array",code:"def eraseOverlapIntervals(self, intervals: List[List[int]]) -> int:\n    intervals.sort()  # 구간들을 시작 시간 기준으로 정렬합니다.\n    res = 0\n    last_end = intervals[0][1]  # 첫 구간의 종료 시간을 기준으로 설정합니다.\n    \n    for start, end in intervals[1:]:\n        # 만약 현재 구간의 시작 시간이 이전 구간의 종료 시간보다 크거나 같다면, 겹치지 않으므로 기준 구간을 갱신합니다.\n        if last_end <= start:\n            last_end = end\n            continue\n        else:\n            # 현재 구간이 겹치는 경우, 제거 횟수를 증가시키고\n            # 최소한의 제거를 위해 이전 구간의 종료 시간과 현재 구간의 종료 시간 중 더 작은 값을 기준으로 갱신합니다.\n            last_end = min(last_end, end)\n            res += 1\n    \n    return res\n",timeComplexity:"O(n log n)",spaceComplexity:"O(1)",explanation:"구간들이 서로 겹치지 않도록 하기 위해 최소한의 구간을 제거하는 문제를 해결합니다. 먼저 주어진 구간들을 시작 시간 기준으로 정렬한 후, 첫 번째 구간의 종료 시간을 기준으로 이후 구간들을 순회하며 비교합니다. 만약 현재 구간의 시작 시간이 이전 구간의 종료 시간보다 크거나 같다면 두 구간이 겹치지 않으므로 기준 구간의 종료 시간을 갱신합니다. 반면, 겹치는 경우에는 두 구간 중 종료 시간이 더 이른 구간을 기준으로 설정하여 겹치는 구간을 제거하고, 제거 횟수를 증가시킵니다. 이와 같이 반복하여 모든 구간을 검사한 후 제거한 구간의 총 수를 반환합니다."}]},{number:13,date:"2025-02-23 21:21",name:"Merge Intervals",tags:["Intervals","Array"],approach:"Sort intervals by start time and merge overlapping intervals by extending the last interval when necessary.",difficulty:"Medium",url:"https://leetcode.com/problems/merge-intervals/description/",solutions:[{id:"intervals",approach:"Intervals, Array",code:"def merge(self, intervals: List[List[int]]) -> List[List[int]]:\n    # intervals를 시작 시간 기준으로 정렬합니다.\n    intervals.sort()\n    res = [intervals[0]]\n    \n    for interval in intervals[1:]:\n        # 현재 구간의 시작이 결과 리스트의 마지막 구간의 종료보다 크다면, 겹치지 않으므로 그대로 결과에 추가합니다.\n        if interval[0] > res[-1][1]:\n            res.append(interval)\n        else:\n            # 겹치는 경우, 두 구간을 병합하여 시작은 더 작은 값, 종료는 더 큰 값으로 업데이트합니다.\n            last_interval = res.pop()\n            res.append(\n                [min(interval[0], last_interval[0]), max(interval[1], last_interval[1])]\n            )\n    \n    return res\n",timeComplexity:"O(n log n)",spaceComplexity:"O(1)",explanation:"주어진 구간들을 시작 시간 기준으로 정렬한 후, 첫 번째 구간을 기준으로 하여 인접한 구간들과 비교합니다. 만약 현재 구간이 이전 구간과 겹치지 않으면 그대로 결과 리스트에 추가하고, 겹치는 경우에는 두 구간의 시작은 더 작은 값, 종료는 더 큰 값으로 병합하여 결과 리스트의 마지막 구간을 업데이트합니다. 이 과정을 통해 모든 구간들을 한 번씩만 순회하면서 겹치는 부분을 통합하여 최종 병합된 구간 리스트를 반환합니다."}]},{number:14,date:"2025-02-23 21:35",name:"Employee Free Time",tags:["Intervals","Array"],approach:"Sort all intervals from all employees, merge overlapping intervals, and then find gaps between them as free time.",difficulty:"Hard",url:"https://leetcode.com/problems/employee-free-time/description/",solutions:[{id:"intervals",approach:"Intervals, Array",code:"def employeeFreeTime(self, schedule: List[List[List[int]]]) -> List[List[int]]:\n    flattened_schedule = []\n    # 모든 직원의 스케줄을 하나의 리스트로 평탄화합니다.\n    for employee in schedule:\n        for e_schedule in employee:\n            flattened_schedule.append(e_schedule)\n    \n    # 평탄화된 스케줄을 시작 시간 기준으로 정렬합니다.\n    flattened_schedule.sort()\n    \n    # 첫 번째 구간을 기준으로 병합할 구간들을 저장할 리스트를 초기화합니다.\n    merged = [flattened_schedule[0]]\n    \n    # 평탄화된 스케줄의 나머지 구간들을 순회하며 겹치는 구간들을 병합합니다.\n    for interval in flattened_schedule[1:]:\n    \n        # 현재 구간의 시작 시간이 이전 병합된 구간의 종료 시간보다 크면, 겹치지 않으므로 그대로 추가합니다.\n        if interval[0] > merged[-1][1]:\n            merged.append(interval)\n        else:\n            # 겹치는 경우, 두 구간을 병합하여 시작은 더 작은 값, 종료는 더 큰 값으로 갱신합니다.\n            last_interval = merged.pop()\n            new_interval = [min(interval[0], last_interval[0]), max(interval[1], last_interval[1])]\n            merged.append(new_interval)\n    \n    free_time = []\n    # 첫 번째 병합 구간을 기준으로 설정합니다.\n    last_interval = merged[0]\n    \n    # 병합된 구간의 다음 구간부터 순회하며 이전 구간의 종료와 현재 구간의 시작 사이의 간격을 자유 시간으로 저장합니다.\n    for interval in merged[1:]:\n        free_time.append(\n            [last_interval[1], interval[0]]\n        )\n        last_interval = interval\n    \n    return free_time    \n",timeComplexity:"O(n log n)",spaceComplexity:"O(n)",explanation:"모든 직원의 스케줄을 하나의 리스트로 평탄화한 후, 시작 시간 기준으로 정렬하여 모든 구간을 순서대로 배치합니다. 이후 겹치는 구간들을 병합하여 직원 전체의 바쁜 시간대를 하나의 구간들로 통합하고, 병합된 구간들 사이의 빈틈을 찾아서 그것을 자유 시간으로 반환합니다."}]},{number:15,date:"2025-02-23 21:54",name:"Meeting Rooms II",tags:["Intervals","Array"],approach:"Sort start and end times separately, then use two pointers to count overlapping meetings.",difficulty:"Medium",url:"https://leetcode.com/problems/meeting-rooms-ii/description/",solutions:[{id:"intervals",approach:"Intervals, Array",code:"def minMeetingRooms(self, intervals: List[Interval]) -> int:\n    # 각 회의의 시작 시간과 종료 시간을 따로 저장할 리스트입니다.\n    starts = []\n    ends = []\n    for interval in intervals:\n        starts.append(interval.start)\n        ends.append(interval.end)\n    \n    # 시작 시간과 종료 시간을 각각 오름차순으로 정렬합니다.\n    starts.sort()\n    ends.sort()\n    \n    count = 0  # 현재 동시에 진행 중인 회의의 수를 저장합니다.\n    res = 0  # 필요한 최소 회의실 수를 저장할 변수입니다.\n    \n    s = 0\n    e = 0\n    \n    # 모든 회의의 시작 시간을 기준으로 반복합니다.\n    while s < len(starts):\n        start = starts[s]\n        end = ends[e]\n        \n        # 만약 현재 회의의 시작 시간이 가장 빨리 끝나는 회의의 종료 시간보다 작다면,\n        # 새로운 회의가 시작된 것이므로 동시에 진행되는 회의 수를 증가시킵니다.\n        if start < end:\n            s += 1\n            count += 1\n        else:\n            # 그렇지 않다면, 하나의 회의가 종료된 것이므로 동시에 진행 중인 회의 수를 감소시키고,\n            # 다음 종료 시간으로 이동합니다.\n            e += 1\n            count -= 1\n        \n        res = max(res, count)\n    \n    return res\n",timeComplexity:"O(n log n)",spaceComplexity:"O(n)",explanation:"각 회의의 시작 시간과 종료 시간을 따로 정렬한 후, 두 개의 포인터를 사용하여 동시에 진행되는 회의의 수를 계산합니다. 시작 시간 포인터가 현재 가장 빠른 종료 시간보다 앞서면 새로운 회의가 시작된 것으로 판단하여 회의 수를 증가시키고, 그때마다 최대 회의 수를 갱신합니다. 반대로, 시작 시간이 종료 시간과 같거나 늦으면 회의가 종료된 것으로 처리하여 회의 수를 감소시키고 다음 종료 시간으로 넘어갑니다. 최종적으로 동시에 진행되는 최대 회의 수가 필요한 최소 회의실 수가 됩니다."}]},{number:16,date:"2025-02-27 00:13",name:"Bus Routes",tags:["Adjacency List","BFS"],approach:"Build a mapping from stops to bus routes, then perform BFS on bus routes to determine the minimum number of buses needed.",difficulty:"Hard",url:"https://leetcode.com/problems/bus-routes/description/",solutions:[{id:"BFS",approach:"Adjacency List, BFS",code:"def numBusesToDestination(self, routes: List[List[int]], source: int, target: int) -> int:\n    bus_stops = defaultdict(list)\n    \n    # 만약 출발지와 도착지가 같다면, 버스를 탈 필요가 없으므로 0을 반환합니다.\n    if source == target:\n        return 0\n\n    # 각 정류장(stop)을 key로 하고, 해당 정류장을 경유하는 버스 노선의 인덱스 리스트를 값으로 하는 딕셔너리를 생성합니다.\n    for i, route in enumerate(routes):\n        for stop in route:\n            bus_stops[stop].append(i)\n    \n    # BFS를 위한 큐와 방문한 버스 노선을 추적하기 위한 집합을 초기화합니다.\n    q = deque()\n    visited = set()\n\n    # 출발 정류장을 경유하는 모든 버스 노선을 큐에 추가하고, 방문 처리합니다.\n    for bus in bus_stops[source]:\n        q.append((bus, 1))\n        visited.add(bus)\n    \n    while q:\n        size = len(q)\n\n        for _ in range(size):\n            # 큐에서 현재 버스 노선과 이용한 버스 수를 가져옵니다.\n            curr_bus, num_bus = q.popleft()\n            \n            # 현재 버스 노선에 속한 모든 정류장을 순회합니다.\n            for stop in routes[curr_bus]:\n            \n                # 만약 목표 정류장에 도착했다면, 지금까지 이용한 버스 수를 반환합니다.\n                if stop == target:\n                    return num_bus\n                \n                # 현재 정류장을 경유하는 다른 버스 노선들을 확인합니다.\n                for connected_bus in bus_stops[stop]:\n                \n                    # 아직 방문하지 않은 버스 노선이면 큐에 추가하고 방문 처리합니다.\n                    if connected_bus not in visited:\n                        q.append((connected_bus, num_bus + 1))\n                        visited.add(connected_bus)\n    \n    # 모든 가능한 경로를 탐색했음에도 목표 정류장에 도달할 수 없다면 -1을 반환합니다.\n    return -1\n",timeComplexity:"O(N+M)",spaceComplexity:"O(N+M)",explanation:"각 정류장마다 해당 정류장을 경유하는 버스 노선들을 딕셔너리로 매핑한 후, BFS를 사용하여 출발 정류장에서 출발하는 모든 버스 노선을 탐색합니다. BFS 과정에서 각 버스 노선에 속한 정류장들을 확인하며, 만약 목표 정류장에 도달하면 그때까지 이용한 버스 수를 반환합니다. 아직 방문하지 않은 연결된 버스 노선은 큐에 추가하여 계속 탐색하며, 모든 경로를 확인한 후에도 도착할 수 없으면 -1을 반환합니다."}]}]},4508:function(n,e,t){t.d(e,{cn:function(){return a}});var r=t(1994),o=t(3335);function a(){for(var n=arguments.length,e=Array(n),t=0;t<n;t++)e[t]=arguments[t];return(0,o.m6)((0,r.W)(e))}}}]);